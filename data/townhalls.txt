Open Source Initiative (OSI) Town Hall meetings on the subject of the Open Source AI Definition (OSAID)
### Start of next town hall held on 2024-01-12 ###
--- Presentation for 2024-01-12 ---
OPEN SOURCE AI DEFINITION
Online public townhall
Jan 12, 2024

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

The objective for 2024

Open Source AI Deﬁnition
version 1.0

Deﬁnition of AI system

Preamble
Out of scope issues
4 freedoms
License checklist

How Open Source came to be
1: Legal framework

2: Principles

3: Licenses

Copyright applied to
software, ﬁrst.

The GNU Manifesto
lays the ground to
oppose privatization.

Copyleft is a hack on
copyright.

This new artifact
became privatized
work.
Researchers
complained.

A community forms
around these
principles.

Incorporating the
principles, serving as
the Constitution of a
forming community.

5

Golden Rule applied to AI
If I like an AI system I must be free to share it with other people.

What we’ve learned so far
● We need to deﬁne Open Source AI, in general, not just
machine learning
● OECD’s deﬁnition of AI is well accepted (caveat: decisions)
“An AI system is a machine-based system that, for explicit or
implicit objectives, infers, from the input it receives, how to
generate outputs such as predictions, content,
recommendations, or decisions that can inﬂuence physical or
virtual environments. Different AI systems vary in their levels of
autonomy and adaptiveness after deployment.” (2023)

Matching expectations

AI deserves to enjoy the
beneﬁts of Open Source
● autonomy
● transparency
● collaborative
improvement
● ensuring the agency of
the user

Policy makers, academia and
industry are focusing on
● transparency
● trustworthiness
● reliability
● transparency
● explainability
● fairness
● safety etc

What basic freedoms do we need?
What is the preferred form to make modiﬁcations to an AI system?

What is Open Source AI
To be Open Source, an AI system needs to be available under
legal terms that grant the freedoms to:
● Use the system for any purpose and without having to ask
for permission.
● Study how the system works and inspect its components.
● Modify the system to change its recommendations,
predictions or decisions to adapt to your needs.
● Share the system with or without modiﬁcations, for any
purpose.

What is the preferred form to make
modiﬁcations to an AI system?

Getting the speciﬁcations
AI systems

List of
components

Legal
frameworks

Legal
documents

Checklist

What elements are
necessary to:
- use
- study
- modify
- share
an AI system?

What elements are
necessary to:
- use
- study
- modify
- share
an AI system?

For each artifact,
evaluate which
laws apply. Some
will be under
“Intellectual
Property” regimes,
some will be under
other regimes.

We’ll match the
components and
the identiﬁed legal
frameworks with
the terms of the
legal documents
already in use,
where available.

After repeating
this exercise
enough times,
we’ll be able to
generalize the
outcomes and
write the specs to
evaluate the
freedoms granted.

Small working groups to analyze systems
For each in:
- Pythia
- Llama2
- BLOOM
- Mistral
- Phi2
- …

● What do you need to give an input and
get an output? (use)
● What do you need to give an input and
get a different output? (modify)
● What do you need to understand why
given an input, you get that output?
(study)
● What do you need to let others give an
input and get an output? (share)
What’s the preferred form to make
modiﬁcations to an AI system?

Example: Pythia – INCOMPLETE! DON’T QUOTE!
Freedom to use:
- What do you need to
give an input and get an
output from Pythia?

❓

Example: Pythia – INCOMPLETE! DON’T QUOTE!
Freedom to study:
- What do you need to
understand why Pythia,
given an input, gives one
output?

❓

Example: Pythia – INCOMPLETE! DON’T QUOTE!
Freedom to modify:
- What do you need to
give an input and get a
different output from
Pythia?

❓

Example: Pythia – INCOMPLETE! DON’T QUOTE!
Freedom to share:
- What do you need to let
others give an input and
get an output from
Pythia or a version you
modiﬁed?

❓

Then the rest
-

get the legal framework for each component
get the legal documents
analyze the documents
write up a summary

Repeat for at least 4-5 AI systems, ideally not just LLMs
and “Generative AI”

2024 timeline

System testing work stream
Stakeholder consultation work stream
Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7

Draft 0.0.8

Townhall +

… October
Monthly Virtual
Meetings

Release
version 1.0

OSI In-Person
Stakeholder
Meeting (date
+ place TBD)

RC1

v. 1.0

Criteria for RC1 and v. 1.0
RC1

version 1

- Expected outcome of
in-person meeting end
May/early June!
- The draft is completed
in all its parts
- The draft is supported
by at least 2
representatives for
each of the 6
stakeholder groups

- Expected outcome of
in-person and online
meetings through the
summer/early autumn
- The draft is endorsed by at
least 5 reps for each of the
stakeholder groups
- Announced in late October

Help us ﬁnd stakeholders
System Creator

License Creator

Regulator

Licensee

End User

Subject

Makes AI system
and/or
component that
will be studied,
used, modified,
or shared
through an open
source license
(e.g., ML
researcher in
academia or
industry)

Writes or edits
the open source
license to be
applied to the AI
system or
component;
includes
compliance
(e.g., IP lawyer)

Writes or edits
rules governing
licenses and
systems (e.g.
government
policy-maker)

Seeks to study,
use modify, or
share an open
source AI
system (e.g. AI
engineer, health
researcher,
education
researcher)

Consumes a
system output,
but does not
seek to study,
use, modify, or
share the
system (e.g.,
student using a
chatbot to write
a report, artist
creating an
image)

Affected
upstream or
downstream by
a system output
without
interacting with it
intentionally;
includes
advocates for
this group (e.g.
people with loan
denied, or
content creators)

✅

✅

⚠

✅

⚠

⚠

Enough to start

Enough to start

Leads to US, EU,
Singapore, no
commitment yet

Enough to start

Which org is squarely in
this space?

ACLU, Algorithmic
Justice League

It doesn’t end with v. 1.0
We’ll need to deﬁne rules for maintenance and review of the
Deﬁnition

OSI’s immediate next steps
- more publicity to the process
- public discussion forum
- bi-weekly townhalls
- more opportunities to volunteer
- update project landing page
- reach out to more stakeholders
- raise funds for 2024 meetings
- setup the board for review and approval of v. 1.0

Draft v. 0.0.4 of the Open Source AI Deﬁnition
Open to public comments

https://opensource.org/deepdive/drafts

24

❓
Become a member of OSI
https://members.opensource.org/join
Support more workshops in 2024
@ed@opensource.org
stefano@opensource.org
25

The Open Source Deﬁnition

Three building blocks of AI

Hardware

Knowledge

Data

Money

Money

Money

Time

Time
Gazillions of laws

A typical $FOO is made of
Software for
training and
testing, inference
and analysis

Model architecture
and its weights and
training
parameters

Raw data and
prepared datasets,
for training and
testing

All that is written by
a human and
copyrightable must
be Open Source.

No restrictions on:

It’s not the preferred
form for making
modiﬁcations to
model/weights.

●

Who can use them

●

How they’re used

●

Retraining

●

Redistribution

Does that mean the
Deﬁnition can ignore
the original data?
28

A typical $FOO is made of
Software for
training and
testing, inference
and analysis

Model architecture
and its weights and
training
parameters

Raw data and
prepared datasets,
for training and
testing

All that is written by
a human and
copyrightable must
be Open Source.

No restrictions on:

It’s not the preferred
form for making
modiﬁcations to
model/weights.

●

Who can use them

●

How they’re used

●

Retraining

●

●

Redistribution
Unless
it kills you

?

Does that mean the
Deﬁnition can ignore
the original data?
29

“Thou shall not use
[my code | my art]
in your dataset.”
Golden Rule violated!
If I like an AI system I must share it with other people who like it

EFF: How We Think About Copyright and AI Art
https://www.eff.org/deeplinks/2023/04/how-we-think-about-c
opyright-and-ai-art-0

Accumulating data is already highly regulated

Privacy
Anti-discrimination
Accessibility
Disability protection
National security
Human rights
FTC Lina Kahn on regulating AI
https://www.nytimes.com/2023/05/03/opinion/ai-lina-khan-ftc-technology.html

Fun with names

AI, Artiﬁcial Intelligence
● It’s a science with 70 years of history
● Ignore the hype
● It has no “intelligence”
Machine Learning, drop AI?
Open Source AI? No!
What then?
32

What are Open Source AI Components
For the purposes of today’s work, we are deﬁning the
components* of an AI system broadly as:
● Code Instruction for a computer to complete a task.
● Model Abstracted representation of what an AI system
has learned from the training data.
● Data Information converted into a form efficient for
processing and transfer.

*sources: Digital Public Goods Alliance, Bunch, Appen, ComputerScience.org

What Makes an AI System Open Source

How should the freedoms apply to each component for the AI system to be licensed as
open? Study
Use
Modify
Share
Code
For someone to study how the AI
system's code works and inspect it
requires that the license for that
system....

For someone to use the AI system's
code for any purpose and without
having to ask for permission
requires that the license for that
system....

For someone to modify the code to
change its recommendations,
predictions or decisions to adapt to
their needs requires that the license
for the AI system...

For someone to share the code with
or without modiﬁcations, for any
purpose requires that the license for
the AI system...

Model
For someone to study how the AI
system's model works and inspect it
requires that the license for that
system....

For someone to use the AI system's
model for any purpose and without
having to ask for permission
requires that the license for that
system....

For someone to modify the model
to change its recommendations,
predictions or decisions to adapt to
their needs requires that the license
for the AI system....

For someone to share the model
with or without modiﬁcations, for
any purpose requires that the
license for the AI system....

Data
For someone to study how the AI
system's data works and inspect it
requires that the license for that
system....

For someone to use the AI system's
data for any purpose and without
having to ask for permission
requires that the license for that
system...

For someone to modify the data to
change its recommendations,
predictions or decisions to adapt to
their needs requires that the license
for the AI system....

For someone to share the data with
or without modiﬁcations, for any
purpose requires that the license for
the AI system....


--- Subtitles for 2024-01-12 --- ###
All right, here I am.

Let's start the recording and welcome everyone.

Maybe we can wait a couple of minutes and give a little bit of time for others to join.

Okay.

Okay.

All right.

All right.

Let's get it started so we can use most of the time and we can also collect feedback.

So I'll try to get enough time for people to ask me questions and I'm here available.

Let's get started with some very quick community agreements.

Let's make sure that we have give time for people to speak and if you're the kind of

person who usually stays quiet, speak up, feel free to really grab time and write down.

Use the hand button if you want to get attention or write down your comment, but please, we

want to be able to, we want to hear from you.

Be nice and don't have to remind people that this is a safe space and we don't have to

we have to be gentle and we need to keep on moving.

Also if we face obstacles, we move around and we will get back to it and we want to

focus on solutions.

This is a process that is complicated and it's also quite pioneer if you want.

We don't have that history outside the organization of running this co-design process with multiple

stakeholders across the world and there are a lot of things that we know don't work and

can be done better, but we also need to keep on working because time is on us.

Is there anything else that you think we need to cover in this agreement?

All right.

Okay.

So give a recap to the people who have just started following this work.

We started a discussion to define the definition of open source AI and this is a definition

that is coming from a wide conversation with stakeholders from different sides of society

for a very wide different groups and the objective that we have is to talk to multiple experts

in various fields and disciplines around the world.

We will not be able to have some genius coming out of the basement with a definition.

It's unlikely for this to happen, so this needs to be a global conversation and we're

helping.

We hear as the open source initiative as facilitator, convener of conversations for an open source

AI definition to come out of consensus from different stakeholders and the document that

we're trying to draft looks is made of three parts.

My computer is getting really slow.

Okay.

It's made of three parts.

There is a definition of AI system and a preamble at the top and the preamble contains the basic

principles of why we need open source AI.

And there is a section also with issues that are out of scope to clarify what's not covered

in this AI definition.

Then we have the shortest possible answer to the question, what is open source AI?

And they look a lot like the four freedoms for software that many of us have been accustomed

to see.

And then the rest of it is a checklist to evaluate legal documents that are used to

grant the four freedoms above to the AI system.

And we got to the point where we had plenty of conversation in the second half of last

year, 2023, with a variety of people to have the bones, the bare bones of the definition

of AI systems, the preamble, the out of scope and the four freedoms.

And we're missing this checklist of legal documents at the end.

Yes, I will explain the checklist in more details.

So probably it's worth having a very quick overview of how we are proceeding.

We're basically retracing the history of open source, compressing those 25, 30 years of

history in a few months so that we can get to the open source AI definition.

We're tracing the steps following this sequence.

We're going from a software when it came out, there was a legal framework that was applied

to it.

And a community established itself around the principles of the GNU manifesto.

And it started writing new software, the GNU operating system and sharing that was shared

with legal agreements, legal documents that were granting rights rather than removing

them.

So that's the sequence that we're trying to re-trace.

From understanding the new artifacts, these new AI systems, how they're working and which

legal frameworks apply to them, what are the principles that we want to have applied for

granting freedoms, and then we're going to look at legal documents to grant the rights

rather than remove them.

There is one interesting principle that is written inside the GNU manifesto, and that's

the golden rule that is, it's written, we can reuse it easily to apply to the AI system.

So if I like an AI system, I must be free to share it with other people.

That's the basic principle that we want to embed that we're looking for now.

And so far, what we've learned is that we really need to define open source AI in general,

not just focus on machine learning or whatever is new and exciting in this generative AI

space of the past year and a half.

So the other thing that we have learned is we need a definition of AI system.

And we found that the one provided by the Organization for Economic Development is quite

well accepted.

It's embedded in many legislations around the world and so far can be a valid starting

point.

And at least to get the conversation started, we can improve it later.

And this system definition has this concept of it basically, you can read it, it was very

in November, it was updated by the OECD.

And the other thing that is important that we have learned is that we've established

that for AI developers, we want practitioners that academia users of AI, we want them to

have the same benefits of open source, which is the autonomy, the transparency, the fact

that they have an agency, there is agency for the user.

But we also noticed that policymakers and academia and maybe the developers themselves,

developers of AI systems, they seem to be focusing more or concerned about transparency,

explainability and other objectives.

They're not thinking about open as a value.

So we need to work to match the expectations of these two groups and make sure that open

source AI helps ease the concerns of policymakers and academia.

In other words, it does not block for example, transparent or trustworthy.

We cannot have an open source AI that will never be transparent, will never be explainable

or fair, because otherwise, there will never be an open source AI that can be adopted or

that can be even legal if we look at some of the draft legislation that is flying around

the world.

So the next question that we asked ourselves in a small group is, what basic freedoms

do we need in order to share AI systems?

And the next, the sub question is, what is the preferred form to make modifications to

an AI system?

So the basic freedoms we have started by looking at the definition, the free software

definition and tweaked the language during a few meetings in person.

And we took the language to a point where it seems fair that we can have a more public

conversation.

And this is the current draft of the open source AI definition written down and you

can see it's nothing too controversial or too complicated.

We need to be able to use the system for any purpose without having to ask for permission.

And it's quite important because that permissionless is what enabled open source, the open source

world, the open source ecosystem to thrive.

We need to be able to study, we need to be able to modify and give it to others for any

purpose and without having to ask for permission again.

Now the next big question in order to get a complete draft is, what is the preferred

form to make modifications to an AI system?

And that's what we need to do.

This is the next big exercise that we need to do.

We need to get the specification.

So how are we going to be proceeding on this?

We need to start by identifying the technical legal specifications of what is made, what

an AI system is made of.

What are the components that go into it?

And what are these, the components that are, which of these components are necessary to

use, to study, to share, modify such systems?

Once we have that list of components that we need for each of those different four verbs,

for freedoms, then we look at the legal frameworks that are for those.

And from the legal frameworks, we can evaluate the legal elements, the legal documents that

accompany them.

Matching, for example, if one component is under copyright or intellectual property in

general regime, then we can say the license, we can evaluate the license and see if that

grants the freedoms.

So after we repeat this exercise for more groups, then we'll have a better understanding.

We can create that checklist.

So here's the, how we're going to proceed.

And we're going to proceed by evaluating a few examples, very specific elements, very

specific systems like BTR or Lama2 or Bloom, and we'll split into small groups.

And we're going to ask the questions one by one.

What do I need to give input and get an output?

So that's the use or and modify, et cetera.

So for example, if we want to give one by one, let's look at PTA.

What do I need in order to get an output from PTA?

Then probably we'll need weights, inference code, for example, in this one as elements

and components.

Like then why is PTA giving an input gives one output?

This is what we need to know.

We probably need to know the architecture, what went into building the dataset, maybe

access to the dataset itself and calculate the biases, et cetera.

Then moving on, how do we modify and get a different output from PTA?

They're big question.

And finally, what we need in order to share it, you know, what share the original version

or the modified version?

So we'll need to run this exercise for more than one of these systems and write, get those

components in general, analyze the legal frameworks, analyze the legal documents, and write up

a summary.

And that's going to be our-- most likely, it's going to be our basic components of the

checklist that we have at the end of the document draft definition.

In terms of timeline, we need to work-- we need to activate, like, at least-- we need

to move very fast because everyone is-- there is already enough confusion on the market

and many groups that are talking about open source AI without having a big-- without having

a shared understanding of what that means.

And we want to get with version 1 in October of this year.

So towards the end of the year.

And this means that we should be really having a release candidate around the beginning of

the summer.

In order to get to that, we need to have monthly release cadence of drafts and a constant

public review of our work with these town halls that we're going to be running-- that

are going to be running every two weeks at different time zones.

And the important piece here is that-- so we're going to create working groups and we're

going to create working groups to analyze these AI components.

And we're going to be releasing new drafts as we go.

Monthly with a monthly cadence.

Hopefully by the end of May, early June, we'll have an in-presence meeting.

We want to have enough support from different stakeholders.

And I'm going to talk about that.

What do we expect for the release candidate?

Is to have at least a draft that is completed in all its parts.

And support from at least two organizations, two groups for each of the stakeholders in

that we have-- in the groups that we have identified that I will show in a second.

And for version one, it's basically a larger group of support.

So more stakeholders that support and endorse the definition.

And we have identified six categories of stakeholders.

The system creators, the ones who are going to be creating AI systems and they will need

to-- so the ones that will create the AI systems.

And the license creators, the ones who write the legal documents to apply to the AI system

of components.

The regulators, we want to have at least-- going to want to have conversations with regulators

to get their feedback.

If they may not be able to give us endorsements, but at least we want to hear what their thoughts.

We're going to have early exposure to that.

Then we have licensees, the ones who seek to study, modify, share an open source AI

system.

So it's engineers or developers, researchers.

On the last two categories, it's where we probably need most help is end users.

So the ones who, one, need to consume the system output, but are not necessarily interested

in studying or modifying or sharing the system.

And then the final group is the subjects, those who are affected by the effects of the

system outputs, whether they are upstream or downstream.

We use this to indicate, for example, prospective homeowners whose mortgage application is evaluated

by a bank through an AI.

That's a downstream subject.

Or for example, photographers who find their image in a training data set.

That's like content creators.

Those are upstream subjects.

We want to be talking to these organizations, too.

And we want to have their feedback.

And maybe and hopefully also they're endorsing the definition at the end.

One thing also that I want to say is that this doesn't end, this process will probably

not end with version 1, because this is going to be the first definition of open source

that has a version number attached.

So we'll need to have by the end of the year, once we announce version 1, we'll need to

have in place rules for maintenance and review of this definition.

We're probably going to need to maintain and update it, given how quickly the technical

landscape changes, we will have to adapt.

So our immediate next step is we want to have the process make it more public.

Until now, we worked with a private drafting group that has been helping.

And now we got to the point where we feel there is plenty of momentum on one hand and

plenty of shared understanding of where we stand and what are the roadblocks, the biggest

ones.

So we want to have public discussion forums.

We're starting today with this public biweekly town halls.

And this will open up also to more opportunity for more opportunities to volunteer and help

out.

We'll be updating our project landing page, the opensource.org/deepdive.

We need more stakeholders to get involved and we're raising funds.

And we're also setting up the OSI board to review and approve version 1 once it comes

out.

And the drafts are being published.

They're already public and they're already public also the comments.

You can go to deepdive/drafts and you'll find a list of the published drafts and you can

join the conversation in there.

And with that, I want to open up to questions from you.

I see that there is a little bit of a discussion here already.

Do I have domain experts?

Yes.

So some domain experts have already volunteered.

I'm talking to basically friends.

Like there is one of the developer advocates and outreach advocates at Intel.

He's a personal friend.

I'm going to talk to him next week.

The people at Luther AI have made themselves available to help out to analyze Pythia.

And I'm reaching out to developers at Meta to get an explanation of Lama, Lama 2.

And I'm happy to talk to more people.

I have other people who have also volunteered to help.

And we got expertise also inside the board to help out.

To review, to run those reviews.

The topic of content creators and the New York Times with their lawsuit.

Yes, the legal team, the legal experts inside the board are already aware of that.

They're following it.

And I'm pushing the board and the board itself.

People inside the board are getting more expertise and getting ready to even write opinions eventually

on those topics.

It's really interesting to see what's happening in the content on the content creators front

and those legal issues.

Any more curiosities?

Maybe I can spend more time to talk about that checklist idea.

The idea is to get it is to get the completion of that document of the open source AI definition

needs to have something that resembles that can help that can help the license committee

or the AI committee that will be formed.

Some committee inside the open source initiative to evaluate the legal documents that are coming

together with an AI system.

So that an AI system can be judged whether it's open source or not.

Whether it grants the four freedoms that it's supposed to grant.

That is the checklist basically.

Yes.

Daniel.

The question about the getting the discussion people from the global south and not just

the United States and Europe.

Absolutely.

It was one of the eye opening conversations I've had with one of the meetings we had last

year was in Africa, Ethiopia with the digital public goods alliance.

Members meeting, members summit, private event with the DPGA members.

It was really eye opening.

So we are absolutely open to that.

And more than happy.

Like one of the call for actions, one of the things where you can help is to put us in

touch with the people who can participate to these meetings.

And workshops.

So I'm happy to follow up with you, Daniel.

Yes.

Amanda.

Good idea.

Yes.

We'll publish the agenda as we go forward.

Ian or John, I don't know how to pronounce your name.

Probably so.

That's one of the things that we need to understand.

What kind of so access to training data is probably unavoidable.

The question is what kind of access?

What level of access?

The full on training data set?

Or is it sufficient to have a detailed description of what went into it?

Or something else?

That's what we absolutely that's probably one of the most important, most difficult

questions to ask.

And most delicate conversation also.

That's why we need to look at the individual specific.

We try to have this conversation in generic terms.

And having the conversation in generic terms ended up generating a lot of yes, but.

Or yeah, but in this case, maybe if.

You know, lots of uncertainties.

We need to be specific.

Let's look at specifically what's happening individually with PTA, with Lama 2, with FIDO,

with one of these with OpenCV components, like OpenCV algorithms.

Let's have a look at specifically what these need.

And then we generalize.

SBOMS with yeah, of course, like again, with the expert, with someone who has been modifying

Lama 2.

For example, this is one of the questions I asked one of the one of the friend of mine

who's been working with and modifying Lama 2.

Let's have a chat.

What do you what do you actually need in order to modify the behavior of the Lama 2?

For example, that's the exercise we need to do.

Responsible data.

Okay.

Amanda, can you send me?

Yeah, I'll save that.

And I will if you have people who you know who will be I'd be happy to talk to them.

I see other people typing.

Did I answer your question?

Okay.

Thank you.

Yes, links to slides.

I got to publish them.

So the next steps I mentioned, one is to we're going to be creating these these these forums,

public forums where we can we can have conversations more more openly.

And let me pull it back.

And and run the exercise.

I have scheduled meetings next week.

As we as we get more as we run these exercises, analyzing PTA and analyzing Lama 2, building

that list of elements of components and getting through the the the analysis of the legal

frameworks and and and their legal things like let me get back to the slide where it

shows.

Yeah, this is the exercise that we need to do.

This one.

We need to go through this pipeline as quickly as possible.

And once it's completed, we'll have version five, draft five.

And from then on, we'll keep on iterating with with more online meetings and we'll try

to be more more visible, more transparent from now on.

Everything will be public.

And if you follow us on Mastodon and and on LinkedIn, you get the updates.

But as soon as hopefully end of next week, we'll have the public forum, if not the beginning

of the week after.

By the end of the month, for sure, we'll have the public forums that you can sign up and

have discussions and conversations and get updates.

All right.

Are there any more questions or doubts?

Yes, we should.

We should be studying also applications not based on machine learning or deep learning.

Yes, Jean Pierre.

You have any specific suggestions, recommendations for one example that we or two examples that

we we need to look at?

Claire, the best link is open source.org/deepdive.

But that page is in the process of being updated.

Diane, yes, ML Commons is looped in with this initiative and as is the Linux Foundation,

Linux Foundation groups.

That's another thing that we should be we could be doing is to publish all the organizations

that have been participating so far, following the development so far.

I offer.

Okay.

I think we can also do voice.

Voice questions.

If anyone has.

Yeah, we'll share it as a PDF, don't worry about it.

All right, folks, if there are no more questions, I'm gonna close the recording and

we'll make available the recording and a slide deck.

And I'm gonna be available again in two weeks, similar content.

We're gonna alternate the times so that instead of being in the afternoons in

Europe time, we're gonna be in the morning in Europe time.

So we're gonna try to follow to get the Asia Pacific

audience to follow, an opportunity to follow.

So thanks everyone, enjoy your weekend.

### End of last town hall held on 2024-01-12 ###

### Start of next town hall held on 2024-01-26 ###
--- Presentation for 2024-01-26 ---
OPEN SOURCE AI DEFINITION
Online public townhall
Jan 26, 2024

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

The objective for 2024

Open Source AI Deﬁnition
version 1.0

Deﬁnition of AI system

Preamble
Out of scope issues
4 freedoms
License checklist

What is Open Source AI
To be Open Source, an AI system needs to be available under
legal terms that grant the freedoms to:
● Use the system for any purpose and without having to ask
for permission.
● Study how the system works and inspect its components.
● Modify the system to change its recommendations,
predictions or decisions to adapt to your needs.
● Share the system with or without modiﬁcations, for any
purpose.

What is the preferred form to make
modiﬁcations to an AI system?

Getting the speciﬁcations
AI systems

As deﬁned by the
OECD.

List of
components

Legal
frameworks

Legal
documents

Checklist

What elements are
necessary to:
- use
- study
- modify
- share
an AI system?

For each artifact,
evaluate which
laws apply. Some
will be under
“Intellectual
Property” regimes,
some will be under
other regimes.

We’ll match the
components and
the identiﬁed legal
frameworks with
the terms of the
legal documents
already in use,
where available.

After repeating
this exercise
enough times,
we’ll be able to
generalize the
outcomes and
write the specs to
evaluate the
freedoms granted.

Report from the ﬁrst working group
session
Analyzing Llama2

8

Participants
●
●
●
●
●
●
●
●

✔ Stefano Maffulli -- Open Source Initiative (convener)
✔ Mer Joyce -- Do Big Good (facilitator)

✔ Bastien Guerry -- DINUM, French public

administration
✔ Ezequiel Lanza -- Intel
✔ Roman Shaposhnik -- Apache Software Foundation
✔ Davide Testuggine -- Meta
✔ Jonathan Torres -- Meta
Stefano Zacchiroli -- Polytechnic Institute of Paris

✔ = attended
All members participating in a personal capacity.

9

Purpose
● Process -- OSI has been convening a global
conversation to ﬁnd the deﬁnition of open source AI for
almost two years.
● Track -- The 2024 objective scope for Track 1: System
Testing is to discover what components need to be
available in each AI system for the whole system to be
studied, used, modiﬁed, and shared. We plan to
complete this track at the latest by May.
● Working group report -- objective is to talk through
initial points of difference on what components of
Llama 2 would need to be open for the whole AI system
to be studied, used, modiﬁed, and shared.
10

Framing
● Document – We’ll review the components table in the
Llama 2 specs doc and decide which exist in that AI
system, with a focus on resolving disagreement.
● Expectations – We’ll see how much of the table we get
through. (Insights on tempo and pace will be among
the learnings from this meeting.)
● Anything else? – Are there any other expectations or
framings we should put in place before we begin
working through the components table?
Go to Llama 2 document →

11

What do you need to give an input and get an
output from LLaMA2? (use)
Code

Which of these components is strictly necessary to use
Llama2?

Data preprocessing code

Not necessary BG EL
Nice for scientific reproducibility DT SM JT

Training code

Not necessary BG , EL, JT

Code used to perform inference for benchmark tests

Not necessary BG , DT, EL, SM, JT

Inference code

Necessary SM, EL, DT BG

Evaluation code
Any libraries or other code artifacts that are part of the
system, such as tokenizers and hyperparameter search
code, if used.

Necessary BG,EL SM
Should be split by “do you need it to run the model?”, so a
tokenizer is necessary while hyperparameter search code
is not (you do hyperparameter search at training time)

12

What do you need to give an input and get an
output from LLaMA2? (use)
Data - All data sets, including:
Training data sets

Not necessary - JT ,EL
Not necessary BG

Testing data sets

Necessary to check performance claims & compare
models, not necessary to run the model DT
Nice to have (for validation) - JT
Not necessary BG ,EL

Validation data sets

Nice to have (for validation) - JT DT SM
Not necessary BG

Benchmarking data sets

Nice to have (for validation)- JT ,EL
Not necessary BG

Data cards

Nice to have - JT
Not necessary BG

Evaluation metrics and results

Nice to have - JT
Not necessary BG

All other data documentation

Nice to have - Jt
Not necessary BG

13

What do you need to give an input and get an
output from LLaMA2? (use)
Model
[description TK]
Model architecture

Not necessary EL
Not necessary BG

Model parameters

Not necessary EL
Necessary SM

Model card

Necessary EL

Sample model outputs

Nice to have EL SM

Other documentation [or .…] produced, including
Thorough research papers

Nice to have EL SM

Usage documentation

Necessary EL SM

14

Next questions
What do you need
to understand how
LLaMA2 was built,
how can it be
ﬁne-tuned, what
biases, get a sense
of why an output to
an input … ? (study)
◦

how was it built,
explain its
performance,
etc.

What do you need
to give an input and
get a different
output from
LLaMA2? (modify)
◦

Techniques and
tools to
adapt/modify
for use including
ﬁne-tune and
optimize.

What do you need
to let others give an
input and get an
output from
LLaMA2? (share)
◦

Either
as-received or
after ﬁne-tuning
and other
modiﬁcations.

15

Next steps

16

Recruiting volunteers
- Review and validate the list of components
- Analyze other AI systems
(Pythia, BLOOM, Mistral, OpenCV …)

17

2024 timeline

System testing work stream
Stakeholder consultation work stream
Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7

Draft 0.0.8

Townhall +

… October
Monthly Virtual
Meetings

Release
version 1.0

OSI In-Person
Stakeholder
Meeting (date
+ place TBD)

RC1

v. 1.0

Criteria for RC1 and v. 1.0
RC1

version 1

- Expected outcome of
in-person meeting end
May/early June!
- The draft is completed
in all its parts
- The draft is supported
by at least 2
representatives for
each of the 6
stakeholder groups

- Expected outcome of
in-person and online
meetings through the
summer/early autumn
- The draft is endorsed by at
least 5 reps for each of the
stakeholder groups
- Announced in late October

Help us ﬁnd stakeholders
System Creator

License Creator

Regulator

Licensee

End User

Subject

Makes AI system
and/or
component that
will be studied,
used, modified,
or shared
through an open
source license
(e.g., ML
researcher in
academia or
industry)

Writes or edits
the open source
license to be
applied to the AI
system or
component;
includes
compliance
(e.g., IP lawyer)

Writes or edits
rules governing
licenses and
systems (e.g.
government
policy-maker)

Seeks to study,
use modify, or
share an open
source AI
system (e.g. AI
engineer, health
researcher,
education
researcher)

Consumes a
system output,
but does not
seek to study,
use, modify, or
share the
system (e.g.,
student using a
chatbot to write
a report, artist
creating an
image)

Affected
upstream or
downstream by
a system output
without
interacting with it
intentionally;
includes
advocates for
this group (e.g.
people with loan
denied, or
content creators)

✅

✅

⚠

✅

⚠

⚠

Enough to start

Enough to start

Leads to US, EU,
Singapore, no
commitment yet

Enough to start

Which org is squarely in
this space?

ACLU, Algorithmic
Justice League

It doesn’t end with v. 1.0
We’ll need to deﬁne rules for maintenance and review of the
Deﬁnition

OSI’s immediate next steps
- more publicity to the process
- public discussion forum https://discuss.opensource.org
- bi-weekly townhalls
- more opportunities to volunteer
- update project landing page
- reach out to more stakeholders
- raise funds for 2024 meetings
- setup the board for review and approval of v. 1.0

Join the conversation
● Public forum
● Join as OSI member
○ Free or full
○ SSO with other
OSI websites

23

Draft v. 0.0.4 of the Open Source AI Deﬁnition
Open to public comments

https://opensource.org/deepdive/drafts

24


--- Subtitles for 2024-01-26 --- ###
All right, and welcome.

Welcome everyone.

This is our second public town hall on the open source AI definition.

The process that the open source initiative has started more than a year ago now.

So a little ground rules before we start, we have these community agreements and I love

to have your comments on these one person at a time.

Meaning make space for others.

If you have the tendency to speak a lot, try yourself.

Think about being quiet and allow others to speak up.

And if you're the kind of person who usually doesn't speak, I highly encourage you to raise

your hand, write down your comments on the chat or take the mic.

We want to hear your voice.

We want to hear your comments.

Everyone is welcome.

Be nice.

I don't think that we need to be talking too much about this.

We expect everyone to go through this hard work without being hard themselves.

And another couple of points, like we need to keep moving.

And this means that if we face an obstacle during our conversations and as we are drafting

the open source AI definition, we may want to face recognize that we have an obstacle

or something hard to deal with.

But during the meetings, we try to keep on moving.

And we'll get back to the hard part later.

So then we go towards the destination.

And focus on solutions.

That means this is pioneer work.

It's a multi-stakeholder process.

And we know that there are a lot of things that don't work that can be done better.

But we need to focus on what works and keep marching towards the end goal.

And the end goal is to have the open source AI definition version 1 by the end of the

year.

By ideally October.

We started more than a year ago.

And we need to have a shared understanding among multiple experts in various disciplines

around the world.

This definition is not coming from a sacred text given by a genius or a saint or some

other form of venerable entity.

It needs to be built by us.

And we need to build an understanding together as we move forward before we can call this

version 1.0.

And I said we started some time ago now.

And this is what we have achieved so far.

We have a document that we're calling this definition.

And it's made of a few parts.

There is a definition of AI system at the beginning which is the same as the definition

used by the organization for economic cooperation and development.

OECD.

And there's a preamble that contains the basic principles of why we need open source AI.

And also mention of what is out of scope.

Meaning the things that we're not covering in the definition.

Then for freedoms which is the shortest possible answer to the question what is open source

AI and followed by a checklist to evaluate legal documents, not just licenses that are

used to grant the four freedoms to the components and elements of an AI system.

So we have done quite a bit of work on the part above the checklist.

And that's what we're missing.

We're missing the checklist.

That's what we're focusing on.

That's what we focused on the last couple of weeks.

Since our last meeting.

So what is open source AI in terms of the four freedoms?

This is the text that we have now in draft four.

And after a few reviews with a few experts, I don't think that this is up for discussion.

But I don't think that there are a lot of controversies or controversial statements

in here.

I think it should be quite fairly understood and fairly well supported.

Now what we need to do in terms of question that we need to find an answer for, the next

big thing is to understand what is the preferred form to make modifications to an AI system.

Because if you those of you who are familiar with the open source definition and the free

software definition, the preferred form to make modification is quite crucial to understand

how you can make how you can exercise your freedom on software.

To exercise your freedoms on software, for example, the freedom to study or the freedom

to modify the software, you need access to the source code of that program.

And we need to find an equivalent of source code of the program for the AI system.

And the proposed path towards getting there is to use this multiple steps.

First start from the concept of AI system.

Now AI system as defined by the OECD means to simplify a system, a digital system that

is capable given an input to generate an output with various degrees of independence from

human interactions.

So input, magic collaboration, output.

Now for the first step that we're working on now is to find the list of components that

are necessary to use, study, modify, share an AI system.

And depending on the component, then from the list of components, we're going to look

at each of these components to see if in which in each legal, which legal framework, legal

regimes they operate under.

So if it's, for example, the inference code or the training code that is software, it's

under the what we already know that is covered by software.

So it's going to be what people refer to as usually intellectual property or things like

that.

If it's data, then we have different regime.

And this is also going to be an exercise where we're going to be identifying potential gaps.

But we already know, for example, that large language models, the weights, for example,

are not clearly, are not yet clearly labeled either as data or software, and they may fall

into some other regime.

So there's going to be conversations around there.

And then we're going to look at existing frameworks.

I mean, for each component, we're going to look at the legal documents that go with them

and see if there is any gaps.

And reading them and analyzing them, identify common traits.

And finally, we should have, after repeating this exercise for many different AI systems,

we're going to have something that looks like a valuable checklist that we can use for many

years probably, hopefully.

So last week I said the past weeks we have started working to analyze Lama 2 as an AI

system as an example.

And this is what we discovered in the meetings and online conversations that we had last

week.

We assembled a working group made of these people from different organizations, different

expertise, all of them participating in the personal capacity.

This is one of the -- none of them is authorized to speak for the company, but they are working

-- they're collaborating with us.

And the -- so the purpose of the meeting is -- I mean, we show the purpose of the meeting.

It's part of the -- part of a track of work that is testing the system to discover the

components that are available, like the -- and so make that list and identify which ones

of them are absolutely necessary for -- to exercise each of the individual freedoms.

Like the study -- use, study, modify, and share.

And so we have reviewed the table of components that we have -- that we have borrowed.

We've been following the work of the Linux Foundation, AI and data foundation, and data

group, they've been working on a document on their own.

And that contains a pretty long, pretty detailed list of components.

And we've used that as a conversation starter for our exercise.

We have -- so this is what we've done.

We have separated the list of components into four main blocks.

Well, three main blocks and one smaller block.

One for things that we call code.

That is software.

And we have, for example, looking at the code, list of components that we call code.

And apply to the exercise -- I mean, the function of using an AI system.

So getting an output from an AI system.

Asked the group to write down if that component was necessary, strictly necessary or not.

For running or using the system.

And this is the first result for the code.

And then the next question is looking at the data.

Separated into many -- you see many different types of datasets in here.

And we asked what is necessary to use Llama2 in terms of data.

And as you can see, most of the answers are in the not necessary.

And we also captured in the document the comments on nuanced approaches.

It's not necessarily it would be nice to have.

And this is something that we want to debate further.

I'm gonna ask a question to you afterwards.

And finally, on the model itself, so the model weights, parameters, architecture, model card,

et cetera, we asked people here to describe what is needed to use.

I gotta say there was a little bit of a lot of actually a lot of conversations during

the meeting around the meaning of these words.

And there was a major misunderstanding on the word model parameters.

Because in the intention of the paper from the LFAI data, which is a very early draft,

so it's not really meant to be quoted yet, model parameters contains both model weights

and model biases and parameters, hyperparameters and other elements.

So there was a little bit of confusion.

But there was -- you know, the group seemed to agree that, of course, you need the model

weights to run, to use Llama2.

And other components like model card, some people interpreted the definition of model

card as something that is necessary for use.

And then finally, the last group of elements or components is on the documentation, the

supporting documentation.

Like, the availability of a thorough research paper for the execution, you know, for running

Llama2 is nice to have.

I guess, you know, you can understand a lot of things.

But it's actually not strictly -- what is strictly or much more necessary is have documentation

on the usage.

And this is the current status.

We didn't get through -- we didn't get through the first meeting, during the first meeting

through the other freedoms, Modify and others.

But we're gonna keep on iterating with the others.

So yeah.

This is what we need to do next.

It's to ask these questions on what you need to study.

So understand how the Llama2 was built, fine-tuned, how it can be fine-tuned, what biases are

in the dataset.

And things like that.

Explain its performance.

And on the Modify questions are more on the -- what are the tools, techniques that we

can use to fine-tune, optimize, get a different output from -- or faster outputs from the

model or more accurate.

And finally, in order to share it, what are we gonna do?

You know, what is necessary, what is needed?

So for us, the next steps are continuing on this process of running these meetings and

starting new AI systems.

We've already -- I've already asked a few people who volunteered to analyze Pythia.

But we need to start parallel the process for Bloom and Mistral.

And also we want to look at AI systems that are not generative AI, that are not large

language models.

And like inside OpenCV, the Open Computer Vision Project, there are a lot of neural

networks and other kind of AI that are not generative AI.

So they pose a slightly different -- slightly different questions if we want to look into

those.

So if you know anyone in those areas, point them our way.

And I'll give you also more information about how to engage later.

And we also need to validate this list of components.

As I mentioned, we worked with the AI and data from Linux Foundation.

But we know that the -- that their paper is not peer-reviewed.

And their working paper, they're still working on it.

So we need to provide feedback to them.

But also we need to see whether that list of components is enough or if we need to keep

on improving it.

So to reiterate our timeline, it still looks like this.

We want to have a new draft of the definition in February.

And then a regular cadence every month.

Have a new draft of the definition.

Refining at every step.

And most importantly, the most important part is as we refine this step, we also have more

publicity to it, more people supporting it, endorsing it.

And we need it to -- we want to get to a point in between the end of May, early June, where

we have enough support and enough endorsements collected from a variety of different stakeholders

to be able to call the definition feature complete and issue a release candidate, first

release candidate.

Then between June and October, we want to get into a series of conferences, a series

of meetings around the world with me and other volunteers who have participated in the drafting

process.

Maybe some of the original endorsers that participated to release candidate work.

And push it through a big exposure and a round of larger feedback.

And by October, gain like double the amount of endorsers and be able to call it version

1.0.

And because version 1.0 will be basically feature complete license that enough organizations

from a variety of interests will be supporting it and be able to endorse it.

And say we're going to be using it.

But then after version 1, we know that there's going to be more work to be done.

So in terms of stakeholders that we want to have in the rooms to work with us on the definition,

we need to find a way to engage with policymakers.

That is we have some contacts and we need to have a little bit more of conversations

with people who are working in the government space, in the policymaking space.

Even though of course regulators will not be giving comments to us.

People who write the legislation.

And we will not engage with people who write legislation directly because we cannot as

an American.

But we want to hear from the people who are in this space.

Because we notice that there is legislators are concerned about abuse of AI.

And there is already starting to emerge a vision that open source AI or open AI widely

available models and AI are capable of influencing elections or creating havoc in the society

in general.

So we need to make sure that whatever definition comes out of this process is not seen as a

threat to society by regulators.

That's something we need to be very careful about.

And we need to explain this as we go.

Understanding the problematics and solve them as soon as possible.

And we need also to engage a lot with end users.

So people who are like interacting with a bot at a bank.

Or subjects.

These are people who don't know that they're talking to an AI and they are affected by

the automatic decisions, for example.

We need to engage with them.

So how a reminder, this is doesn't end with 1.0.

We already started to define to think about what's going to be the future of 1.0.

Like the open source initiative and its board has set up is setting up a new committee to

brainstorm to think about the maintenance of this definition that is coming very quickly

in a space that is evolving even faster, even more rapidly.

So we need to prepare to catch up and to have a process to maintain the definition to keep

it valid over time.

And so what we're launching today is a new forum.

We'll keep on doing these biweekly town halls and we'll keep on adding opportunities to

volunteer to help out.

We're working on a new version of the landing page to have the information all about this

process all in one place.

And we've done that.

We're working on this.

And as I said, setting up the board for managing the future.

So as a big announcement for you is to the opening of the forums to have this conversation

publicly online in order to join the forum.

The forum uses the single sign on with other OSIs website.

So you can you need to become a member of OSI.

That is a free member.

We have three tiers.

There is a free membership.

So you don't have to worry about having to pay.

Or if this is an opportunity for you to support this work, which is very important, you can

become a full member and donate to us from $50 a year and up.

And on the forums you will find the links to the latest drafts.

We will keep on asking questions on the forums.

We'll keep on having the conversations we're having here constantly on the forums.

And with that, I will I see that there are some questions on the chat.

If you prefer, I can unmute all of you.

You can also take the mic and speak.

So I'll answer the question from Dirk.

What licenses are required for the data and software components in the AI system?

So we'll be talking about it.

From the software components, it's I think that the answer is going to be quite easy.

Anything that is recognizably software, we need to use licenses that have been approved

by the open source definition.

For the data component, it's we'll have to have conversations around that.

I think we are working with organizations like Creative Commons and I mentioned the

Linux Foundation AI Data.

They have their licenses.

There are different licenses that qualify as open data.

The open data world has a different culture than the open source movement and the open

source world.

The data people, I mean, the people who have been dealing with open data that I met, I'm

not sure how much they have been thinking about the fact that their data is actionable.

We need to understand with them, we need to work with them to understand exactly what

they think of their space once the space of open data, once it becomes actionable just

like software.

In other words, to make a pretty simple example, not many data sets out there are maintained

in a way that they can be modified and fixed.

One of the latest examples that I noticed is that in an open data set that has been

used to train a lot of the large language models had reported, I mean, someone analyzed

it years ago and found that it contained a lot of images that were illegal in many parts

of the world and absolutely abhorrent, including child porn and atrocious material.

Now the project that the people, the group that maintains this data set, which is open,

never received a public issue.

This is on GitHub, this data set.

It's a GitHub project and there was no issue filed, but there was a paper, a research paper

filed that described the bad material in the data set.

So I think that there is work that needs to be done into this community because they're

completely different and they're probably inside a similar conundrum that we as open

source groups are when it comes to AI.

Our world is being disrupted, let's say, modified.

I don't know if that explains it.

Any other questions?

Curiosities?

Thanks, Kellen.

Yeah, glad to see you.

And I hope that we can, yeah, we can work together soon.

Any other concerns, questions?

I'll give you time to start playing with the forums and maybe if you have any technical

issues, you can, we can do, play with it.

All right.

No more questions.

I'm going to stop the recording.

Thanks.

Bye.

### End of last town hall held on 2024-01-26 ###

### Start of next town hall held on 2024-02-09 ###
--- Presentation for 2024-02-09 ---
OPEN SOURCE AI DEFINITION
Online public townhall
Feb 9, 2024

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

The objective for 2024

Open Source AI Deﬁnition
version 1.0

Deﬁnition of AI system

Preamble
Out of scope issues
4 freedoms
License checklist

What is Open Source AI
To be Open Source, an AI system needs to be available under
legal terms that grant the freedoms to:
● Use the system for any purpose and without having to ask
for permission.
● Study how the system works and inspect its components.
● Modify the system to change its recommendations,
predictions or decisions to adapt to your needs.
● Share the system with or without modiﬁcations, for any
purpose.

What is the preferred form to make
modiﬁcations to an AI system?

Getting the speciﬁcations
AI systems

As deﬁned by the
OECD.

List of
components

Legal
frameworks

Legal
documents

Checklist

What elements are
necessary to:
- use
- study
- modify
- share
an AI system?

For each artifact,
evaluate which
laws apply. Some
will be under
“Intellectual
Property” regimes,
some will be under
other regimes.

We’ll match the
components and
the identiﬁed legal
frameworks with
the terms of the
legal documents
already in use,
where available.

After repeating
this exercise
enough times,
we’ll be able to
generalize the
outcomes and
write the specs to
evaluate the
freedoms granted.

Report from the working groups
Analyzing Llama2 and Pythia

8

Participants (Llama2 WG)
●
●
●
●
●
●
●
●

✔ Stefano Maffulli -- Open Source Initiative (convener)
✔ Mer Joyce -- Do Big Good (facilitator)

✔ Bastien Guerry -- DINUM, French public

administration
✔ Ezequiel Lanza -- Intel
✔ Roman Shaposhnik -- Apache Software Foundation
✔ Davide Testuggine -- Meta
✔ Jonathan Torres -- Meta
Stefano Zacchiroli -- Polytechnic Institute of Paris

✔ = attended
All members participating in a personal capacity.

9

Participants (Pythia wg)
●
●
●
●
●
●

Stefano Maffulli -- Open Source Initiative (convener)
Seo-Young Isabelle Hwang (Samsung)
Cailean Osborne (Researcher, Linux Foundation)
Stella Biderman (Eleuther AI)
Justin Colannino (Microsoft)
Aviya Skowron (Eleuther AI)

All members participating in a personal capacity.

10

Purpose
● Process -- OSI has been convening a global
conversation to ﬁnd the deﬁnition of open source AI for
almost two years.
● Track -- The 2024 objective scope for Track 1: System
Testing is to discover what components need to be
available in each AI system for the whole system to be
studied, used, modiﬁed, and shared. We plan to
complete this track at the latest by May.
● Working group report -- objective is to talk through
initial points of difference on what components of
Llama2, Pythia would need to be open for the whole AI
system to be studied, used, modiﬁed, and shared.
11

Framing
● Document – We’ll review the components table in the
Llama 2 specs doc and decide which exist in that AI
system, with a focus on resolving disagreement.
● Expectations – We’ll see how much of the table we get
through. (Insights on tempo and pace will be among
the learnings from this meeting.)
● Anything else? – Are there any other expectations or
framings we should put in place before we begin
working through the components table?
● Deadline - Feb 16 publish Llama2 and Pythia
12

Analysis of LLaMA2
Code All code used to parse and process
data, including:

Required to
Use?

Required
to Study?

Required to
Modify?

Data preprocessing code

SZ

SZ EL

Training code

SZ

SZ

Required to
Share?

Test code
Code used to perform inference for benchmark
tests
Validation code
Inference code

SZ
SM EL DT
SM JT SZ

SZ

SZ

SZ

SZ

Evaluation code
Other libraries or code artifacts that are part of
the system, such as tokenizers and
hyperparameter search code, if used.

BG,EL, SM,
SZ

SZ

13

Analysis of LLaMA2

Data All data sets, including:
Training data sets

Required to
Use?

Required
to Study?

Required to
Modify?

SZ

SZ

Testing data sets

SZ

Validation data sets

SZ

Required to
Share?

Benchmarking data sets
Data card
Evaluation data
Evaluation metrics and results
All other data documentation

SZ

SZ

14

Analysis of LLaMA2
Model All model elements, including:

Required to
Use?

Model architecture
Model parameters

SM, SZ, JT

Model card

EL

Required to
Study?

Required to Modify? Require
d to
Share?

SZ

SZ

SZ

SZ

Required to
Study?

Required to Modify? Require
d to
Share?

SZ

Sample model outputs
Other Any other documentation or tools produced or
used, including:

Required to
Use?

Research paper
Usage documentation

SZ

Technical report
Supporting tools

15

Analysis of Pythia
Code All code used to parse and process
data, including:

Required to
Use?

Required
to Study?

Required to
Modify?

Required to
Share?

Data preprocessing code

SH

SB SH CO

SB SH CO

SH

Training code

SH

SB SH CO

SB SH CO

SH

Test code

SH

SB SH CO

Code used to perform inference for benchmark
tests

SB SH CO

Validation code

SB SH CO

Inference code

SB SH

Evaluation code
Other libraries or code artifacts that are part of
the system, such as tokenizers and
hyperparameter search code, if used.

SH

SH

SH

SB SH CO
SB CO

SB SH CO

SB CO

16

Analysis of Pythia

Data All data sets, including:

Required to
Use?

Required
to Study?

Training data sets

SH

SB SH CO

Testing data sets

SH

SB SH CO

Validation data sets

SB SH CO

Benchmarking data sets

SB SH CO

Data card

SB SH ?

Evaluation data

SB SH CO

Evaluation metrics and results

SB SH CO

All other data documentation

SB SH CO

Required to
Modify?

Required to
Share?

17

Analysis of Pythia
Model All model elements, including:

Required to
Use?

Required to
Study?

Required to Modify? Require
d to
Share?

Model architecture

SB SH CO

SB SH CO

SB SH CO

SB SH
CO

Model parameters

SB SH CO

SB SH CO

SB SH CO

SB SH
CO

SB

SB

Model card
Sample model outputs

SH

Other Any other documentation or tools produced or
used, including:
Research paper
Usage documentation
Technical report
Supporting tools

SB

SB

18

Important questions on the forums
◦
◦
◦

The question of data
Is the OECD deﬁnition too broad?
Does the “Share” verb need clariﬁcation?

19

Next steps

20

Recruiting volunteers
- Review and validate the list of components
- Analyze other AI systems
(BLOOM, OpenCV …)

21

2024 timeline

System testing work stream
Stakeholder consultation work stream
Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7

Draft 0.0.8

Townhall +

… October
Monthly Virtual
Meetings

Release
version 1.0

OSI In-Person
Stakeholder
Meeting (date
+ place TBD)

RC1

v. 1.0

Criteria for RC1 and v. 1.0
RC1

version 1

- Expected outcome of
in-person meeting end
May/early June!
- The draft is completed
in all its parts
- The draft is supported
by at least 2
representatives for
each of the 6
stakeholder groups

- Expected outcome of
in-person and online
meetings through the
summer/early autumn
- The draft is endorsed by at
least 5 reps for each of the
stakeholder groups
- Announced in late October

Help us ﬁnd stakeholders
System Creator

License Creator

Regulator

Licensee

End User

Subject

Makes AI system
and/or
component that
will be studied,
used, modified,
or shared
through an open
source license
(e.g., ML
researcher in
academia or
industry)

Writes or edits
the open source
license to be
applied to the AI
system or
component;
includes
compliance
(e.g., IP lawyer)

Writes or edits
rules governing
licenses and
systems (e.g.
government
policy-maker)

Seeks to study,
use modify, or
share an open
source AI
system (e.g. AI
engineer, health
researcher,
education
researcher)

Consumes a
system output,
but does not
seek to study,
use, modify, or
share the
system (e.g.,
student using a
chatbot to write
a report, artist
creating an
image)

Affected
upstream or
downstream by
a system output
without
interacting with it
intentionally;
includes
advocates for
this group (e.g.
people with loan
denied, or
content creators)

✅

✅

⚠

✅

⚠

⚠

Enough to start

Enough to start

Leads to US, EU,
Singapore, no
commitment yet

Enough to start

Which org is squarely in
this space?

ACLU, Algorithmic
Justice League

It doesn’t end with v. 1.0
We’ll need to deﬁne rules for maintenance and review of the
Deﬁnition

OSI’s immediate next steps
- more publicity to the process
- public discussion forum https://discuss.opensource.org
- bi-weekly townhalls
- more opportunities to volunteer
- update project landing page
- reach out to more stakeholders
- raise funds for 2024 meetings
- setup the board for review and approval of v. 1.0

Join the conversation
● Public forum
● Join as OSI member
○ Free or full
○ SSO with other
OSI websites

27

Draft v. 0.0.5 of the Open Source AI Deﬁnition
Open to public comments

https://opensource.org/deepdive/drafts

28

Closing

37

Debrief
● Reﬂection – How did that discussion go? Were we
able to address areas of disagreement in a
meaningful way? If so, how? If not, why not?
● Adaptation – How might we change the structure of
this meeting? How can we improve our review method
for other AI systems?
● Next Steps – How to continue to resolve
disagreements? Another synchronous meeting?
Asynchronous commenting or other method? How
would you personally like to be involved?
38

Thank you
We realize this is difficult work and we appreciate
your help and openness, both in analyzing this
system and improving the deﬁnitional process.

39


--- Subtitles for 2024-02-09 --- ###
All right.

Thanks for joining this panel meeting again.

Sorry for my voice.

This is the result of a week of conversations in Brussels in very loud environments.

I think I stressed out my vocal cords a little bit too much.

And I caught the false debug, which is not COVID.

Just a little cold.

So the purpose of these meetings is to keep the tempo and get live conversations and live

updates on the most important things that have happened in the past couple of weeks.

And let's remind everyone our principles under which we operate.

We try to have -- make sure that one person speaks at a time.

There's no crowds around Mike.

Try to make space for others.

If you tend to be quiet, speak up.

You can use the buttons to raise your hands in this meeting, but you can also type if

you prefer not to speak up.

But please give feedback.

This is the best place to have quick interactions.

Let's use them.

And I don't think we need to be stressing the fact that we want everyone to be nice.

And keep in mind, we need to keep moving.

We need to finish this process.

And if we face an obstacle, we move around it and we should be getting back to it later

rather than stop it and admiring how big and insurmountable it is.

And we need to focus on solutions.

It's a multi-stakeholder, co-design process.

It's basically pioneer work for us.

And we know there are a lot of things that don't work that can be done better.

But we need to focus on what actually works and keep on moving.

Are there anything else that we need to take care of?

All right.

Reminder.

I was wondering whether to keep this slide or not.

But I think I want to remind everyone that our objective is to have an open source AI

definition that is workable, that is good enough by the end of the year.

It's really important.

And everyone is asking, not only is asking for one, but I think that we really have this

responsibility to create, to come to an agreement, to agree on something.

And notice the version number 1.0.

It's not necessarily going to be the most perfect one.

We will always be able to fix it.

And a reminder for what we have so far.

We have a definition of AI systems in a document, version 5.05.

And we have basic preambles for the basic principles of why we need an open source AI.

And we may want to have this wording also reviewed and straight up as quickly as possible.

Because that's another question that I get asked often.

Why do we need open source AI?

Why is it important?

I refer to this preamble, but I want to make sure that we are quoting that.

The other piece is the what's Atascope?

And there has been a little bit of discussion around what is Atascope.

I encourage you to give feedback on this text, too.

Because I don't want to, you know, I want to have it finalized as quickly as possible.

I don't think that it's bad, necessarily.

But we want to have a conclusion very quickly.

Then we have the four freedoms.

There isn't much debate around this right now.

Although there are a couple of questions that I will highlight later.

And what we're working on right now that is missing is this checklist of legal documents.

And I give you an update now on this, on the work that we've been doing.

So the four freedoms as described here are at the core of the open source definition

of AI.

And we're at the stage where we need to identify what are the preferred forms to make modifications

to an AI system.

And in the process, understand what we're going to be is highlighted here.

And we're at the stage two.

We have a list of components that we have identified thanks to the work done by Linux

Foundation AI and Data Commons, Generative AI Commons Working Group.

They have provided a list of components for machine learning systems.

And we have been using that list of components to identify which of those components are

required, they are a must have, in order to be able to use a system, to study a system,

modify and share it.

And then once we have this list with these matching points, we're going to be progressing

on this, on this, on this line, on this timeline, where we're going to be checking whether the

components have or fall under which legal frameworks, whether that's exclusive rights,

exclusive rights like intellectual property, broad term, copyright, patents, secrets, or

what have you.

Or if they don't, what kind of legal frameworks they fall under.

And then we're going to be looking at the licenses as a next step.

And the licenses are legal documents, legal terms, with which they are distributed.

We're going to be identifying gaps.

And from those gaps, and from the list of legal documents, we're going to make a checklist

to evaluate the freedoms in these legal documents.

Now we started working with two groups, analyzing specifically Lama 2 and PTI as examples, two

examples of generative AI machine learning systems.

And the members of these groups are in this list, me and Mer, are almost basically observers

and facilitators of the meeting.

And we have experts of different, different capabilities.

All of these people are working for a company, one way, shape, or form.

But they're participating, not representing their company's views.

They're representing us, experts.

But of course, for transparency, we list their affiliation.

So this is the Lama Working Group and PTI Working Group.

It's a little bit smaller, but it includes people here from different parts of the world

also.

So with them, we have gone through, the process has been, we're at the point where we are

at this working group report.

They need to go through these documents.

They're going through these documents.

Let me share with you what's happening, what's happening in here.

So for, we built this table, you may have seen it in draft five that I published at

the beginning of last week.

The draft five of the definition of open source CI has this table at the bottom, in which

you can see the list of components, and then on each, on the first column.

And then there are other four columns.

Those four columns have, basically, they're going to be X marks, whether the component

on the row is required, so it's mandatory.

It must be available to use the system, to use LamaTo, or to study LamaTo, or to modify

and share it, LamaTo, so individually.

And the components are split into four categories.

There is code, and this is what happens, what are the analysis done by the experts in the

working group for LamaTo.

And it looks like, in order to, the kind of code that we need to, there is pretty much

consensus on the kind of code that needs to be available for using LamaTo is the inference

code and the libraries, such as the tokenizer and hyperparameter search code, et cetera.

So those are required to use, seem to be.

In order to study, there is a little bit less participation of this group, like only one

person so far has filled in the table.

And it looks like training code and data pre-processing code and the other libraries are required

to study and to modify.

Similarly, there is little participation, but there are some boxes in here.

Moving forward on the data front, doesn't look like any of the data is required to use

the system, but SC is the initials of StackFano Zacchiroli.

He's looked at the, he's left these comments that training data set and other data documentation

is required to study.

And similarly, testing and validation data set is required to modify the system, but

not to use and share.

And finally, on the use front, looks like there is pretty much consensus that model

parameters is necessary to use it and study, modify, and share.

And maybe usage documentation, according to StackFano Zacchiroli, is required to modify.

And moving forward, Pithia, this one working group has done a little bit more work and

it's a little more comprehensive.

You can see that in order to study the data, it looks like there is a lot of boxes checked

here, which is very interesting to see.

Some data is even necessary, according to Sarah Young, in order to run, to use the system.

It's going to be interesting to see, to have for her, the rationale behind this decision.

And on the data front, sorry, that was the code front, yeah, okay, so on the code piece.

On the data front, some data required to use, but there is a unanimity that, again, a lot

of data is required to study, which is also very interesting and needs to be investigated

further.

And when we build a model for execution and model architecture and parameters seem to

be necessary, but also modify and share.

So this work is making progress.

We are, we have scheduled two more meetings with each of these groups next week, and we're

going to drive for completing these cards by Friday, so that we can have two complete

analyses and publish them for a wider conversation on the forums.

This is going to be a very major milestone for us, and a very good, important result.

Now, the forums that we launched, we launched them, was it last week?

They already contain a lot of interesting conversations, but I wanted to highlight three

of them that I think are very crucial to have some sort of, to have a, to drive towards

a conclusion so we can release a T in three weeks, four weeks, we can release a new draft

of the definition.

And I think that the top and most important one is the conversation around data, and you

will see it on the forum.

This is one of the ones with the highest amount of comments on it, I think.

It's worth keeping an eye out in there, because I think we need to come close to a conclusion

very soon, or at least to try to understand what the consensus is, or if there is no consensus,

we need to highlight why, and what are the reasons, the main reasons for that lack of

consensus, the controversial part.

It's very crucial in there.

And the other thing, the other conversation we have ongoing is that I think is important,

it is the one on the definition of AI system, that right now we've been using the one provided

by the organization for economic cooperation and development, the OECD.

There are a couple of comments, one by Richard Fontana, but also others, that, arguing that

the definition by the OECD is too wide, and too, that covers pretty much everything.

Everything digital.

And we may want to revise it.

So I don't have a strong attachment to that definition, or any other definition, but we

need to have a definition of AI system, because the open source AI needs to refer to a system,

and not to individual components, or pieces.

We need to have a framework of reference that we can tie to.

I go back to explaining that the open source definition for software refers to programs.

And programs, even though they're not defined either, but pretty much everyone knows what

they are, the discipline, and the software, the computer science is old enough that we

know a program when we see it.

For AI, I don't think we have that luxury yet, and we need to be able, we need to be

a little bit more specific.

So if anyone knows of different, better, well understood definitions of AI systems that

we can use and reuse, so please go and make suggestions on that thread.

There is another one that is very interesting to me, at least, and there's a conversation

around the meaning of the verb share, because there is an argument being made that the sharing

needs to be clarified, that we can share the systems with the same conditions under which

we have, under the same legal conditions for which we have received it.

I, you know, it's a very quite legally type of question.

I'm not exactly sure I understand where that conversation, that question is coming from,

but I see people involved in it, and I would recommend someone looks at it and tries to

explain or tries to find a converging solution.

So what are the next steps?

And maybe, let me see, I see a question in here.

Nick, the result for Lama2 and PTA, should they be similar?

Eventually, yeah, I mean, probably they will not, because they're different people making

different evaluations.

They should be similar, because they're similar systems, similar architecture, similar things.

They should be similar, but if they don't, then that's what the process is going to be

like.

We're going to have to have a conversation once we have also Bloom, for example, the

three of them, we will have to find a way to identify the diversity and why, explain

why things are different, and drive towards a conclusion.

I think a lot of the work is going to be around explaining exactly what access means.

I'm sensing from conversations I've had with multiple people that the concept of access

to the data, access to the architecture, access to the documentation is different.

Sorry.

Sorry for that.

All right, so what are we doing next?

We started recruiting people, but we need to review this list of components and the

checklists that the two working groups on PTA and Lama2 have started, and also we started

recruiting people to analyze Bloom OpenCV, and we may even need probably will recruit

for more other systems if necessary.

But at least we want to look at OpenCV as a curiosity mostly because it's a non-generative

AI just to validate that list of components down the line.

That's for the next couple of weeks' work.

And just reminding everyone, the timeline is here.

We have draft five released in February as scheduled.

We're going to be releasing 06.

We keep on going with these virtual meetings, town halls, and work group activities, trying

to speed up things so that we can get in end of May, early June with an in-person meeting

that will eventually resolve the last controversies and issue a release candidate.

This is a very aggressive timeline.

I keep on stressing this out.

We need to keep the tempo, and that's why I'm putting so much energy into this.

Once we have the release candidate, the idea is to take it in a roadshow around the world.

We have found already three partner conferences in different ways in different parts of the

world where we can host a presentation and a review of the release candidate.

And so we get to number version one in October.

The criteria for respectively release candidate and version one is to have representatives

from each of the stakeholders to support it, and all of this information is public now

on our website.

And these are the categories of stakeholders where we would be putting logos in here as

we go.

And that's the other reminder that I want everyone to keep in mind.

It's not going to be perfect.

And the board of the OSI is already working on setting up a committee that will be looking

into the review and approval of version one when it comes out, because it's going to be

the board's purview to review and finally approve the work of the community and take

over the maintenance of this definition, because this is going to be the first version, the

first definition maintained by the OSI with a version number in it.

And yeah, we're working very hard to make sure that we have the funding to support all

of this.

So but I'm crossing fingers.

I think we're going to be okay.

And if I run out of funds, I'm going to let you know in advance.

And we got the forums.

I'm pretty excited about this.

So they're easy to sign in.

If you have already a member, log in for any of the open source initiatives, websites,

and opensource.net, it's going to work seamlessly.

If not, you can register, become a free member, or now is also a good time to sign up and

become a full member so that you can vote also at the next election that are coming

up for the board.

And we're also draft 05.

Since last time we spoke at this time, it's a new thing.

So go and look at the latest draft also.

And leave your comments on the you can leave comments directly on the draft, or you can

leave comments on the forums if they're more generic.

If it's specific for, you know, I want to change this word, I would recommend leave

the conversation on the draft.

But if it's more generic about and requires larger, more text and stuff like that, like

leave it on the forum.

And with that, I'm happy to take questions.

Victor, public link to LamaTubePT session.

No, well, actually not yet.

Not yet, because we want to leave the groups to work a little bit more, you know, in peace

and without having to be, you know, like under, what is it called?

Under, you know, like a aquarium type of thing.

We're going to make public everything as soon as the work is done.

Matt is that correct as an answer?

I cannot hear you.

Sorry.

I need to enable you.

You should be able now to unblock your mic.

And now you're muted.

You need to unmute yourself.

Thank you.

It's only been three months, three years of pandemic.

Yeah, so the groups themselves, they meet as small groups, but the membership is transparent.

And then we report out all the documentation that's being created, which is the summary

and also the tables that Stefano shared.

And that really is the report.

I think we're also planning to make the slides that the groups are working from public, which

is effectively the agenda.

So that's how we're balancing transparency and also people being able to have a meeting,

which I think also has value.

So yeah, open to any feedback.

Thank you.

you

you

you

you

you

you

you

### End of last town hall held on 2024-02-09 ###

### Start of next town hall held on 2024-02-23 ###
--- Presentation for 2024-02-23 ---
OPEN SOURCE AI DEFINITION
Online public townhall
Feb 23, 2024
last updated: Feb 22, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

The objective for 2024

Open Source AI Deﬁnition
version 1.0

3

Deﬁnition of AI system

Preamble
Out of scope issues
4 freedoms
License checklist

4

What is Open Source AI
To be Open Source, an AI system needs to be available under
legal terms that grant the freedoms to:
● Use the system for any purpose and without having to ask
for permission.
● Study how the system works and inspect its components.
● Modify the system to change its recommendations,
predictions or decisions to adapt to your needs.
● Share the system with or without modiﬁcations, for any
purpose.

5

Report from the workgroups

6

Workgroups
Llama 2
1.
2.
3.
4.
5.
6.

Bastien Guerry
DINUM, French
public administration
Ezequiel Lanza
Intel
Roman Shaposhnik
Apache Software
Foundation
Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute
of Paris

Pythia
BLOOM
1.
George C. G. Barbosa
1.
Seo-Young Isabelle
Fundação Oswaldo Cruz
Hwang Samsung
2.
Daniel Brumund GIZ
2.
Cailean Osborne
FAIR Forward - AI for all
University of Oxford,
3.
Danish Contractor
Linux Foundation
BLOOM Model Gov. WG
4.
Abdoulaye Diack
3.
Stella Biderman
Google
EleutherAI
5.
Deshni Govender GIZ
4.
Justin Colannino
FAIR Forward - AI for all
Microsoft
6.
Jaan Li University of
5.
Aviya Skowron
Tartu, Phare Health
EleutherAI
7.
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
8.
Ofentse Phuti WiMLDS
Gaborone
9.
Caleb Fianku Quao
Kwame Nkrumah
University of Science and
Technology, Kumasi

OpenCV
1.
2.
3.
4.
5.
6.
7.

8.
9.

Rahmat Akintola
Cubeseed Africa
Ignatius Ezeani
Lancaster University
Kevin Harerimana
CMU Africa
Satya Mallick
OpenCV
David Manset
ITU
Phil Nelson
OpenCV
Tlamelo Makati
WiMLDS Gaborone,
Technological
University Dublin
Minyechil Alehegn
Tefera Mizan Tepi
University
Akosua Twumasi
Ghana Health
Service

7

Recommendations summary

2/21/24

● Required
● Likely Not Required
○ Training, validation and
○ Evaluation code
testing code
○ Evaluation data
○ Inference code
○ Evaluation results
○ Model architecture
○ All other data
○ Model parameters
documentation
○ Supporting libraries and
○ Model metadata
tools
○ Model card
● Likely Required
○ Research paper
○ Data preprocessing code
○ Technical report
● Maybe Required
● Not Required
○ Datasets
○ Data card
○ Usage documentation
○ Sample model outputs

8

Methodology
○ Voting: by component (Llama 2 example) +
compilation overview
○ Emerging Results: recommendation rubric
■ Code: recommendations + detail
■ Data: recommendations + detail
■ Model: recommendations + detail
■ Other: recommendations + detail

Component voting (Llama 2 example)
Code All code used to parse and process
data, including:

Required to
Use?

Required
to Study?

Required to
Modify?

Data preprocessing code

SZ

SZ EL

Training code

SZ

SZ

Required to
Share?

Test code
Code used to perform inference for benchmark
tests
Validation code
Inference code

SZ
SM EL DT
SM JT SZ

SZ

SZ

SZ

SZ

Evaluation code
Other libraries or code artifacts that are part of
the system, such as tokenizers and
hyperparameter search code, if used.

BG,EL, SM,
SZ

SZ

(as of Feb. 9, 2024)
10

Vote compilation (overview)

As of 2/21/24 at 9:00 pm UTC

11

Recommendation rubric

*

As of 2/21/24 at 9:00 pm UTC

12

Code recommendations

As of 2/21/24 at 9:00 pm UTC

13

Code detail

As of 2/21/24 at 9:00 pm UTC

14

Data recommendations

As of 2/21/24 at 9:00 pm UTC

15

Data detail

As of 2/21/24 at 9:00 pm UTC

16

Model recommendations

As of 2/21/24 at 9:00 pm UTC

17

Model detail

As of 2/21/24 at 9:00 pm UTC

18

Other recommendations

As of 2/21/24 at 9:00 pm UTC

19

Other detail

As of 2/21/24 at 9:00 pm UTC

* Most votes come from a category titled "Other libraries
or code artifacts that are part of the system, such as
tokenizers and hyperparameter search code, if used."
20

Liesenfeld, A., Lopez, A. &
Dingemanse, M. 2023. “Opening up
ChatGPT: Tracking Openness,
Transparency, and Accountability in
Instruction-Tuned Text Generators.”
In CUI '23: Proceedings of the 5th
International Conference on
Conversational User Interfaces. July
19-21, Eindhoven. doi:
10.1145/3571884.3604316

21

Voting ends today @ 11:00pm UTC

22

Other updates

23

Focus narrowing on machine learning

● Narrowing the deﬁnitional scope from any AI
system to ML speciﬁcally
● Goal is to increase the accuracy and precision of
the deﬁnition we create
● Change will appear in version 0.0.6 this month
24

Questions from the forum
● In other words, the use of this “system”
terminology is a complication that may have the
effect of narrowing the perceived scope of what
the OSAID covers. Is the thought that the ordinary
OSD kicks in in cases where purportedly you don’t
have a “system”?
(Richard Fontana)
25

Next steps
● Final vote compilation next week
● Version 0.0.6 release early March

26

2024 timeline

System testing work stream
Stakeholder consultation work stream
Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7

Draft 0.0.8

Townhall +

… October
Monthly Virtual
Meetings

Release
version 1.0

OSI In-Person
Stakeholder
Meeting (date
+ place TBD)

RC1

v. 1.0

27

Criteria for RC1 and v. 1.0
RC1

version 1

- Expected outcome of
in-person meeting end
May/early June!
- The draft is completed
in all its parts
- The draft is supported
by at least 2
representatives for
each of the 6
stakeholder groups

- Expected outcome of
in-person and online
meetings through the
summer/early autumn
- The draft is endorsed by at
least 5 reps for each of the
stakeholder groups
- Announced in late October

28

Help us ﬁnd stakeholders
System Creator

License Creator

Regulator

Licensee

End User

Subject

Makes AI system
and/or
component that
will be studied,
used, modified,
or shared
through an open
source license
(e.g., ML
researcher in
academia or
industry)

Writes or edits
the open source
license to be
applied to the AI
system or
component;
includes
compliance
(e.g., IP lawyer)

Writes or edits
rules governing
licenses and
systems (e.g.
government
policy-maker)

Seeks to study,
use modify, or
share an open
source AI
system (e.g. AI
engineer, health
researcher,
education
researcher)

Consumes a
system output,
but does not
seek to study,
use, modify, or
share the
system (e.g.,
student using a
chatbot to write
a report, artist
creating an
image)

Affected
upstream or
downstream by
a system output
without
interacting with it
intentionally;
includes
advocates for
this group (e.g.
people with loan
denied, or
content creators)

✅

✅

⚠

✅

⚠

⚠

Enough to start

Enough to start

Leads to US, EU,
Singapore, no
commitment yet

Enough to start

Which org is squarely in
this space?

ACLU, Algorithmic
Justice League

29

It doesn’t end with v. 1.0
We’ll need to deﬁne rules for maintenance and review of the
Deﬁnition

30

Join the conversation
● Public forum
● Join as OSI member
○ Free or full
○ SSO with other
OSI websites

31

Draft v. 0.0.5 of the Open Source AI Deﬁnition
Open to public comments

https://opensource.org/deepdive/drafts

32

Q&A

33

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the
deﬁnitional process.

34


--- Subtitles for 2024-02-23 --- ###
Welcome to the fourth Town Hall. The scope of this Town Hall is to get people the chance

to interact live with the process, ask questions, and get regular updates on what's happening

and what's hot. So for the live meeting, just a few ground rules. We want to be giving space

and being nice, listening to questions, but also make sure that people can ask questions

and feel empowered to do so. But we also want to make sure that we're moving forward. We're

not getting stuck debating forever. We need to make decisions and keep on going. And let's

remind everyone that the objective for 2024 is to have a working open source AI definition.

And by working, I mean it must be something that has endorsements from different groups

and can be put in practice and allows for open source AI systems and components to exist.

It's not something that is theoretical pie in the sky. We love it, but nobody can use

it in practice. What we're working on is to have a definition that is made up of a few

pieces. We have pretty decent understanding of all the pieces in here, minus some wordsmithing

and clarifications, but the basic piece that we're still working on is the license or legal

documents checklist at the bottom. So what happens, we have clarified that what is open

source AI is basically something, it's referred to AI system. And the reason for it is that

it gives us an anchor. It gives us a way to clarify what we're talking about, what freedoms

we want to use. And it helps us run, drive the conversation around what do I need in

order to use an AI system? What am I actually using? What is it that I want to study? What

is it that I want to modify? What is it that I want to share? What kind of practical outputs

or practical elements, examples I want to get out of this freedom, out of this verb?

And so we've been running this exercise with four groups that have been split into analyzing

four systems, Lama2, Bloom, BFIA, and OpenCV. Three of them, the first three are generative

AI systems and OpenCV is non-generative. It's a computer vision program, computer vision

framework, set of libraries with different algorithms. And some of the algorithms that

OpenCV uses are neural networks and so machine learning based systems. And we wanted to see

with a little bit of differentiation, if the requirements are different for non-generative

AI systems so far. So you see the people who have volunteered to analyze the systems and

there is a lot of diversity here, geographic representation from all over the place, from

all places in the continent. There is academia represented, there are industry players, there

is civil society interest in here too, and government organizations like the ITU. You

can see a lot of diversity here. I'm really happy to see the involvement of the very wide

breadth of people volunteering their time to contribute to this effort. I kept saying

this from the beginning, this is not the effort defining something new like open source AI,

having a new definition. The Open Source Initiative is not the work of a genius in a basement

that comes out with a secret text. This is the work of a community that puts their brilliant

minds together and drives towards consensus, drives towards a shared understanding of what

open source AI means. That's what's going to make this valuable.

So the summary, so these groups have been looking at the list of components that have

been produced by a list of components, generically described in a working paper that is almost

ready for publication by the Linux Foundation AI and Data Generative AI Commons Working

Group or initiative inside the Linux Foundation AI and Data Foundation. They have produced

a list of components that they want to use as a reference for judging the projects that

are going to be hosted by the Linux Foundation. We've taken that same list of components,

we passed it to the working groups, and each of them have been looking at the list of working

groups and have been answering the question, what do I need in order to, which component

is necessary, which component is required to train, to study, or to run a system or

modify and share it? And a summary, very quick high-level view,

is what are required are the training and evaluation and testing code, there is a requirement

for inference code, model architecture, model parameters, and supporting libraries and tools.

That looks like there's pretty good consensus. And then a few other things are on the likely

required, maybe required, are data pre-processing code, data sets, and usage documentation.

And then on the right-hand side, you see what's likely not to be required.

We have asked the group to vote for each component. We compiled the votes into one document that

I will show, and we split the results. This is an example of the table that the working

group has been using as a reference. They've been filling in their initials in the cells.

For each row, there is the component, and on the column side, there is yes or no. Is

it required for using? Is it required to study, et cetera?

Then we compiled, we're compiling the exercises. It's going to be done today, completed today.

We're compiling this spreadsheet with the sum of the votes for each of the components,

and we're going to grade it with a very simple algorithm. Basically, a yes if the median

is higher than two votes, et cetera. I mean, yes, is the median higher? It's a yes. It's

lower? It's a no. Pretty simple. This is what it's going to look like, and we're going to

share this as the exercise completes today. I'm going to summarize and make it public

next week on the forums.

So, code, we can see what's required. As I mentioned, inference code is mostly likely

on the data front. This is the interesting part. A lot of the groups are leaning on the

maybe or maybe not. Maybe not. This is an important result and something that we'll

have to spend a little bit of time debating as soon as the exercise finishes. My sense

is that this is the crucial. We knew from the beginning that the conversations around

data are crucial. Some of the live interactions that I've had with people in the working group

have been along. I've been sort of describing what the highlighting, I've been highlighting

to me the fact that definitely data is often, if not always, necessary, but the level of

access is different in the mind of the practitioners. In other words, for example, during one of

the conversations with one of the working groups, one of the questions from a volunteer

was what level of depth do we want to organize or do we want to understand the verb study?

So how deep do I want to be able to study a system? Because there is a very radical

difference between studying a system because I need to write a PhD dissertation or if I

need to study and understand it enough so that I can evaluate, for example, its transparency

according to the regulation from the AI Act or a slightly different level of understanding.

What level do I need to have if I want to only understand enough so that I can modify,

retrain, improve, fine-tune a system? That, in my mind, means diving deeper with other

conversations with some of these working groups has been highlighting how the level of access

to the original dataset is also something that we need to clarify and we have an opportunity

to clarify. How much do we need the dataset in full, like all the terabytes or petabytes

of the original dataset or in some cases, some people have argued that it's enough to

have a very good detailed description of what went into the dataset, maybe a randomized

sample of the data inside the dataset. It could be sufficient to study, to modify, etc.

This is a conversation that we'll have to dive deeper in the next iteration.

The last thing that I want to say around the data issue is that a lot of the debates are

also on the availability of data in general. Many of the practitioners that I talked to

highlighted how not having access to data in general is a problem. The uncertainties

around the regulations for text and data mining and the privacy laws and the very different

implications of the copyright issues that have been raised in the United States and

other places, they're all putting obstacles and this lack of clarity is blocking a lot

of the freedoms that we want to unblock instead.

I've been discussing with the people of the Open Future in Europe and we're starting to

think about opening another separate conversation around data governance. This is something

that might happen in the very near future where the data conversation will probably

be spun off or another parallel conversation will start to talk about the availability

of data.

Moving on for the model recommendation, no surprise here, we know that we need to have

the model architecture and the model parameters and unsure about the model metadata and model

card. This is probably because there is not a lot of clarity over what those components

actually mean because the paper from the Linux Foundation is fairly new still. The communities

need more time to digest and understand what each individual component is.

The other interesting thing is the groups have many, many people have voted yes on the

supporting libraries and tools. That's because depending on how the supporting tools are

described and the Linux Foundation has described them quite well in detail, they include in

here things like hyperparameters, search code and tokenizers that most people consider necessary

in order to interact, for example, with the system.

This is the summary. This is where we are. It's interesting to see how we got very close

to the framework from the research paper on openness in AI from this group and the group

Liesenfeld and Dingelman. This is it. We're going to be ending the vote on the working

group today. We're going to wrap it up and summarize the exercise.

One thing that is quite becoming clear is that we're really focusing on machine learning

right now. This is something that we expected when we started at the very beginning of the

process that we were actually, this definition of open source AI is very close to, I mean

very close. Right now, it's being driven by machine learning. We're going to be talking

mostly about this. I'm not sure exactly how we're going to be dealing with this slight

change, but it may be necessary to clarify this in the definitional documents. I still

don't know exactly how to deal with this. Because there was a conversation months ago

and so many people have argued that what we want to have is a definition for AI in general

and not machine learning specifically. This is something that will be brought up again

and we'll have that conversation. Then there is one highlight that there is an interesting

question from the forum, very thought provoking from Richard Fontana. He's been driving the

conversation around whether we need a definition that refers to open source, I mean to AI systems

and not to its individual components. He makes a very compelling argument and I encourage

you all to check on the forum and see the debate because one of my highlighting here

is only one of the questions that Fontana raises. It is one of his latest messages.

He's talking about whether the terminology may have the effect of narrowing or interacting

in weird ways with the open source definition, the one that refers to software. My current

line of thinking is that the definition of AI system is something that we have to introduce

at the beginning because the conversation that we were having was going around in circles

because we were talking about things like, "Oh, but what do I need to exercise the freedom

to use a model?" People were thinking about data, were thinking about our components.

It was really not clear. There was no clarity in there. As soon as we introduced the concept

of AI system, then everything started to drive and to be more aligned. Now that we got into

the deeper parts of the debate, we're starting to get a much clearer understanding of what

is necessary to use and to study and run and what kind of components we're talking about.

This is being formalized by the industry groups inside the Linux Foundation. There are other

groups that are working in a similar fashion on listed components for machine learning

systems. It's becoming more clear, that whole aspect. I'm not too married to any of these

ideas. I do want to clarify and answer the question to Fontana.

I believe that every single component – now that we have identified every single component,

each of the components will have its own terms of use and terms of services. Some are going

to be software code and those will be distributed and will be available with licenses like any

other piece of software that we are very used to. Other components like model parameters,

etc., they will be covered by other law and other legal frameworks. I don't think that

there is going to be much of an interaction between the open source AI definition and

the open source software definition. There's going to be interaction, but there's going

to be a clear separation between one and the other. I don't think that there's going to

be any complication in here. We'll have the list of components and we'll have the legal

frameworks understood for each of the components. We will have a way to read and interpret each

of the individual components' legal documents that go with them. We'll be able to generally

understand the freedoms that we must have for each of the components.

One thing that is interesting, though, is that we also are going to generate – we

will need to have some sort of dependency graph. For example, a component that is like

the model parameters. The model parameters will have a dependency on maybe on the tokenizer

because otherwise you're not going to need it. So, model component, model parameter,

and tokenizer will have to come and be shipped together in order to be used. That's why we

need a definition for a system, in my mind. You cannot say the component itself is free

or an open source like the model itself because the model itself is not going to be usable

without this tokenizer, for example. That's where I think we're going to be heading

towards, this dependency graph and the bundles that are necessary in order to have an open

source AI. That's why we need a definition of a system because we need to have some way

of anchoring that conversation. But we may not need it and just reference to the graph.

We'll see where we end up with.

That's for the next step. Today, the final vote. Then, next week, early March, we're

going to be releasing a new version. We're still on time, in my mind, to get to June

with a release candidate. The criteria, to repeat, the release candidate will need to

have the support of at least two representatives for each of these stakeholder groups that

we have invited to the conversation. Version 1 will have to be supported and endorsed by

at least double as such or at least five representatives for each stakeholder group. We will be announcing

it in late October. That's the deadline.

Between the release candidate and version 1, we're planning a worldwide tour to show

the release candidate and host small workshops to iterate with other stakeholders around

the world. We're fundraising for this. Stay tuned and we'll show details probably next

week or the week after.

I think we're getting much closer to have a full list of stakeholders yet. It's always

good if you have friends or contacts that you think should be involved and should be

following this. Mostly, we're looking for end users and subject category and in some

ways also regulators, although not necessarily government employees or policy makers because

they're not going to be able to freely give feedback. But organizations that work very

closely like lobbying organizations that work very closely with policy makers, they'd be

very useful to have a read into the definition as it's being drafted so that they can help

us understand what the regulators are concerned about.

We create a definition or we come up with a definition that is not illegal out of the

gate. Let's put it that way. Either illegal or impossible to implement in many parts of

the world because it clashes with regulation.

And a reminder that we'll probably have to keep an eye on the evolution of the world

and keep an eye on the definition that we come up with so that we can adapt it in case

there are changes in the technological landscape that will force us to create either another

checklist separate. Like if we're now focusing on machine learning, maybe there's going to

be some new technology or some variation of machine learning that we require to review

the list of components. And at that point, we will have to adjust or add a new checklist

to the bottom of our definition of AI. So we will need to keep on working.

And with that, my encouragement for you is to join the conversation in the forum. We're

making an effort to start publishing weekly also a summary of the forums on our blog to

make sure that everyone has an opportunity to stay on top even though their inboxes get

full. And a reminder to everyone that on opensource.org/deepdive, you will find a link to the drafts and the

drafts themselves are – you can comment on them directly.

So with that, I'm open to opening the floor for questions and answers from you. I can

bring up your mic so you can speak up or you can type it however you want to talk.

I believe Isabel is writing a question. Let's wait for that.

In the meantime, it's very good that we're seeing these types of discussions. And I find

it particularly interesting that we're actually discussing what's the meaning of each one

of those verbs, right? What's use, what's study, what's modify, and what's share? I

see a lot of discussions there in the forum around those verbs. And in particular for

study, it really does depend on how deep it's study, what's the meaning of study. And I

was looking back here at the free software definition and I'm just going to read through

this, the freedom, what, right? So the freedom to study how the problem works and change

it so it does not – it does your computing as you wish.

So it's clear here that the idea behind this is just study how the problem works and to

modify. If you really want something deep, like to study to really understand that, it

becomes clear that you need more than just access to the code. You have to have a lot

of documentation to understand the idea behind that. And the same applies to data. You have

to have not just the data should be open, but also how the data was created. How was

it filtered? So in a way, it becomes impractical. And the open source definition and open source

software has always been pragmatic, right? That's one of the key ideas behind open source

definition. And so having a study so deep like that, perhaps it might become impractical

to actually apply that. So that's what I wanted to share here.

Yeah, that's a good point. I've been rereading the classic documents myself and realizing

that that's the spirit. It's very, very practical. The freedom to study, all the descriptions

inside the Kino Manifesto, the benefits are for scientific progress. And it talks about

the schools will not have to waste too much in order to acquire software and for teaching

and let the students understand what's happening. So there are multiple facets that are useful

to go back and read.

All right. So if there are no more questions...

Isabel.

Okay, go ahead.

Yeah, so Isabel doesn't have a question, but she actually shared exactly those discussions

around the verbs use and share. And thank you, Isabel, for sharing that.

Wonderful. Yes, thank you. So today we're going to start with publishing a forum wrap-up

on our blog. And we're going to be publishing the recording as usual and the slide deck

for this town hall. All right, everyone, thank you for joining. And we'll see you in two weeks

at a later time. So that is compatible, more compatible with the United States and West

Coast in general. And we'll keep on hammering on this. We'll have a new definition, new draft

at the next meeting. Thank you.

### End of last town hall held on 2024-02-23 ###

### Start of next town hall held on 2024-03-08 ###
--- Presentation for 2024-03-08 ---
OPEN SOURCE AI DEFINITION
Online public townhall
March 8, 2024
last updated: March 5, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

The objective for 2024

Open Source AI Deﬁnition
version 1.0

3

hackmd.io/@opensourceinitiative/osaid-0-0-5

Deﬁnition of AI system

Preamble
Out of scope issues
4 freedoms
Legal checklist

4

What is Open Source AI
To be Open Source, an AI system needs to be available
under legal terms that grant the freedoms to:
● Use the system for any purpose and without having to
ask for permission.
● Study how the system works and inspect its
components.
● Modify the system to change its recommendations,
predictions or decisions to adapt to your needs.
● Share the system with or without modiﬁcations, for
any purpose.
5

Working group recommendations

6

Systems review plan
Planned phases and where we are now:
1. ✔ Analyze a sample of “AI systems” to identify precisely the
required components for study, use modiﬁcation, and sharing of
the entire system
2. For each component of these systems, check their availability
and the conditions for use/distribution (the legal documents)
3. Generalize the ﬁndings and complete a checklist for OSI license
committee to evaluate legal documents for AI systems (OSAID
“feature complete”)
4. Get endorsements from major stakeholders (RC1)
5. Keep reﬁning the OSAID, as it gains support from more
stakeholders (v. 1.0)

7

Systems
Selected to have diversity of approaches:
1. Pythia: open science project, with a permissive license
2. BLOOM: open science project, with lots of details
released but shared with a restrictive license
3. Llama 2: commercial project, accompanied by limited
amount of science and with a restrictive license
4. OpenCV: open source project, with ML components
outside of the generative AI space
8

Members
Llama 2
1.
2.
3.
4.
5.
6.

Bastien Guerry
DINUM, French
public administration
Ezequiel Lanza
Intel
Roman Shaposhnik
Apache Software
Foundation
Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute
of Paris

Pythia
BLOOM
1.
George C. G. Barbosa
1.
Seo-Young Isabelle
Fundação Oswaldo Cruz
Hwang Samsung
2.
Daniel Brumund GIZ
2.
Cailean Osborne
FAIR Forward - AI for all
University of Oxford,
3.
Danish Contractor
Linux Foundation
BLOOM Model Gov. WG
4.
Abdoulaye Diack
3.
Stella Biderman
Google
EleutherAI
5.
Deshni Govender GIZ
4.
Justin Colannino
FAIR Forward - AI for all
Microsoft
6.
Jaan Li University of
5.
Aviya Skowron
Tartu, Phare Health
EleutherAI
7.
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
8.
Ofentse Phuti WiMLDS
Gaborone
9.
Caleb Fianku Quao
Kwame Nkrumah
University of Science and
Technology, Kumasi

OpenCV
1.
2.
3.
4.
5.
6.
7.

8.
9.

Rahmat Akintola
Cubeseed Africa
Ignatius Ezeani
Lancaster University
Kevin Harerimana
CMU Africa
Satya Mallick
OpenCV
David Manset
ITU
Phil Nelson
OpenCV
Tlamelo Makati
WiMLDS Gaborone,
Technological
University Dublin
Minyechil Alehegn
Tefera Mizan Tepi
University
Akosua Twumasi
Ghana Health
Service

9

Voting
Code All code used to parse and process
data, including:

Required to
Use?

Required
to Study?

Required to
Modify?

Data preprocessing code

SZ

SZ EL

Training code

SZ

SZ

Required to
Share?

Test code
Code used to perform inference for benchmark
tests
Validation code
Inference code

SZ
SM EL DT
SM JT SZ

SZ

SZ

SZ

SZ

Evaluation code
Other libraries or code artifacts that are part of
the system, such as tokenizers and
hyperparameter search code, if used.

BG,EL, SM,
SZ

SZ

source: Llama 2 working group (Feb. 9, 2024)
10

Vote compilation

As of 2/21/24 at 9:00 pm UTC

11

Recommendations summary
● Required
○
○
○
○
○

Training, validation &
testing code
Inference code
Model architecture
Model parameters
Supporting libraries &
tools

● Likely Required
○ Data preprocessing code
● Maybe Required
○
○
○

Datasets
Usage documentation
Research paper

2/26/24

● Likely Not Required
○
○

Model card
Evaluation code

○
○
○
○
○
○

Data card
Evaluation data
Evaluation results
Model metadata
Sample model outputs
Technical report

● Not Required

go to results spreadsheet →
12

Deﬁnition v. 0.0.6

3/7/24

● Required components ● Optional (appreciated, not required)
○
○
○
○
○
○

Data preprocessing
code
Training, validation &
testing code
Inference code
Model architecture
Model parameters
Supporting libraries &
tools

○
○
○
○
○
○
○
○
○
○
○

Datasets
Usage documentation
Research paper
Model card
Evaluation code
Data card
Evaluation data
Evaluation results
Model metadata
Sample model outputs
Technical report

13

Required Components Detail

3/7/24

●

A sufficiently detailed information on how the system was trained,
including the training methodologies and techniques, the training
data sets used, information about the provenance of those data
sets, their scope and characteristics; how the data was obtained
and selected, the labeling procedures and data cleaning
methodologies.

●

The code used for pre-processing data, the code used for training,
validation and testing.

●

The model parameters, including weights. Where applicable, these
should include checkpoints from key intermediate stages of
training as well as the ﬁnal optimizer state.

●

The supporting libraries like tokenizers and hyperparameters
search code (if used), the inference code, and model architecture.

14

Generalized text in v. 0.0.6
Precondition to exercise these freedoms
is to have access to the preferred form
to make modiﬁcations to the system.
Release date: Mar 11, 2024

15

Next steps
● Version 0.0.6 release on Monday
● Start step 2: For each system, check the availability
of required components and analyze their
conditions for use/distribution (the legal
documents)
16

What phase 2 will look like
For each AI system, build a table like:
Required component

Link to resource

Legal framework

Data pre-processing code

URL

OSI-approved license

Training, validation and testing code

URL

…

Inference code

URL

…

Supporting libraries and tools

URL

…

Model architecture

URL

…

Model parameters

URL

???
17

2024 timeline

Track 1: System testing work stream
Track 2: Stakeholder consultation work stream
Track 3: Releases

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7

Draft 0.0.8

Townhall +

… October
Monthly Virtual
Meetings

Release
version 1.0

OSI In-Person
Stakeholder
Meeting (date
+ place TBD)

RC1

v. 1.0

18

Criteria for RC1 and v. 1.0
RC1

version 1

- Expected outcome of
in-person meeting end
May/early June!
- The draft is completed
in all its parts
- The draft is supported
by at least 2
representatives for
each of the 6
stakeholder groups

- Expected outcome of
in-person and online
meetings through the
summer/early autumn
- The draft is endorsed by at
least 5 reps for each of the
stakeholder groups
- Announced in late October

19

Help us ﬁnd stakeholders
System Creator

License Creator

Regulator

Licensee

End User

Subject

Makes AI system
and/or
component that
will be studied,
used, modified,
or shared
through an open
source license
(e.g., ML
researcher in
academia or
industry)

Writes or edits
the open source
license to be
applied to the AI
system or
component;
includes
compliance
(e.g., IP lawyer)

Writes or edits
rules governing
licenses and
systems (e.g.
government
policy-maker)

Seeks to study,
use modify, or
share an open
source AI
system (e.g. AI
engineer, health
researcher,
education
researcher)

Consumes a
system output,
but does not
seek to study,
use, modify, or
share the
system (e.g.,
student using a
chatbot to write
a report, artist
creating an
image)

Affected
upstream or
downstream by
a system output
without
interacting with it
intentionally;
includes
advocates for
this group (e.g.
people with loan
denied, or
content creators)

✅

✅

⚠

✅

⚠

⚠

Enough to start

Enough to start

Leads to US, EU,
Singapore, no
commitment yet

Enough to start

Which org is squarely in
this space?

ACLU, Algorithmic
Justice League

20

It doesn’t end with v. 1.0
We’ll need to deﬁne rules for maintenance and review of the
Deﬁnition

21

Join the conversation
● discuss.opensource.org
● Public forum
● Join as OSI member
○ Free or full
○ SSO with other OSI
websites

22

Q&A

23

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the
deﬁnitional process.

24


--- Subtitles for 2024-03-08 --- ###
Yeah, let's go with it.

All right.

Okay, welcome everyone.

So you are attending the online public town hall for the open source AI definition on

March 8th, 2024.

My name is Mare Joyce.

My pronouns are she and her, and I'm the process facilitator for creating this definition as

a multi-stakeholder co-design process.

Okay, so these are community agreements.

Some of you have already seen them.

I'll go over them briefly.

So one mic, one speaker, allowing one person to speak at a time, no interrupting.

Take space, make space if you tend to speak up.

Allow space for others to speak.

If you tend not to speak, we do invite you to share.

Kindness, just remembering that the work is hard, but we don't have to be, and to just

be gentle with each other and curious.

And of course, hate speech and insults are not permitted in the spaces that we host.

Forward motion just means that we focus on what's possible and that we note obstacles

and then we route around them and move forward and come back when needed, but that we don't

let complexity stop our project from moving forward.

Solution seeking is connected to that.

So we just, we know that suggesting new ideas and options is vulnerable, but it is crucial.

And this is how we resolve those complexities that we just mentioned.

And are there any other norms that you would like to see in this meeting?

If you have any, you can type them in the chat.

I also realized that there's a transparency norm that we should add here, just to say

that this will be posted publicly, this video will be posted publicly.

Okay.

Looks like we don't have any other comments.

I will continue.

So yes, our objective for 2024 is to release version 1.0 of the open source AI definition.

And this is what the definition looks like.

We define AI system.

There is a preamble that basically makes an argument for why this definition is necessary.

There are certain out of scope issues.

The URL is up at the top.

If you'd like to see the document.

And there are the four freedoms, which I will go into in greater detail.

And then there's this license checklist, which is looking at specifically which components

of an AI system must be open in order for the system to be called open according to

this definition.

These are the freedoms.

These were coming from earlier documents in the open source movement, but were verified

and drafted specifically for this purpose by co-design workshops at the end of 2023.

So using the system for any purpose without having to ask for permission, studying how

the system works and inspecting its components, modifying the system to change its recommendations

and predictions and to adapt it to your needs and sharing the system with or without modification

for any purpose are the overarching requirements of an open source AI system.

And now what we're going to talk about is the most recent work we've been doing, which

is recommendations of working groups that have been looking at AI systems to develop

this list of required components.

So this is what we're up to with systems review, which is also called track one of our project.

We're not going too deeply into different tracks, but for those of you who have that

context, this is track one of three.

So what we have completed is that we analyzed a sample of AI systems to identify precisely

required components for study, use, modification and sharing.

And what we are going to do next is for each component of these systems, check their availability

and the conditions for use and distribution.

So legal documents and licenses, because that is the mechanism by which OSI verifies a piece

of technology is open source or not is through licenses and legal documents.

Then we will generalize the findings and complete a checklist for OSI license committee, get

endorsement from major stakeholders.

And that will be called that's release candidate one, which will proceed version 1.0, which

of course we will refine and rough dates are RC1 is June and then version 1.0 is October.

And anything to add to the slide, Stefano?

No, this to me looks complete.

It's more about if anyone has any comments so far, I mean, you can use the chat and keep

on adding comments.

Yeah.

Okay.

Sounds good.

Okay.

So these are the four systems that we developed work groups around and this is why we chose

them.

We wanted to have a diversity of approaches.

So we looked at Pythia, an open science project with a permissive license, Bloom, another

open science project with lots of details with release, but with a restrictive license.

And I'm sure all these descriptions could be, might be different for different people,

but this is how we were looking at the systems.

Lama2, obviously a commercial project with a restrictive license, OpenCV, an open source

project with ML components, but let's have generative AI.

And so these were the work group members having public membership as part of the transparency

commitment we have just so that you know, who are the people that are making these recommendations?

Cause these are particularly empowered stakeholders in determining what the components of the

definition will be.

And we did additional outreach to have a better, particularly racial and geographic representation.

So you can take a look at that later, I guess.

We do have posted on the forum, all these, this information as well.

And what the, what the members of the working groups did, this might be information that

some of you have already heard, but I'll go through it for those who are new, is that

they voted on, we took a list of components from a forthcoming paper.

Can we, can we name the paper yet Stefano?

Cause it is forthcoming.

We can name it.

Yes.

Okay.

Excellent.

Okay.

So it's called the Model Openness Framework.

It's being, it was written primarily by researchers connected to the Linux Foundation, although

with other collaborators as well, it's going to be released on ArchiveX, I think imminently,

maybe even today or tomorrow.

Anyway, they came up with this really nice generalized list of AI system components.

And so we use their list and then we created this voting system.

Do you think this component is necessary to use, study, modify, share, and then members

of the working groups with their initials.

So again, there's transparency who's saying that what is required voted.

And this is just a screenshot of a slide from the LAMA working group.

And yeah, if you have any questions, just put them in the chat.

And if I don't see them, Stefano will see them.

And then we compiled all the votes across all the working groups.

And I developed a rubric for basically picking a vote total and turning it into a recommendation

for a requirement.

And I think, do I have a zoom in on that?

I do not have a zoom in on that.

So if you look at the upper, I don't know which corner it is, upper left or right, but

you see this part of the slide, for me, it's the upper right, which says legend.

And it's basically based on the mean number of votes, something that was more than two

times the mean was an automatic yes, this is required on down to likely yes, maybe lean

no and then no for less than, okay, between I think 0.5 and zero or zero less than 0.5

and zero.

Yeah.

So you can kind of see through this color coding how each component ranked, you can

see there's a few here that are yeses, like training validation and testing code and inference

code.

And then many lean no's, for example, data set.

And then we looked at multiple different data sets.

So that was different from the model openness framework.

They just had data set, but we thought that's such an important part of the system that

we broke it out into multiple different types of data set to really get as much input as

possible on whether that should be required.

And then this is the result of the voting of that applying the rubric to the votes was

that the required elements were and are training validation and testing code, inference code,

model architecture, model parameters, which includes weights, supporting libraries and

tools which includes things like tokenizers and hyperparameter search if used.

And then down through a likely required data processing code, maybe the data sets as you

saw not likely elements like the model card, not required data card, sample model, technical

report.

And then what is new from I think some of you have been in previous meetings is that

we have for version 6.0 made this distinction.

So the required components, we took everything that was required plus likely required.

So the data pre-processing code and those are the required components.

And then everything else is optional.

So there's nothing that we're saying don't include this, but everything else is listed

as appreciated, but not required.

And I think let's see what's next.

I feel like this might be a good place to pause.

Maybe we do this.

Do you want to pause here for questions, Stefano, or do you want to go into this greater detail

about version 6.0 and then pause?

Yeah, let's wait and see if anyone has any questions so far.

We can definitely take a break.

Yeah.

So any kind of questions or thoughts on how we got here and where we are?

Okay.

Thank you.

I'm muted basically, everyone.

If anyone wants to jump, they can use voice or if you feel more comfortable, you can type.

Yeah.

And there's a raise hand function at the bottom like in Zoom as well.

Yep.

I don't see many questions.

Maybe we can just...

Obastium has a question.

Go ahead.

Yeah.

Hi.

Thanks for the summary.

I was just wondering if you had any priority in each column, like is data processing code

more important than training validation?

I guess on the left, everything is at the same level, but maybe on the right, some things

are more optional than others or is it something that has not been discussed?

Hasn't been discussed, frankly.

And yes, they're all required.

It's a yes or no.

Yeah, it's a yes or no.

Yeah, we can have a conversation about that.

Yeah.

Because...

Oh, let me just before those double questions, let me get another question from the next

person, Bastien, and come back to you.

Unless...

Is that okay?

Sure.

No problem.

Yes.

Okay.

Thanks.

All right.

Jacob?

Yeah.

You guys can hear me, right?

Correct.

Yep.

Okay, cool.

Yeah, sure.

So I guess one question I had is if some of the reasoning around decisions that were made

within these groups is available.

I'd just be curious, particularly on the datasets portion.

I guess my intuition is that if something is open source, we should be able to verify

its legality completely.

And without access to the datasets or in some way, then that may be a lot more difficult.

I'm not saying complete access to the datasets.

But some access may be worthwhile.

Go ahead, Stef.

Yeah.

I can give an argument.

So the question of legality may not be appropriate for the open source definition.

It's a separate conversation.

But I do believe, and there were conversations inside the group about that understanding

of the datasets.

And in fact, one of the reasons why you see there the required components, the data pre-processing

code is that many of the groups had debated about which of the -- what's necessary, what

level of understanding do you need to have in order to be able to feel safe about using

a model or have enough information, the transparency requirements that look like they're going

to be mandated by law anyway, at least in Europe, and other information about provenance

and assessing risk in deployments, bias calculation, and all of those things.

So the conversation went -- this is the -- it's the torn issue, access to the datasets, what

is necessary, what is required, what level of depth do you need to have access to it.

And it's something that we're probably going to keep continuing debating.

What seemed clear to me is that the original dataset, having access to it completely and

fully in a way that you can download it, et cetera, and retrain with the purpose of retraining

or rebuilding from scratch a model that you have received, it's a requirement that is

not strictly necessary.

At least there was pretty much -- pretty good agreement on that front.

>> Thank you.

And I see you have a raised hand again, Jacob.

I'm just going to go to another question, and we can come back to you.

So Shala asks -- yeah, exactly.

No, thank you.

So Shala asks, did any of the systems reviewed meet the required components?

So let me go back to the -- yeah.

So it wasn't that we were trying to evaluate whether any system had all of its components

required.

It was more of a comparison.

And no, there was no system where all the components were considered to be required.

But the ones that are required are simply the ones on this list under the lime green

required title.

And those are the ones that then we moved into this binary distinction of required and

not, which will appear in definition 0.0.6.

And feel free to raise your hand or ask a follow-up question in case I didn't ask.

Okay.

Bastien needs to go.

Okay.

Thank you for coming, Bastien.

I see -- Jacob, did you want to ask another question?

>> I want to complete the answer.

I want to add something else for Shala.

This analysis, this -- you know, the response also will come after the next phase.

We're going to be reviewing the systems and see if they have available the required components

and what conditions they're available.

What can we do with those components?

>> Okay.

Yeah, I see what you're asking, Shala.

Thank you for clarifying that, Stefano.

I see Justin is typing.

But Jacob already has his hand up.

So yes, ask your question, Jacob.

>> I should have written it down.

I apologize.

I had a thought.

It's gone now.

I'll bring it up if I remember it.

>> No problem.

No problem.

I'm going to -- let's move on to the next slide.

Because that one adds this extra information about requirements around the training method.

And then we can continue to take questions.

What do you think, Stefano?

So I think this is where you will start presenting, I think.

>> I was looking at the -- we can answer Justin.

>> Okay.

Let's do that.

>> He admitted -- no, no.

He admitted that it's outside of this.

>> Okay.

Great.

>> So this is the text that is now in the draft of -- in the draft version 6.

006.

Which is going to go live on Monday.

So it's basically completed.

And the narrative in here is to have a piece of text inside the definition of that section

of what is open source AI.

Where we describe what we actually need in order to exercise those four freedoms.

To use study, share, modify.

And that's where the text that I was talking about before, the sufficiently detailed information

of how the system was trained, and the components basically that the groups have said that they

require.

Here they are described in a more verbose way, more of a narrative rather than bullet

points talking about quoting, mentioning specifically components that are referenced in a separate

paper by -- or maintained by another organization.

So this is more about describing in a more -- in a fairly precise fashion the list of

components that require components that came out of the working group.

And here you can see, like, you need to have detailed information of how the system was

trained.

Providence of the data, the scope and characteristics.

Some of these wording also comes from the EU AI Act in terms of requirements of transparency.

So I tried to use the words included in that legislation so that thinking that it's sufficiently

-- it's been reviewed.

It's been debated.

It's been agreed upon by the -- at least by the European regulators.

And negotiated heavily.

So I'm assuming it's quite fine-tuned to represent transparency requirements in a fairly

detailed way.

So at least it's a good way to start the conversation for us.

And then in terms of code, pieces that are about the preprocessing data, the code used

for the training validation, and the supporting libraries.

And the model parameters, the weights, which should also include the checkpoints for the

intermediate stages of the training.

As well as the finalized one.

So this is what's in -- you will see on Monday on draft six as it gets published.

You want to go on to the next one?

Because this is the other thing that will be clear.

Spelled out.

Like the precondition that we need to focus on, like a very, very high-level necessary

thing, necessary feature that needs to be made available is to have the preferred form

to make modifications to the system.

And that, for machine learning, the examples that we have studied, they give us the list

of components.

This sentence here is a form to make the open source AI definition a little bit more flexible

and adaptable to other technologies should they change next year or two years from now.

At least in the short term.

Give us a little bit more flexibility.

And that's what we're going to do.

So the next step is -- the very immediate next step is to finalize the -- hit the release

button and go live with version six of the draft on Monday.

And then we're going to start the second step in track one, which is to review each of the

systems that we have already analyzed.

Maybe add some more.

I'm not against adding more at this stage.

Because we need to look at the required components that we think are necessary.

The working groups have identified as necessary.

Make a list.

And for each of the components, put the URLs, you know, where can I get them?

Where can I get it?

If it's not available, then mark it as unavailable.

And if we can get them, under what conditions?

So we're going to find out -- I can already say we know.

For Lama 2, we know that in order to download the model weights, you will have to -- you

will have to sign up on a website.

You need to give in your details.

You need to ask for permission.

And you need to sign an agreement by doing so.

And that agreement has specifications of what you can and cannot do.

And we'll log all of that information in a place.

And we'll analyze them in step three.

PTR will have different things, et cetera, et cetera.

Oh, in fact, yes.

I put together -- there is a slide with -- go ahead.

Go to the next one.

Yes.

That's the -- that's what the next table, the next working groups will do.

It's basically go through the list of required components, put the URL, and match the legal

framework.

Now, you will see that here we're talking mostly about code.

And there is one line.

So for the code parts, it's going to be easy to say that all the code made available needs

to be formally using an OSI-approved license.

And I don't think it's going to be that complicated, that part.

The model parameters instead.

That part is most likely going to raise a conversation around what legal frameworks

go around the parameters.

Those are -- there is still some, from what I hear from the legal communities, the lawyers

have diverging opinions whether parameters are copyrightable.

And if they're not copyrightable, what kind of other -- if there is any other exclusive

in property regimes or not.

And therefore, what kind of contracts -- the validity of the contracts or terms of use

and other legal tools.

Whether -- you know, which ones are better or valid, et cetera.

So it's going to spin off an interesting legal conversation.

>> Sorry.

I clicked early.

I didn't want to raise my hand before you were done.

>> No, you're good.

Go.

>> Okay.

So the first question I have, which is what I meant to ask earlier, was what constitutes

data preprocessing versus a new dataset?

Like is it -- if it's done internally to the company that is making the model, that's when

it's data preprocessing?

Or -- yeah, I guess basically how are we differentiating between those?

>> No, let me look at the paper.

The paper, it will go live later today.

And definitely on Monday.

But my memory serves me right.

The data preprocessing is the tooling that is used to do things like cleaning up, formatting

the data, and tokenizing, you know, doing the -- all the preparation work that goes

into prepare the data to be fed into -- for data ingestion, for example.

>> Right.

>> Feature engineering, you know, data, yeah, all of that code.

>> Right.

Oh, I guess there's a follow-up.

But I'll pause if you want to go to someone else.

>> What do you mean?

There's overlap?

>> Sorry, Mer, I couldn't hear you.

>> Yeah, you can -- yeah, let's -- yeah, good facilitation practice.

Let me go to Mo and then we can come back to this.

Mo says model architecture is defined in the code.

It overlaps with the training and validation and testing code.

Is model architecture really an independent component that can be analyzed individually?

Do you want to -- >> Once we can -- yeah, I think that once

we can point at the paper that so far we've been using generously through pre-preview,

we can have a better understanding of these technical overlaps, et cetera.

>> Yeah, the delineation between different components.

So yeah, part of this paper is that there's often multi-paragraph definitions of each

of these components.

So yeah, I think that's the best place to go for that.

Jacob, did you want to ask a follow-up?

>> Yeah.

So I guess then at least how I'm thinking about this data pre-processing and I will

be like be open -- I'm coming at this from an adversarial perspective intentionally because

I feel like that will be done, I guess.

And so basically my thought is if we don't have to know -- like if a third party can

do the pre-processing, not in terms of tokenization necessarily, but more of like sifting the

data and can create a new dataset that is proprietary and then you use that, that's

a way to obfuscate your data usage.

And so maybe that's not relevant here.

Maybe that goes too much into legality, but that's just sort of how I'm thinking about

it and I'm curious to hear what your response is.

>> It seems like it's covered by the first bullet.

Isn't a lot of that concern covered by the first bullet?

There's just so much documentation about data that's required?

Or what do you think, Stefano?

>> If I understand correctly, the question or the concern, it's about replicating the

dataset with different setups, different things in it.

Or different way of reorganizing, reshuffling the same -- using the pre-processing code

means that you have a way to rebuild -- it doesn't mean that you have access to the original

data.

You can -- you have a way to extrapolate, you have those transparency requirements that

make you -- that give you some sort of better understanding for how you would have to build

your own dataset for your own training if you want to do -- if you want to rebuild from

scratch or if you want to build from -- not rebuild from scratch, build from scratch something

else that looks or behaves similar to what you have received.

In other words, I don't think that the scenario that you're describing is a scenario that

necessarily is part of this conversation.

>> Gotcha.

Okay.

Let's go on and see what else comes up.

>> Yeah, because I think some of these questions can be -- yeah, can be described also in what

we're doing.

Another thing -- another of the things that we're doing next and partially I can talk

about here the roadshow that now it's not detailed here, but you can see on the timeline

we have these three tracks, the green, the white, and the light blue that we're following

in parallel.

And in June we're going to have the release candidate.

Once that release candidate happens, we'll have meetings in different parts of the world

and we're organizing them to show the release candidate to gain more visibility across different

communities and different practitioners, different stakeholders in order to get to release candidate

to version 1 in October.

During these meetings, we're going to spin off a conversation about data because there

is a strong requirement for good quality data sets and an increased amount of awareness

in the practice of building data sets that are valid, respectful, trustworthy, you know,

they are clean, they're transparent, they're fair in how -- what they represent, et cetera.

And there is very few of these.

There are very few data sets that are large enough, that are good enough -- that are good

in that term.

And what's becoming more clear to me also is that the data community hasn't been -- needs

to also -- to have these conversations.

So we're going to be partnering with organizations that are more into that data space and we're

going to be helping supporting conversations around data in parallel or, you know, as a

spin off of this project.

>> Jacob, go ahead.

>> Yeah, sorry.

Last one.

You touched on this just now, but I guess one thing that I've been thinking about a

lot is how do we -- or I guess OSI maybe -- take back the term?

Because I feel like it's been falsely attributed to systems that are pretty clearly not open

source by this definition.

And like you said, you're going to go and, you know, talk with more people and have those

meetings.

But, yeah, just curious what your thoughts are about that.

>> Yeah, this is a known issue, unfortunately.

Yes, exactly.

Having a definition helps to take back the term.

And having people, enough people who support it and are willing to say we're going to use

it.

This is what we mean when we say open source AI.

And they're going to be multiplying the idea.

You know, they're going to go -- so I'll tell you an anecdote.

I was in -- I was at a meeting last week with a lot of friends of open in general.

And there was a lot of pushback.

Common shared pushback against Meta's use of the open source AI name to identify, to

talk about Lama.

Lama2 specifically.

So it's -- many others will be joining in our effort to clarify the public what that

means.

And it's a little bit the same work that -- the same way that it happens with the open source

software.

Like lots of -- there is people -- some people still complain and say, well, but I mean something

else.

But there is always a very large pushback of supporters of the open source definition who

say, no, it's -- you may have all the opinions you want, but open source is defined by the

open source initiative.

And it's maintained by the open source initiative.

And that brings the cloud up.

Yeah, so that's a big thing.

This doesn't end with version 1.

We know that we will have -- most likely it's going to be -- it's going to have to be maintained

and improved and reviewed.

So the board of the OSI is already at work to think about the -- how we're going to be

maintaining -- we're going to be maintaining this definition.

Which is very different from what the open source definition for software is.

Right?

We're trying to have -- so someone was asking before I saw the meetings and -- oh, it was

Justin.

Yeah, we're talking about meetings, et cetera.

And how to participate.

So we're trying to have everything public.

So that no one gets surprised when at the end we come up with the definition.

We're having this sequence of town halls every two weeks at different times so that we can

accommodate multiple time zones.

We have discussions on the forums.

We do publish on the blog every week a summary of what's happening on the forums.

So there are multiple ways to get involved.

To stay aware and to give comments during this process.

We'll publish the roadshow.

Also the roadshow meetings are going to be in different parts of the world.

We have partnered with existing conferences.

In order to gather people who are already being at a place.

Already going to that place.

So we're going to be in -- at the -- well, we'll publish it next week.

Or the week after.

But I can say that we're going to touch every continent starting from June.

Starting from June until October.

So we're going to be in Africa in June.

We're going to be in September.

We're going to be in Hong Kong.

Europe, Paris, North America, Mexico.

I don't remember when.

So there's many, many opportunities to meet in person.

And we're raising also funds and disclosing this.

By the hope is that we're going to have also travel grants for people who want to participate.

And they can apply and get to some of these meetings.

So hopefully we'll be able to have a very good roadshow.

And gather a lot of support.

And if not, we're going to keep on going next year also.

Multiple opportunities.

>> Thank you, Sam, for offering to host us in Toronto.

Okay.

Yes.

And thank you for your comment, Jacob.

Okay.

Let's see what else we have in the deck.

Oh!

Q&A.

>> I haven't really started.

So yeah.

That's the end of our deck.

So we do have more time in the meeting.

If anyone else has a question.

And this would be a great time if you're someone who often doesn't ask a question in a meeting.

Please do.

We really invite you to.

And if you prefer to put it in the chat rather than to speak publicly, then that is also

most available to you.

>> All right.

Jacob, thank you for sharing the information.

You're welcome to join the forums if you're not already.

They're easy to use.

And should be smooth.

And once you're a you can become a free member of the OSI to join the forums.

It's very easy.

>> Yes.

I joined earlier this week.

I had some troubles with logging in.

But I got that fixed.

So...

>> Cheers.

>> Thank you, guys.

>> Thank you.

>> Bye.

>> See.

Just in typing.

But I'll wait.

But I can stop the recording at this point.

I think.

Okay.

So...

I'm going to stop the recording.

### End of last town hall held on 2024-03-08 ###

### Start of next town hall held on 2024-03-22 ###
--- Presentation for 2024-03-22 ---
OPEN SOURCE AI DEFINITION
Online public townhall
March 22, 2024
last updated: March 21, 2024 (SM)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

The objective for 2024

Open Source AI Deﬁnition
version 1.0

3

hackmd.io/@opensourceinitiative/osaid-0-0-5

Deﬁnition of AI system

Preamble
Out of scope issues
4 freedoms
Legal checklist

4

Deﬁnition of AI system

Preamble

Done … ish?

Out of scope issues
4 freedoms
Legal terms checklist

Working on

What is Open Source AI
An Open Source AI is an AI system made available to the public under terms that grant the freedoms to:
●
●
●
●

Use the system for any purpose and without having to ask for permission.
Study how the system works and inspect its components.
Modify the system for any purpose, including to change its output.
Share the system for others to use with or without modifications, for any purpose.

Data: transparency
requirements only

Precondition to exercise these freedoms is to have access to the preferred form to make modifications to the system. For machine learning
systems that means having public access to:
●
●
●

Data: Sufficiently detailed information on how the system was trained, including the training methodologies and techniques, the training
data sets used, information about the provenance of those data sets, their scope and characteristics; how the data was obtained and
selected, the labeling procedures and data cleaning methodologies.
Code: The code used for pre-processing data, the code used for training, validation and testing, the supporting libraries like tokenizers
and hyperparameters search code (if used), the inference code, and the model architecture.
Model: The model parameters, including weights. Where applicable, these should include checkpoints from key intermediate stages of
training as well as the final optimizer state.

We need to talk about “systems”
because openness is a combination
of availability of multiple artifacts

Alt: we talk about “open
weights” only

What phase 2 will look like
For each AI system, build a table like:
Required component

Link to resource

Legal framework

Data pre-processing code

URL

OSI-approved license

Training, validation and testing code

URL

…

Inference code

URL

…

Supporting libraries and tools

URL

…

Model architecture

URL

…

Model parameters

URL

???
7

Getting the speciﬁcations
AI systems

Active working
groups:
- Llama2
- Pythia
Setting up:
- BLOOM
- OpenCV

List of
components

Legal
frameworks

Legal
documents

Checklist

What elements are
necessary to:
- use
- study
- modify
- share
an AI system?

For each artifact,
evaluate which
laws apply. Some
will be under
“Intellectual
Property” regimes,
some will be under
other regimes.

We’ll match the
components and
the identiﬁed legal
frameworks with
the terms of the
legal documents
already in use,
where available.

After repeating
this exercise
enough times,
we’ll be able to
generalize the
outcomes and
write the specs to
evaluate the
freedoms granted.

2024 timeline

System testing work stream
Stakeholder consultation work stream
Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7

Draft 0.0.8

Townhall +

… October
Monthly Virtual
Meetings

Release
version 1.0

OSI In-Person
Stakeholder
Meeting (date
+ place TBD)

RC1

v. 1.0

What phase 2 will look like
For each AI system, build a table like:
Required component

Link to resource

Legal framework

Data pre-processing code

URL

OSI-approved license

Training, validation and testing code

URL

…

Inference code

URL

…

Supporting libraries and tools

URL

…

Model architecture

URL

…

Model parameters

URL

???
10

Deep Dive AI in-person meetings
Region

Country

City

Conference

Date

North America

United States

Pittsburgh

PyCon US

May 20 - 23

Europe

?

Africa

Nigeria

Abuja

OSCA

June 6 - 8

Latin America

Mexico

Mexico D.F.

Latam OSS

July 19 - 20

Asia Paciﬁc

Hong Kong

Hong Kong

AI_dev

August 23

North America

United States

Raleigh

All Things Open

Oct 27 - 29

May ?

Join the conversation
● discuss.opensource.org
● Public forum
● Join as OSI member
○ Free or full
○ SSO with other OSI
websites

12

Q&A

13

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the
deﬁnitional process.

14

Criteria for RC1 and v. 1.0
RC1

version 1

- Expected outcome of
in-person meeting end
May/early June!
- The draft is completed
in all its parts
- The draft is supported
by at least 2
representatives for
each of the 6
stakeholder groups

- Expected outcome of
in-person and online
meetings through the
summer/early autumn
- The draft is endorsed by at
least 5 reps for each of the
stakeholder groups
- Announced in late October

15

Help us ﬁnd stakeholders
System Creator

License Creator

Regulator

Licensee

End User

Subject

Makes AI system
and/or
component that
will be studied,
used, modified,
or shared
through an open
source license
(e.g., ML
researcher in
academia or
industry)

Writes or edits
the open source
license to be
applied to the AI
system or
component;
includes
compliance
(e.g., IP lawyer)

Writes or edits
rules governing
licenses and
systems (e.g.
government
policy-maker)

Seeks to study,
use modify, or
share an open
source AI
system (e.g. AI
engineer, health
researcher,
education
researcher)

Consumes a
system output,
but does not
seek to study,
use, modify, or
share the
system (e.g.,
student using a
chatbot to write
a report, artist
creating an
image)

Affected
upstream or
downstream by
a system output
without
interacting with it
intentionally;
includes
advocates for
this group (e.g.
people with loan
denied, or
content creators)

✅

✅

⚠

✅

⚠

⚠

Enough to start

Enough to start

Leads to US, EU,
Singapore, no
commitment yet

Enough to start

Which org is squarely in
this space?

ACLU, Algorithmic
Justice League

16


--- Subtitles for 2024-03-22 --- ###
All right, everyone, welcome to this, I don't know how many we've done of this already,

public town hall to get an update on the process to define open source AI.

As you all know, this is a long and hard process.

The agreements that we have in here, I like to remind everyone, and especially I'm fond

of the fact that we're moving forward.

We must be keep going and we must reach a conclusion.

And if we find something that is blocking the conversation, we take notes, we try to

move on, we'll get back to it later.

And we want to find a solution which is really relevant for delivering something on time

and reaching agreements.

This is what we set for our objective, and I'd like to remind this.

We want to get to a workable, usable, agreed upon definition of open source AI.

This is absolutely the goal and objective.

And I got to say that I'm getting more comfortable that we're reaching a conclusion.

And in fact, in...

Okay, got a wrong slide here.

Okay.

And my system is really slow.

Okay.

So here's the status on the structure of the definition, which many of you have already

seen.

It's made of a definition of AI system at the beginning, the preamble where we set the

rules, we set the principles, actually, the principles that we want and why we want to

have a definition, what value and what advantages we think that's going to bring to the world

or to the ecosystem in general.

We also set clear out of scope, and so the boundaries of what's in scope for a definition,

what's left out.

And finally, the four freedoms, which are the basic understanding, the most succinct

way of communicating what is an open source AI.

And below that, we're going to be...

We're working on defining the legal terms, and we'll talk about the draft six, which

was released at the beginning of the month.

And I think it is going to give us a clear understanding.

So what I want to say here is that it looks like very few comments are coming in on the

top parts of the document, like the draft, preamble, out of scope, AI system definition,

and for freedom seem to be fairly set, especially the first three.

The fourth, maybe some small details, but it looks like these parts of the document

look done.

I really encourage you all to reread also the top part.

Don't get fixated on what's working on.

The more...

I'd love to get a sense of what's happening, and if really we can consider the top parts

complete, and if they're going to be...

So that we avoid having surprises at the last minute.

Now on the legal check terms, I mean, legal terms, the checklist, let's talk about what's

in draft six, which is very, very new.

The four freedoms haven't been changed at all.

What's added in draft zero six is the statement of the precondition.

What is that you need to exercise the freedom?

What is the fact, the statement that you need access to the preferred form to make modifications

to the system?

This is a sentence that is quite well understood in the realm of software.

We know because of practice, because it's been defined in various licenses, that access

to the preferred form to make modifications to a program, software program, you need to

have access not only to the source code, but also documentation on how to rebuild it, and

the tools and scripts to build.

So you need to have the compilation, for example, the make files and other pieces.

The GPLD3, for example, has a very detailed list of what's necessary to make modifications

to the program.

Now for machine learning systems, and we focus on machine learning here because as an example

of what an AI system needs in order to have the preferred form to make modifications,

you need three things.

Well, three sets of things, three categories of things.

Let's start from the bottom.

On the model front, we need model parameters, including the weights.

And maybe in some cases, we may need checkpoints for the stages of training.

And that's for the model requirement.

Then there is software that we need.

And the software that we need is software used for pre-processing the data, the software

used for training, validation, testing, and supporting libraries for the execution, like

the tokenizers, the search code, if there are the hyperparameter search code, if there

is one.

Then we need to know how to run inference on it.

And we need to have the model architecture, which is also a piece of code, usually.

Now at the top, data, and I have highlighted it, is the sufficient detailed information

of how the system was trained.

So this is not access, being able to download the full dataset as it was used for training.

But it's enough information to understand what went, from the transparency perspective,

what went into building that dataset, how it's been trained, how it's been collected,

who collected it, the procedures for labeling, if there was any reinforcement training, human

feedback, non-human feedback, rags, what have you, all of the methodologies that went into

building that dataset.

So this is something that many people have highlighted as still an area of contention.

And I'm fully aware of the fact that data is the most controversial part of the open

source of AI in general, and open source AI specifically, even more, because there are

so many open questions.

Now this is one of the boulders that I have highlighted at the beginning.

We know that this is an issue, but we've been going around for over a year, and we can't

figure it out.

So let's move on.

Let's finish this investigation phase.

Let's get to a complete draft using these assumptions, that we don't need access to

the full dataset, and see what happens.

See what we end up with.

Once we go back, we can revisit this decision, if it really looks like we have reached a

wrong or counterintuitive or counterproductive, or maybe it's decent and good enough that

we can work with it.

Now the data transparency requirements, this is something that we will need to elaborate

on in this new phase.

But let's see, because the wording that I've used in this draft are mostly taken from the

draft of the EU, European Union's AI Act, which, and these requirements have been already

criticized for not being clear enough, or not being extensive enough.

So I'm going to be on the data front.

We are going to be working closely with Creative Commons and Open Future, rather, to elaborate

a little bit more, to understand more the issue of data, and the issue of data governance,

as this is a sophisticated and complicated topic.

And all right, so phase two, which has started, is to look at the AI systems that we have

investigated in the phase one, which are Bloom, Lama2, Pythia, OpenCV.

And I'm open to add more, but the reason for this phase is to go through the list of required

components, the ones that in the draft 06 are required to exercise the four freedoms,

find them, find the preprocessing code for Lama2, preprocessing code for Pythia, training

and validation code for OpenCV, inference code, what do we use for inference on Bloom,

and find it, check the conditions under which they're made available, which I am not calling

them licenses, because in some cases, these are not copyright, especially model parameters.

It's not clear whether they're copyrighted or not.

So licenses for everything that is code, licenses for everything that there is documentation,

but we need to find all these resources and see how they are distributed, under which

legal frameworks and legal documentation, legal contracts or terms of use, what have

you.

We need to find them, we need to document them, because once we've completed this for

at least the four systems that I have highlighted, then we're going to go into looking at the

legal documents and write analysis, legal analysis on these.

So we're going to look at the Lama license, or the Lama terms of use, the Bloom rail frameworks

for distribution, use, etc. of Bloom, etc.

We're going to look at the Apache 2 license that is used by OpenCV, if I remember correctly,

in some of the pieces of OpenCV, and see how the language of the Apache license matches

the intention and how compatible it is with the digital artifact, the model weights, the

model parameters, etc.

That will give us the...

Once we finish this, and I'm hoping, aiming to finish this towards the end of May, we

should have the complete, we should reach a complete, feature complete list of elements

for a knowledge, have enough knowledge to be able to say, "Okay, this is what we think

open source AI looks like."

It needs to come with these components, the components need to be made available with

these, need to give out these freedoms, they need to allow these things.

And most likely, it's going to be a checklist, very similar.

Well, we'll see what...

The principles are going to be very similar to what we have in the open source definition

now, most likely.

So those are the steps that we have in mind.

And in terms of timeline, I think that we are still on time.

I still think that we're going to be able to have a meeting in June.

We're still discussing at this point, we're getting a little bit too close to June to

have an in-person meeting, but I have started to think that we might have, in order to...

We might have a virtual meeting, but hold on, we're still...

There are a lot of opportunities, a lot of trips that we can take.

We may have, instead of a one big meeting, we may have multiple ones at different times

around the time of June, because there are so many events where we're really committed

to go to, and we're going to be meeting many of the stakeholders at these events in Paris,

at PyCon in Pittsburgh.

And there's a meeting in Africa also at the beginning of June.

So we might be able to distribute this stakeholder meeting and the issue of a release candidate

around the month of June, rather than one big event.

But in any case, October is still the release of version one, stable version, whatever we're

going to call it.

And we'll add all things open.

So keep that in mind.

And yeah, these are the dates that I mentioned we already have in mind, committed.

So we're thinking about this roadshow, once we have a release candidate feature complete

definition.

The idea is to go through to these events and show the other meetings in this, but these

are the main ones, the top ones with the organizers.

We're partnering with the organizers so that we can have maximum exposure and we can use

the feedback between June, late May to October.

And of course, you're more than welcome to continue to come online, like we're being

super transparent.

We have these working that are set up to do the analysis, the early drafts of the analysis,

and then publish them on the forums where we are hoping to get more comments and feed

into the machine.

So no one is really surprised at the end when the definition is announced.

Easy to use as forums powered by open source discourse.

So fun and also mobile friendly.

All right.

With that, I'm happy to get any questions if there is any.

And if not, we can continue the conversation online.

All right.

### End of last town hall held on 2024-03-22 ###

### Start of next town hall held on 2024-04-05 ###
--- Presentation for 2024-04-05 ---
OPEN SOURCE AI DEFINITION
Online public townhall
April 5, 2024
last updated: March 21, 2024 (SM)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

The objective for 2024

Open Source AI Deﬁnition
version 1.0

3

hackmd.io/@opensourceinitiative/osaid-0-0-5

Deﬁnition of AI system

Preamble
Out of scope issues
4 freedoms
Legal checklist

4

Deﬁnition of AI system

Preamble

Done … ish?

Out of scope issues
4 freedoms
Legal terms checklist

Revising draft

Open Source AI Deﬁnition v. 0.0.6
An Open Source AI is an AI system made available to the public under terms that grant the freedoms to:
●
●
●
●

Use the system for any purpose and without having to ask for permission.
Study how the system works and inspect its components.
Modify the system for any purpose, including to change its output.
Share the system for others to use with or without modiﬁcations, for any purpose.

Precondition to exercise these freedoms is to have access to the preferred form to make modiﬁcations to
the system. For machine learning systems that means having public access to:
●

●
transparency
requirements
only

●

Data: Sufficiently detailed information on how the system was trained, including the training
methodologies and techniques, the training data sets used, information about the provenance of
those data sets, their scope and characteristics; how the data was obtained and selected, the
labeling procedures and data cleaning methodologies.
Code: The code used for pre-processing data, the code used for training, validation and testing, the
supporting libraries like tokenizers and hyperparameters search code (if used), the inference code,
and the model architecture.
Model: The model parameters, including weights. Where applicable, these should include
checkpoints from key intermediate stages of training as well as the ﬁnal optimizer state.
6

System Review Workgroups

● Creating content for deﬁnition v. 0.0.7
● Release by next Friday, April 12th

7

Workgroups
Selected for diversity of approaches to AI openness:
1.

Pythia: open science project, with a permissive license

2.

BLOOM: open science project, with lots of details released but
shared with a restrictive license

3.

Llama 2: commercial project, accompanied by limited amount of
science and with a restrictive license

4.

OpenCV: open source project, with ML components outside of the
generative AI space

8

Members
Llama 2
1.
2.
3.
4.
5.
6.
7.
8.

Bastien Guerry
DINUM, French
public administration
Ezequiel Lanza
Intel
Roman Shaposhnik
Apache Software
Foundation
Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute
of Paris
Mo Zhou Debian,
Johns Hopkins
University
Victor Lu
independent
database consultant

Pythia
OpenCV
BLOOM
1.
Rahmat Akintola
1.
George C. G. Barbosa
1.
Seo-Young Isabelle
Cubeseed Africa
Fundação Oswaldo Cruz
Hwang Samsung
2.
Ignatius Ezeani
2.
Daniel Brumund GIZ
2.
Cailean
Osborne
Lancaster University
FAIR Forward - AI for all
University
of
Oxford,
3.
Kevin Harerimana
3.
Danish Contractor
CMU Africa
Linux Foundation
BLOOM Model Gov. WG
4.
Satya Mallick
4.
Abdoulaye Diack
3.
Stella Biderman
OpenCV
Google
EleutherAI
5.
David Manset
5.
Jaan Li University of
4.
Justin Colannino
ITU
Tartu, Phare Health
Microsoft
6.
Phil Nelson
6.
Jean-Pierre Lorre
5.
Hailey
Schoelkopf
OpenCV
LINAGORA,
7.
Tlamelo Makati
EleutherAI
OpenLLM-France
WiMLDS Gaborone,
7.
Ofentse Phuti WiMLDS
6.
Aviya Skowron
Technological
Gaborone
EleutherAI
University Dublin
8.
Caleb Fianku Quao
8.
Minyechil Alehegn
To achieve better global
Kwame Nkrumah
Tefera Mizan Tepi
University of Science and representation, we conducted
University
Technology, Kumasi
outreach to Black, Indigenous,
9.
Akosua Twumasi
and other People of Color,
Ghana Health
particularly women and
Service
9
individuals from the Global South.

Phase 1: Deciding Required Components
Component Voting

January 15

Vote
Compilation
Recommendation
Report
example: Llama 2

Process: From mid-January through February,
system workgroups voted on which components
should be required for a system to be deﬁned as
open. These votes were then publicly tabulated and a recommendations
report was publicly shared on the forum. The recommendations became
version 0.0.6 of the deﬁnition.

March 10

Deﬁnition
v. 0.0.6

10

Phase 2: Finetuning the Component Checklist
Deﬁnition v. 0.0.6
Checklist for Doc Review

Deﬁnition to Checklist: A
week after the v.0.0.6 release
in mid-March, we went back
the the workgroup members
to ask them to help us
ﬁnetune the requirements
checklist implied by version
0.0.6 (left).
This v 0.0.6 checklist includes
the components categorized
as required or likely required
by voting in Phase 1, plus a list
of data transparency
requirements already in force
under the EU’s AI Act.

Requirements: Open Source AI Deﬁnition 0.0.6

11

Document Review Spreadsheet

example; BLOOM review spreadsheet
To be added in version 0.0.7

12

Document Reviewers
Llama 2

BLOOM

Pythia

OpenCV

Affiliated

Affiliated

Affiliated

Affiliated

1.
2.

Davide Testuggine
Meta
Jonathan Torres
Meta

Unaffiliated
3.

4.

Stefano Zacchiroli
Polytechnic Institute
of Paris
Victor Lu independent
database consultant

1.

Danish Contractor
BLOOM Model
Governance
Workgroup

Unaffiliated
2.

Jaan Li University of
Tartu, Phare Health

1.
2.
3.

Stella Biderman
EleutherAI
Aviya Skowron
EleutherAI
Hailey Schoelkopf
EleutherAI

1.

none

Unaffiliated

2.

none

Unaffiliated
4.

Seo-Young
Isabelle Hwang
Samsung
Volunteers
needed!
Email or DM
Mer

13

Representation: Relation to Open Source AI
Stakeholder

Description

Example

1. System
Creator

Makes AI system and/or component that will be
studied, used, modiﬁed, or shared through an
open source license

ML researcher in academia or industry

2. License
Creator

Writes or edits the open source license to be
applied to the AI system or component,
includes compliance

IP lawyer

3. Regulator

Writes or edits rules governing licenses and
systems

government policy-maker

4. Licensee

Seeks to study, use modify, or share an open
source AI system

AI engineer in industry, health researcher in
academia

5. End User

Consumes a system output, but does not seek
to study, use, modify, or share the system

student using a chatbot to write a report, artist
creating an image

6. Subject

Affected upstream or downstream by a system
output without interacting with it intentionally +
advocates for this group.

photographer who ﬁnds their image in training
dataset (upstream), mortgage applicant
evaluated by a bank’s AI system (downstream)

14

Representation: Global Inclusion and Equity

15

Next Steps

16

2024 timeline

System testing work stream
Stakeholder consultation work stream
OSAID v. 0.0.7
by next Friday,
April 12th

Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Townhalls +

Townhall +

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7

PyCon
Workshop
May 17th,
Pittsburgh)

(≈

Draft 0.0.8

… October
Monthly Virtual
Meetings

Release
version 1.0

OSI In-Person
Stakeholder
Meeting (date
+ place TBD)

RC1

v. 1.0

Deep Dive AI in-person meetings
Region

Country

City

Conference

Date

North America

United States

Pittsburgh

PyCon US

May 17*

Europe

?

Africa

Nigeria

Abuja

OSCA

June 6 - 8

Latin America

Mexico

Mexico D.F.

Latam OSS

July 19 - 20

Asia Paciﬁc

Hong Kong

Hong Kong

AI_dev

August 23

North America

United States

Raleigh

All Things Open

Oct 27 - 29

*conﬁrmed

May ?

Join the conversation
● discuss.opensource.org
● Public forum
● Join as OSI member
○ Free or full
○ SSO with other OSI
websites

19

Q&A

20

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the
deﬁnitional process.

21

Criteria for RC1 and v. 1.0
RC1

version 1

- Expected outcome of
in-person meeting end
May/early June!
- The draft is completed
in all its parts
- The draft is supported
by at least 2
representatives for
each of the 6
stakeholder groups

- Expected outcome of
in-person and online
meetings through the
summer/early autumn
- The draft is endorsed by at
least 5 reps for each of the
stakeholder groups
- Announced in late October

22

Help us ﬁnd stakeholders
System Creator

License Creator

Regulator

Licensee

End User

Subject

Makes AI system
and/or
component that
will be studied,
used, modified,
or shared
through an open
source license
(e.g., ML
researcher in
academia or
industry)

Writes or edits
the open source
license to be
applied to the AI
system or
component;
includes
compliance
(e.g., IP lawyer)

Writes or edits
rules governing
licenses and
systems (e.g.
government
policy-maker)

Seeks to study,
use modify, or
share an open
source AI
system (e.g. AI
engineer, health
researcher,
education
researcher)

Consumes a
system output,
but does not
seek to study,
use, modify, or
share the
system (e.g.,
student using a
chatbot to write
a report, artist
creating an
image)

Affected
upstream or
downstream by
a system output
without
interacting with it
intentionally;
includes
advocates for
this group (e.g.
people with loan
denied, or
content creators)

✅

✅

⚠

✅

⚠

⚠

Enough to start

Enough to start

Leads to US, EU,
Singapore, no
commitment yet

Enough to start

Which org is squarely in
this space?

ACLU, Algorithmic
Justice League

23

Finetuning with Document Review
AI systems

Active
workgroups:
- Llama2
- Pythia
- BLOOM
Recruiting
reviewers
- OpenCV

List of
components

Legal
frameworks

Legal
documents

What elements are
necessary to:
- use
- study
- modify
- share
an AI system?

For each
component,
evaluate which
laws apply. Some
will be under
“Intellectual
Property” regimes,
some will be
under other
regimes.

Next, match the
components and
legal frameworks with the
terms of the
legal documents,
if they exist.

These are listed in
deﬁnition v. 0.0.6.

Finetuned

Checklist
After repeating
this exercise
through multiple
systems, we’ll be
able to generalize
the outcomes and
write the specs to
evaluate the
freedoms granted.
These will appear
in deﬁnition 0.0.7.


--- Subtitles for 2024-04-05 --- ###
I almost forgot.

All right.

Welcome, everyone.

This is our public town hall where we explain the status, where we are, and highlight the -- what happened in the past two weeks, and we talk about what's coming in the next near future.

So today Mer is going to lead the presentation.

So Mer, it's up to you.

>> Okay.

Thank you.

So I think you all know me.

I'm the process facilitator for co-designing the open source AI definition.

And I think you all have seen this, just that we have some community agreements that we use at all meetings.

One mic, one speaker is about not interrupting.

Take space, make space just says if you tend to be more quiet, we invite you to speak up.

And if you tend to speak up more easily, to give space for others to speak as well.

Kindness just reminding us to be gentle with each other because this is quite hard, but we don't have to be.

Forward motion is acknowledging that there's so many challenges and obstacles to this work.

And just that we can choose for those to stop the process.

But rather instead that if we hit a boulder, we note it and we walk around it and come back in the future as needed.

And solution seeking is similar.

It's just that it's easier to say, oh, this doesn't work, that won't work.

And it's more challenging and vulnerable to say, hey, how about this?

Could we do it this way?

But that we need that kind of, I guess, intellectual energy to make this definition a good one.

So, yeah, so this is a slide probably anyone who's been to one of these has seen before.

We're creating the version 1.0 of the open source AI definition this year.

And this is where we are now.

And these are the parts of the definition.

Defining an AI system, a preamble about the need for the definition, issues that are out of scope, definitions of the four freedoms, studies, modify and share.

And that was the first part of our co-design process at the end of last year was co-designing the specific words that we're using to define those concepts.

And that will be shared later in the presentation in case you need a refresher.

And what we're doing now is we're working on a draft of the checklist.

So what are the required components for an AI system to be considered open by according to OSI?

And that summarizes what I've just told you.

We're pretty much finished with the rest of it.

And we're working on a draft of the checklist.

I guess also if you have questions, you can share them in the chat.

And I may or may not see them, but Stefano and Nick are there to do so.

So, yeah, so this is version 0.0.6, which is the current version of the definition.

And you can see at the top the terms, use, study, modify, share, and how we're defining those.

That's not new for this version, but it's important content.

And the thing that was new with this version is that there was a lot of question, as you can all imagine,

about requiring data and what has come out.

And this version, and I'll talk about our process, is that we have transparency requirements only.

So data sets themselves are not required, but we have transparency requirements in the form of documentation requirements.

And I'll go into that.

So this is going into our process, how we've been co-designing the definition.

We've been doing it through these system review workgroups primarily.

And right now the workgroups are still active, and they're creating content for version 7 of 0.0.7,

which will be released next Friday.

And then this is a reminder of what the workgroups, the focus of them.

They're focusing on different AI systems that have varying approaches to openness, to the concept of openness.

So we have Pythia, Bloom, Lama2, and OpenCV.

And these are the members of those groups.

Part of being a member of the group is that you agree to have your name and affiliation shared publicly for the sake of the transparency of the process.

And just to also note that these groups reflected also some outreach that we did to have better global representation,

particularly of Black, Indigenous, and other people of color, women, and individuals from the global south,

because this is going to be a global standard.

So this is what we did in phase one at the beginning of the year.

In each working group, we had component voting.

So we took a list of components from the model openness framework, which is based on a paper by the Linux Foundation and others,

and we thought it was a great list of components, generalized components across multiple systems.

So we used that as our components list.

And we had members of the work groups vote with their initials as to whether they thought that each component was necessary for the system to be studied, used, modified, and shared.

So building on that foundation of the principles, which we'd already established, we used that to develop work group recommendations on whether each component should be required.

Then, in the example that was from the Lama II group, I then compiled the votes and developed a rubric that made a recommendation on the components based on the number of votes.

So we obviously could have had a system where any component that got even one vote, that would mean it was required.

We didn't do it that way.

We said, let's have a set of minimum requirements for openness.

And then the results of that, which ended up being a Likert scale, basically.

So there were components that had the most votes and would definitely be required, that might be required, then I think possibly required, unlikely to be required, not required.

And then we posted that list in the forum, that recommendations report, and then that list became version 0.0.6.

Yeah, and now this is what we're doing now. We're doing phase two, fine tuning the component list.

So we have this checklist in 0.0.6, which then I put into a slightly different format, basically adding documentation.

So documentation was listed in 0.1.6 textually.

But it wasn't in the checklist table. So I put the documentation requirements into a checklist format.

And right now the work groups are...

I hope you can't hear the pinging in the background.

My computer. Hopefully that's just me.

So now all the work groups, they have another spreadsheet they're filling out, lucky them. This is the example from Bloom.

But they're identifying what is the documentation for each of these required components.

And then is it those drop downs, those gray drop downs, I think it's allowed or

allowed, not allowed effectively.

You know, is use allowed, not allowed, studied, not allowed, not allowed, modification, sharing for each component.

And then for 0.0.7, we're also seeking to fill in these blanks, which are in red.

So what would be the legal framework for model parameters, including weights, and what would be the legal framework for all these forms of documentation.

Stefano, do you want to jump in at any, add anything?

No, you're covering all of it.

Okay, sounds good. I'll continue then.

So, yeah, so these are the document reviewers.

Again, we said if you want to be a document reviewer, you need to share your name and affiliation.

And here we wanted to be sure that there was at least one unaffiliated reviewer.

People that are affiliated are creators or advisors of the systems under review.

And they have the most technical knowledge.

And yet also have obviously their own set of preferences around how a system might be reviewed.

So we also have unaffiliated reviewers.

And we are looking good for Lama 2 Bloom and Pythia.

We don't have anyone for OpenCV. So it's possible that OpenCV simply won't be reviewed in this phase, which would be sad.

But we would love for someone to do it.

We've asked on the forum, don't have any takers yet.

But so this is a formal call.

If you would like to volunteer, chat or message me on the forum, or we would love for this review to happen.

But so far we don't have anyone to do it.

And yes, talking about representation.

So we have two ways of looking at representation.

The first way is the way that I was talking about of around identity, not specifically related to open AI.

But then the second way we have of looking at representation is relation to open source AI.

And so we have six stakeholder groups, system creator, license creator, regulator, licensee, end user and subject.

And you can see those descriptions and examples.

And right now, the people most involved in this phase are system and license creators and licensees who tend to have that ability to analyze license documents.

Other individuals are welcome.

And of course, everyone falls into six subjects.

So if you're thinking, oh, I don't fit into any other group, trust me, you fall into six subjects of AI.

So, yes, we welcome everyone to join.

And there will be as we get out of the more technical aspects of the review, it will be easier for people without that technical knowledge to participate.

Although they are invited at any point to be involved.

And then this is just, again, the way that we're ensuring global inclusion and equity with phrases like this.

You know, black, indigenous, Latina and other people of color, women, queer, transgender, non-binary people, people with disabilities, poor and working class backgrounds are encouraged to respond.

So just whenever we're sharing about our project, just saying we want you to be involved, even if you're not seeing people like yourself involved yet.

And I think that's the end of the slides.

Next steps.

Ah, yes.

So here we are in April.

We are going to be releasing Open 0.7 by next Friday.

Also next month there is a live workshop at PyCon in Pittsburgh, probably will be the 17th.

And that will be the review of -- I guess we'll be turning that into 0.0.8.

But it's basically going to be a live opportunity for people to be involved in the next version of the -- yeah.

The -- creating the definition.

And then we also have these meetings that we have planned.

And this purple line is the one that's been confirmed that we will be there.

But we are planning and hoping to be at these other events around the world this summer.

Do you want to say anything about that, Stefano?

>> Yeah.

If you go back to the previous slide, there is one thing that we want to highlight also.

That we're still targeting reaching release candidate in June.

Which means that the workshop at PyCon is going to be very crucial to -- because it's going to be probably the last draft before we go to release candidate.

It's going to be very close.

Or we're hoping to be -- to have it in shape to be close to a future complete, actually.

It should be future complete by May.

And cleaned up at a meeting in June.

We've been hoping to hold one in person.

But we're thinking at the moment, because of opportunities and because of time crunch, it might be an online meeting of a couple of hours.

So we're going to be reaching out to the crucial stakeholders that we want invited.

And you're welcome to also candidate yourself if you think you may want to join this in June.

Just reach out to both me and Mer.

We'll be looping you in.

>> Okay.

Sounds good.

So this is just a reminder that we do have this forum.

I think everyone here knows that because they probably joined this meeting based on the forum post.

But this is our main mechanism of public transparency is the forum.

Obviously not everyone can attend these town halls.

So please do join.

And that's at discuss.opensource.org.

And now we have Q&A.

So thank you.

>> Yeah, thanks, Mer.

Does anyone have any curiosity or question or ideas?

Have you reviewed the draft?

You left the comments on the draft already.

>> Yes.

Can you share the link to the draft just because I'm sharing my screen?

>> Of course.

You can comment directly on the HackMD website.

Or there are dedicated -- there is a dedicated topic on the forum that I just linked.

It's pinned at the top.

You can comment generally on the proposal, see what others have been saying already in general on the draft.

>> Yeah.

And feel free to chat or raise your hands.

Whatever you prefer.

>> There is -- so on the call for volunteers to review OpenCV, I also want to say that this is a pretty simple task.

It doesn't require specific knowledge of AI in general.

Of all the systems, I think OpenCV should have pretty much everything available under free and open source license.

It should be fairly easy to go through the list of components.

There are only eight or ten.

And try to find them basically in the OpenCV repository.

So it should be fairly easy.

And in time, it's a great way to get familiar with the process and what we're doing.

And be listed as a contributor, of course.

Because we'll be giving recognition.

>> So I may be able to jump in on this one.

I will talk to Mary next week and see if this is an option.

>> I will give you the time and the knowledge to do that.

>> That would be great.

Yeah, thanks, Ofer.

And Ricardo is just commenting, this is great.

And saying that he learned about the model openness framework recently.

Yeah, it was only just published on ArchiveX.

The model openness framework.

>> It's pretty new.

>> We only work on this for a few months.

A couple of months, maybe.

>> All right.

If there are no more questions, then I think we can close it here.

Thanks, everyone, for joining and listening in.

We'll be here back again in two weeks at a different time.

More compatible with the eastern side of the world.

But, you know, keep track of the process and keep leaving your comments.

We're going to see you soon.

>> Yeah, thanks, everyone.

### End of last town hall held on 2024-04-05 ###

### Start of next town hall held on 2024-04-19 ###
--- Presentation for 2024-04-19 ---
OPEN SOURCE AI DEFINITION
Online public townhall
April 19, 2024
last updated: April 18, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

OSI’s objective for 2024

Open Source AI Definition

3
3

Open Source AI Definition

Where Are We Now?

4

Open
Source AI
Definition
Elements

Preamble
Out of Scope Issues
4 Freedoms

v.0.0.7

Legal Checklist

-

Scan me!

Open
Source AI
Definition
Elements

Preamble
Out of Scope Issues
4 Freedoms

Done … ish?

v.0.0.7

Legal Checklist

Revising
draft

Open Source AI Definition

The Co-Design Process
Fall 2023: The 4 Freedoms
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

7

The 4 Freedoms for AI
Use • Study • Modify • Share

What should these
open source principles mean
for artificial intelligence?

8

Co-Design Workshop: Raleigh
All Things Open | October 2023

9

Co-Design Workshop: Monterey
Linux Foundation Member Summit | October 2023

10

Co-Design Workshop: Addis Ababa
Digital Public Goods Alliance Members Meeting | November 2023

11

Open Source AI Definition
The 4 Freedoms for AI
1. Use the system for any purpose and without having
to ask for permission.
2. Study how the system works and inspect its
components.
3. Modify the system for any purpose, including to
change its output.
4. Share the system for others to use with or without
modifications, for any purpose.
12

Open Source AI Definition

The Co-Design Process
Winter 2023-24: Required Components
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

13

Required Components for Open Source AI

What components must be
open in order for an AI system
to be used, studied, modified,
and shared?

14

Co-Design Workshop: San Jose
AI.dev | December 2023

15

Virtual Workgroups
Selected to represent a diversity of approaches to AI openness:
1.

Llama 2: commercial project, accompanied by limited amount of
science and with a restrictive license

2.

BLOOM: open science project, with lots of details released but
shared with a restrictive license

3.

Pythia: open science project, with a permissive license

4.

OpenCV: open source project, with ML components outside of the
generative AI space

16

better global representation, we conducted outreach to Black, Indigenous,
Workgroup Members Toandachieve
other people of color, particularly women and individuals from the Global South.

Llama 2
1.
2.
3.
4.
5.
6.
7.
8.

Bastien Guerry
DINUM, French public
administration
Ezequiel Lanza Intel
Roman Shaposhnik
Apache Software
Foundation
Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute of
Paris
Mo Zhou Debian,
Johns Hopkins
University
Victor Lu independent
database consultant

BLOOM
1.
2.
3.
4.
5.
6.
7.
8.

George C. G. Barbosa
Fundação Oswaldo Cruz
Daniel Brumund GIZ
FAIR Forward - AI for all
Danish Contractor
BLOOM Model Gov. WG
Abdoulaye Diack
Google
Jaan Li University of
Tartu, Phare Health
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
Ofentse Phuti WiMLDS
Gaborone
Caleb Fianku Quao
Kwame Nkrumah
University of Science and
Technology, Kumasi

Pythia
1.
2.

3.
4.

Seo-Young Isabelle
Hwang Samsung
Cailean Osborne
University of Oxford,
Linux Foundation
Stella Biderman
EleutherAI
Justin Colannino
Microsoft

5.

Hailey Schoelkopf
EleutherAI

6.

Aviya Skowron
EleutherAI

Over 50% of all
workgroup
participants are
people of color.

OpenCV
1.
2.
3.
4.
5.
6.
7.

8.
9.
10.

Rahmat Akintola
Cubeseed Africa
Ignatius Ezeani
Lancaster University
Kevin Harerimana CMU
Africa
Satya Mallick OpenCV
David Manset ITU
Phil Nelson
OpenCV
Tlamelo Makati
WiMLDS Gaborone,
Technological University
Dublin
Minyechil Alehegn
Tefera Mizan Tepi
University
Akosua Twumasi
Ghana Health Service
Rasim Sen Oasis
Software Technology Ltd.

Workgroups: Required Component Selection
Component List

18

Available on arXiv
CC BY-NC-SA 4.0

Workgroups: Required Component Selection
Component
List
Component Votes

19

Example:
Llama 2
Workgroup

Workgroups: Required Component Selection
Component
List

Component
Votes
Vote Compilation

20

Workgroups: Required Component Selection
Component
List

Component
Votes
Vote
Compilation
Recommendation Report

21

v.0.0.6

Workgroups: Required Component Selection
Component
List

Component
Votes
Vote
Compilation

Recommendation
Report
Definition
Checklist

22

v.0.0.6

Open Source AI Definition v.0.0.7
Required Components

23

Open Source AI Definition v.0.0.7
Required Components: Legal Frameworks

24

Open Source AI Definition v.0.0.7
Required Components: Legal Frameworks

25

Open Source AI Definition

The Co-Design Process
Representation, Inclusion, and Equity
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

26

Equitable and inclusive stakeholder
representation isn’t only about for
justice, it’s about legitimacy.

A global definition requires
global consultation.
27

Stakeholder

Description

Example

1. System
Creator

Makes AI system and/or component that will be
studied, used, modified, or shared through an open
source license

ML researcher in academia or industry

2. License
Creator

Writes or edits the open source license to be applied
to the AI system or component, includes compliance

IP lawyer

3. Regulator

Writes or edits rules governing licenses and systems

government policy-maker

4. Licensee

Seeks to study, use modify, or share an open source
AI system

AI engineer in industry, health researcher in
academia

5. End User

Consumes a system output, but does not seek to
study, use, modify, or share the system

student using a chatbot to write a report, artist
creating an image

6. Subject

Affected upstream or downstream by a system output
without interacting with it intentionally + advocates for
this group.

photographer who finds their image in training
28
dataset (upstream), mortgage applicant
evaluated
by a bank’s AI system (downstream)

28

Stakeholder

Most
involved
in current
phase

Description

Example

1. System
Creator

Makes AI system and/or component that will be
studied, used, modified, or shared through an open
source license

ML researcher in academia or industry

2. License
Creator

Writes or edits the open source license to be applied
to the AI system or component, includes compliance

IP lawyer

3. Regulator

Writes or edits rules governing licenses and systems

government policy-maker

4. Licensee

Seeks to study, use modify, or share an open source
AI system

AI engineer in industry, health researcher in
academia

5. End User

Consumes a system output, but does not seek to
study, use, modify, or share the system

student using a chatbot to write a report, artist
creating an image

6. Subject

Affected upstream or downstream by a system output
without interacting with it intentionally + advocates for
this group.

photographer who finds their image in training
29
dataset (upstream), mortgage applicant
evaluated
by a bank’s AI system (downstream)

29

30

Open Source AI Definition

The Co-Design Process
Next Steps
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

31

System testing work stream
Stakeholder consultation work stream

2024 Timeline
OSAID v. 0.0.7
last Friday, April
12th

Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Townhalls +

Townhall +

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7

PyCon
Workshop
May 17th,
Pittsburgh)

(≈

Draft 0.0.8

… October
Monthly Virtual
Meetings

Release stable
version

OSI In-Person
Stakeholder
Meeting (date
+ place TBD)

RC1

Stable
Version

In-Person Meetings
Region

Country

City

Conference

Date

North America

United States

Pittsburgh

PyCon US

May 17

Europe

France

Paris

OW2

June

Africa

Nigeria

Lagos

Sustain Africa

June

North America

United States

New York

OSPOs for Good

July 9 - 11

Asia Paciﬁc

China

Hong Kong

AI_dev

August 23

Latin America

Argentina

Buenos Aires

Nerdearla

September

Europe

France

Paris

(data governance)

September

North America

United States

Raleigh

All Things Open

Oct 27 - 29

33

Open Source AI Definition
Stay Connected
●
●

●

Public forum: discuss.opensource.org
Become an OSI Member
○ Free or or full
○ SSO with other OSI websites
Biweekly virtual town halls
34

Q&A

35

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the
deﬁnitional process.

36


--- Subtitles for 2024-04-19 --- ###
Good.

Let's get started.

Thanks everyone for joining this public town hall.

I don't even remember the fifth in the series,

but there's been a while we've tried to be transparent

about the process and what's happening

and give a very quick overview

of what's been happening in the past few months

and look at the latest draft

and have a quick glance at what's coming next

because we're really approaching the last months,

actually the last weeks of the drafting process.

We really are getting close to something that is workable.

Let's start with our community agreements

to remind everyone that we are welcoming a place,

we're also trying to balance with moving forward

and finding converging towards a solution,

leaving the largest building blocking paths,

elements for something that can be fixed in the future.

And we are aiming quickly towards having a definition

for open source AI by the end of the year.

So where do we stand now?

Remember, this is a reminder of what we've been working on.

We have a preamble that sets the objective

of why we're doing this, what are the objectives,

what are the reasons why we want to have a clear definition

of open source AI, why that's necessary.

And we want to also clarify what we think needs to be fixed

and we need to be addressed the issues that AI creates

are to be resolved at a different level,

at the government level, governance level,

deployment levels, and not inside the documents

that are used to distribute and make AI systems available.

Then we have worked quite heavily to define the freedoms,

to define exactly what is open source AI in practice,

what are the identifying elements of when we see it,

we will know that that system is an open source AI.

This top part, before what we call the legal checklist,

this top part is the most important piece

and the most urgent piece that we need to get right

and we need to get it right quickly.

What follows below is the space,

is what we are reviewing and revising at this stage.

The top part looks fairly stable

and I really urge everyone to look at it,

to give it a very solid, deep read,

to see, to highlight possible mistakes,

possible areas of improvement,

because we really need to put this to bed

as quickly as possible.

And since no one has been giving a lot of comments to this

in the past couple of iterations,

I'd love to tell everyone, to remind everyone

that this is very important that we complete the process

and this top part is really, really, really the top,

the most important one.

What comes below is the,

what comes below the legal checklist is,

basically, an operation manual,

or at least recommendations and the initial recommendations

for operators of the,

for the people who would be reviewing AI systems

and evaluate whether they satisfy the definition

about what is open source AI.

And because these are strongly targeting,

this checklist is strongly targeting

machine learning systems,

because those are the systems that introduce new elements

and pose more challenges at the moment.

In the future, it may be different,

but at the moment, machine learning is what is creating

this uncertainties around what is open source,

rather than other systems.

And the main reason is because the AI systems require data

and they produce, machine learning systems require data

and they produce model weights.

And these two elements are fairly new in the software world.

And we haven't really been thinking about how they interact

with the open source definition.

This whole exercise of finding the open source AI definition

revolves around these disruption, if you want,

this disturbance in the understanding

of what open source means.

And that's what we are analyzing.

This checklist is the piece that we are using

to evaluate whether a system is open source or not,

the response to the open source definition for AI or not.

So what we've been doing, we started in the fall

and we found these principles with co-design workshops

that we run in multiple parts of the world,

like in October in Raleigh, North Carolina,

then we went to Monterey.

We went to Alisabeba with the United Nations

Digital Public Goods Alliance to run another workshop.

And the result of these conversations,

also we had conversations online,

came out, produced this Four Freedoms for AI,

which is basically the four freedom for free software,

adapted and reviewed and purposed for AI systems,

thinking about the definition of AI system.

Then we focused on understanding the required components

that one needs to have for a machine learning system

in order to exercise those freedoms.

So what do you actually need in order to have access

to these systems?

So we had, again, more workshops in person in San Jose,

and then we run virtual work groups online

to analyze four specific systems,

Lama2, Bloom, PTI, and OpenCV.

And you will see a variety of elements in here.

You see Lama2, it's a commercial project

and distributed with legal terms

that include restrictions,

and the Open Source Initiative has already called Lama2

not an open source system.

But it's relevant to have the analysis.

We looked at Bloom because it's an open science project.

It's very open in terms of it distributes

a lot of its components,

and it's very complete from the science perspective.

Also, we know that it's been shared with our license

and with legal terms that prevent some uses.

PTI is another open science project,

and it's very permissive.

And OpenCV is similarly an open source project

with lots of openness and lots of open components

made available, but it's non-generative.

So it's a computer vision, machine learning,

machine learning system.

So adding a little bit of variety.

We asked for volunteers and we reached out to volunteers

to have the most, the widest possible diversity

in different levels and different stages.

We invited experts from like the developers

and technical experts of each of these groups.

And we included others.

Like we invited Davide Testugine and Jonathan Torres

from Meta into the LAMA working group explicitly

because they are experts.

And if someone couldn't find a component,

we could ask the experts to go look for them

and to tell us whether those were available or not.

And that's the reason why they're here together with,

for example, Stella Biderman from PTI.

And we worked also, we aligned our work.

We started with the model openness framework

that is produced by Matt White, Ibrahim, Adad

and others from the Linux Foundation and other researchers

who they have analyzed machine learning

and they grouped the required, the components

that go into producing, distributing a system.

And we based on that list of components,

we asked the volunteers in the working groups

to go look and see which of these components

you think is required to study,

which one is required to use the system,

which one is required to share and modify.

And they voted for each of these components.

Then we composed and weighted all those results,

all those votes.

And we came up with a recommendation summary

of what is required and what is less necessary

or gathered less votes from the working groups.

And that has produced the latest,

no, that has produced a list of components

for which we needed to go look at the legal documents.

So we had the required components,

we grouped them into three main areas for code,

for what we call model, and then for data

because the votes didn't reach a very high threshold

for the votes of the working groups

didn't reach a very high threshold

to require the original training dataset.

And because of other practical considerations,

we substituted the information,

we built a proxy for the access,

having access to the original training dataset.

We replaced it with requirements for data transparency.

Like we wanna have the maximum amount

of transparency on the data.

And we wanna have also the tools

instead of the actual dataset,

the tools to build compatible data datasets.

So we want to have the code

that went into building that dataset as an alternative.

And now with that list of the required components,

we went and looked at the legal frameworks

for each of these components.

And we ended up with having basically everything

we discovered basically that everything,

all the required components,

they fall under copyright quite clearly

except one of the components.

So everything that is code,

so in this slide, you can see everything

that is in the pre-training, I mean, the code section,

in the data transparency section,

that's documentation basically.

And in model architecture,

those are all distributed as code

that is written by a human,

falls squarely under copyright

and maybe patent law eventually.

But it's something that we are very familiar with.

It's an environment that we understand very well.

It's an environment where we have, it's a legal framework.

These are legal frameworks for which we have licenses

and clear understanding of what those means.

But for the model parameters,

and these include, for example,

the weights and the biases.

For model parameters, we don't have a universal understanding

around the world of what these fall under,

what kind of laws they fall under.

So we have to be a bit more careful evaluating

what are the terms that we want to apply here

and how we want to have,

evaluate the legal terms

under which model parameters are distributed.

So I mentioned that we worked a lot

to get global representation in this process,

because ultimately we want,

we have engaged with,

we have identified these groups of stakeholders,

like system creator, license creators, regulators,

licensees, end users, and subject.

And we have tried to engage with as many as possible.

With the most involved ones in the current phase

have been the licensees and system creators

and license creators,

so lawyers and integrators and developers.

And we are expanding our reach now at this stage

to end users, subjects, and regulators.

And as a proxy for regulators,

we're gonna be engaging with civil society

who talks to regulators, lawmakers around the world.

And so we have closed that phase,

so we have now the next steps,

what's happening in the next steps.

We're getting ready to release the next draft, draft 08.

I'm actually at a conference this week

where I gathered a lot of feedback

and may be able to release at 08 before May,

and maybe go into Pittsburgh at the PyCon

with an even higher version number,

even more clearly towards a release candidate with a 0.1.

So skipping that level

and going into minor release numbering.

And like a feature complete,

but with close to be a release candidate in June.

Between in June, we'll hold in-person or online.

This is getting into a territory

where we'd love to have it in person,

but we also would love to have different people

from different parts of the world.

And so it's probably most likely gonna be online

instead of in-person, but we'll see what happens.

In any case, in June, we wanna have a group

of important relevant stakeholders

who have been involved into the drafting process

to meet and release the release candidate number one.

And during the summer months between July

and the end of October,

we have a plan to go through a worldwide roadshow

to demonstrate, to illustrate, to advocate for,

and gather in different parts of the world

and gather more sustained to support

and endorsement from different groups and organizations

so that at the end of the October in Raleigh

at All Things Open,

the OSI board can review the draft with the comments

and release the stable version at the end of the month.

And this is our plan.

I think we're getting very close to the finish line

and it's really exciting.

If you haven't been involved until now,

I really, really, really, really encourage you

to go to the online forums

where we have healthy, deep conversations.

Keep coming to these down-home meetings,

ask questions, and stay engaged

because we are making history right now.

We are writing a definition that we hope will remove,

that we want people to use to remove uncertainties

and doubts from the market.

People are releasing more models.

They're using the open source moniker.

They are confusing regulators

and legislators around the world.

And we need to provide certainties.

We need to provide a stable view

of what open source AI means

so that regulation can come in

and encourage innovation without causing harm,

without spreading more disinformation

and providing a positive environment.

So with that, I'm gonna take a pause.

And if you have any questions, I'm happy to respond.

Any curiosities?

- Yeah, I just have a question.

So again, you may have touched based on it,

but I was not sure it was clear.

You do not touch at all on the data used for training

except getting some form of transparency.

Do I get it right?

- Yes, that is correct.

This is a, it's really,

we started to work on a frequently asked question document

because it's becoming recurrent now

as more people are becoming aware of the process.

The data issue has been,

we have debated it at the very beginning

and it's been really confusing.

It's been really, it's been going around in circles.

Like the very big issue with data

is that if we require the original dataset

to be distributed together with the model weights

and parameters and the rest of the code,

we will automatically exclude from the pool

of possible AI systems.

We will exclude systems that don't have data

where the data is not available, right?

Like federated learning,

federated learning or privacy preserving,

training mechanisms, all of those, for example,

will not be part of the open source AI ecosystem

because there is no data.

The other reason is that many times

you have the right to download, for example,

information from a website

in order to do data mining on it,

but you don't have the right to redistribute it further.

So also in these cases,

you got a model parameters

that you can definitely use.

You have instructions to rebuild that dataset,

but you cannot really have the original dataset

because it's illegal to distribute it.

And so to obviate for these issues,

it's much easier and probably also more relevant

to have access instead as a proxy to the tooling,

to the filtering and to the instructions

on how the dataset was built as a minimum.

Again, these are default requirement.

Nothing really prevents from something like

Starcoder or other systems

that have been built with open science in mind

and have been very careful.

Like Luther AI is working on the pile

to a new dataset that is more,

since they became more concerned

about the copyright status of the input,

the training datasets,

they're rebuilding the pile,

excluding all the possible sources of lawsuits

and DMCA takedowns.

So nothing excludes from building datasets

that are relevant and important

and can be distributed further,

but that would make the open source AI,

would put the, having that as a harder requirement,

would put the open source AI at a disadvantage

compared to the commercial proprietary systems

where they basically don't even disclose

the list of the data.

Yeah.

- That makes sense.

Thanks a lot.

So that's indeed very clear.

- Absolutely.

- Thank you.

- Absolutely.

All right.

If there are no more questions,

then I will close it here.

And again, please go to the forums

and there is a long thread about data

where you can see the past conversation

on this very hot topic.

And yeah, we can continue there,

or we can also move on to the other big issue,

which is defining and understanding a little bit better,

gathering more comments on the legal status

of the model parameters and understand,

get more suggestions on how we should treat them.

Thanks everyone for joining and talk to you soon.

In two weeks, we'll redo this.

Bye.

### End of last town hall held on 2024-04-19 ###

### Start of next town hall held on 2024-05-03 ###
--- Presentation for 2024-05-03 ---
OPEN SOURCE AI DEFINITION
Online public townhall
May 3, 2024
last updated: May 2, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

OSI’s objective for 2024

Open Source AI Definition

3
3

Open Source AI Definition

Where Are We Now?

4

Open
Source AI
Definition
Elements

Preamble
4 Freedoms

v.0.0.8

Legal Checklist

-

Open
Source AI
Definition
Elements

Preamble
4 Freedoms

v.0.0.8

Now feature
complete for
required and
optional
components

Legal Checklist

-

Open Source AI Definition

How Did We Get Here?

7

Open Source AI Definition

The 4 Freedoms for AI
Fall 2023
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

8

The 4 Freedoms for AI
Use • Study • Modify • Share

What should these
open source principles mean
for artificial intelligence?

9

Co-Design Workshop: Raleigh
All Things Open | October 2023

10

Co-Design Workshop: Monterey
Linux Foundation Member Summit | October 2023

11

Co-Design Workshop: Addis Ababa
Digital Public Goods Alliance Members Meeting | November 2023

12

Open Source AI Definition
The 4 Freedoms for AI
1. Use the system for any purpose and without having
to ask for permission.
2. Study how the system works and inspect its
components.
3. Modify the system for any purpose, including to
change its output.
4. Share the system for others to use with or without
modifications, for any purpose.
13

Open Source AI Definition

Required Components
Winter 2023-24
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

14

Required Components for Open Source AI

What components must be
open in order for an AI system
to be used, studied, modified,
and shared?

15

Co-Design Workshop: San Jose
AI.dev | December 2023

16

Virtual Workgroups
Selected to represent a diversity of approaches to AI openness:
1.

Llama 2: commercial project, accompanied by limited amount of
science and with a restrictive license

2.

BLOOM: open science project, with lots of details released but
shared with a restrictive license

3.

Pythia: open science project, with a permissive license

4.

OpenCV: open source project, with ML components outside of the
generative AI space

17

better global representation, we conducted outreach to Black, Indigenous,
Workgroup Members Toandachieve
other people of color, particularly women and individuals from the Global South.

Llama 2
1.
2.
3.
4.
5.
6.
7.
8.

Bastien Guerry
DINUM, French public
administration
Ezequiel Lanza Intel
Roman Shaposhnik
Apache Software
Foundation
Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute of
Paris
Mo Zhou Debian,
Johns Hopkins
University
Victor Lu independent
database consultant

BLOOM
1.
2.
3.
4.
5.
6.
7.
8.

George C. G. Barbosa
Fundação Oswaldo Cruz
Daniel Brumund GIZ
FAIR Forward - AI for all
Danish Contractor
BLOOM Model Gov. WG
Abdoulaye Diack
Google
Jaan Li University of
Tartu, Phare Health
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
Ofentse Phuti WiMLDS
Gaborone
Caleb Fianku Quao
Kwame Nkrumah
University of Science and
Technology, Kumasi

Pythia
1.
2.

3.
4.

Seo-Young Isabelle
Hwang Samsung
Cailean Osborne
University of Oxford,
Linux Foundation
Stella Biderman
EleutherAI
Justin Colannino
Microsoft

5.

Hailey Schoelkopf
EleutherAI

6.

Aviya Skowron
EleutherAI

Over 50% of all
workgroup
participants are
people of color.

OpenCV
1.
2.
3.
4.
5.
6.
7.

8.
9.
10.

Rahmat Akintola
Cubeseed Africa
Ignatius Ezeani
Lancaster University
Kevin Harerimana CMU
Africa
Satya Mallick OpenCV
David Manset ITU
Phil Nelson
OpenCV
Tlamelo Makati
WiMLDS Gaborone,
Technological University
Dublin
Minyechil Alehegn
Tefera Mizan Tepi
University
Akosua Twumasi
Ghana Health Service
Rasim Sen Oasis
Software Technology Ltd.

Workgroups: Required Component Selection
Component List

19

Available on arXiv
CC BY-NC-SA 4.0

Workgroups: Required Component Selection
Component
List
Component Votes

20

Example:
Llama 2
Workgroup

Workgroups: Required Component Selection
Component
List

Component
Votes
Vote Compilation

21

Workgroups: Required Component Selection
Component
List

Component
Votes
Vote
Compilation
Recommendation Report

22

v.0.0.6

Workgroups: Required Component Selection
Component
List

Component
Votes
Vote
Compilation

Recommendation
Report
Definition
Checklist

23

v.0.0.6

Open Source AI Definition

Legal Documents Review
Early Spring 2024
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

24

Workgroups: Legal Documents Review

25

v.0.0.6

Workgroups: Legal Documents Review

26

v.0.0.6

Workgroups: Legal Documents Review

27

v.0.0.6

Open Source AI Definition
Required Components
v.0.0.8

28

Open Source AI Definition
Optional Components
v.0.0.8

29

Open Source AI Definition

A Representative Process
Diversity, Inclusion, and Equity
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

30

Equitable and inclusive stakeholder
representation isn’t only about for
justice, it’s about legitimacy.

A global definition requires
global consultation.
31

Stakeholder

Description

Example

1. System
Creator

Makes AI system and/or component that will be
studied, used, modified, or shared through an open
source license

ML researcher in academia or industry

2. License
Creator

Writes or edits the open source license to be applied
to the AI system or component, includes compliance

IP lawyer

3. Regulator

Writes or edits rules governing licenses and systems

government policy-maker

4. Licensee

Seeks to study, use modify, or share an open source
AI system

AI engineer in industry, health researcher in
academia

5. End User

Consumes a system output, but does not seek to
study, use, modify, or share the system

student using a chatbot to write a report, artist
creating an image

6. Subject

Affected upstream or downstream by a system output
without interacting with it intentionally + advocates for
this group.

photographer who finds their image in training
32
dataset (upstream), mortgage applicant
evaluated
by a bank’s AI system (downstream)

32

Stakeholder

Most
involved
in current
phase

Description

Example

1. System
Creator

Makes AI system and/or component that will be
studied, used, modified, or shared through an open
source license

ML researcher in academia or industry

2. License
Creator

Writes or edits the open source license to be applied
to the AI system or component, includes compliance

IP lawyer

3. Regulator

Writes or edits rules governing licenses and systems

government policy-maker

4. Licensee

Seeks to study, use modify, or share an open source
AI system

AI engineer in industry, health researcher in
academia

5. End User

Consumes a system output, but does not seek to
study, use, modify, or share the system

student using a chatbot to write a report, artist
creating an image

6. Subject

Affected upstream or downstream by a system output
without interacting with it intentionally + advocates for
this group.

photographer who finds their image in training
33
dataset (upstream), mortgage applicant
evaluated
by a bank’s AI system (downstream)

33

34

Open Source AI Definition

Next Steps
Spring - Fall, 2024
● Creating content for definition v. 0.0.7
● Release by next Friday, April 12th

35

Definition Validation
● Confirm current systems (Llama 2, Pythia, BLOOM,
OpenCV) equally reviewable under v. 0.0.8
● Seeking volunteers to review 1 to 3 additional AI
systems to see how well they align with the
definition
○
●

Contact Mer at Mer@dobiggood.com if you are interested.

Due Monday, May 20th
36

Reviewers

We are interested in reviewing about 10 AI systems self-described as open as part of this definition process.
Those marked (*) have were reviewed in previous phases. Other systems are newly added.

1. Arctic
1.

Seeking volunteer

2. BLOOM*
2.
3.

Danish Contractor
BLOOM Model Gov.
Work Group
Jaan Li University of
Tartu, Phare Health

5. Llama 2*
1.
2.
3.
4.

Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute of
Paris
Victor Lu independent
database consultant

8. OpenCV*
1.

Rasim Sen Oasis
Software Technology
Ltd.

11. T5
1.

Jaan Li University of
Tartu, Phare Health

9. Phi-2
1.
2.

Seo-Young Isabelle
Hwang Samsung
Abdoulaye Diack
Google

3. Falcon
1.

Casey Valk Nutanix

6. Mistral
5.

4. Grok
1.

Victor Lu independent
database consultant

Mark Collier
OpenInfra Foundation

10. Pythia*
3.
4.

7. OLMo
6.
7.

Amanda Casari
Google
Abdoulaye Diack
Google

Seo-Young Isabelle
Hwang Samsung
Stella Biderman
EleutherAI

5.

Hailey Schoelkopf
EleutherAI

6.

Aviya Skowron
EleutherAI

Additional
volunteers
welcome on all
systems

System testing work stream
Stakeholder consultation work stream

2024 Timeline

Release schedule

OSAID v. 0.0.8
last week

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Townhalls +

Townhall +

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7 and 8

PyCon
Workshop
May 17th,
Pittsburgh)

(≈

Draft 0.0.9

… October
Monthly Virtual
Meetings

Release stable
version

Virtual Launch
Event (date
TBD)

RC1

Stable
Version

In-Person Meetings
Region

Country

City

Conference

Date

North America

United States

Pittsburgh

PyCon US

May 17

Europe

France

Paris

OW2

June 11-12

Africa

Virtual

Virtual

Sustain Africa

June

North America

United States

New York

OSPOs for Good

July 9 - 11

Asia Paciﬁc

China

Hong Kong

AI_dev

August 23

Latin America

Argentina

Buenos Aires

Nerdearla

September

Europe

France

Paris

(data governance)

September

North America

United States

Raleigh

All Things Open

Oct 27 - 29

39

Open Source AI Definition
Get Involved
●
●

●
●

Public forum: discuss.opensource.org
Become an OSI Member
○ Free or or full
○ SSO with other OSI websites
Biweekly virtual town halls… like this one!
Volunteer for definition validation (email Mer)
40

Q&A

41

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the
deﬁnitional process.

42


--- Subtitles for 2024-05-03 --- ###
>> Hello, everyone.

>> Hi, welcome.

>> Do you want to take it now?

>> I will.

>> It's becoming a tradition that we tag team on this one.

>> Yeah.

Teamwork.

>> So, yes, welcome to the online public town hall for the

open source AI definition for May 3rd.

We always go through our community agreements.

Those who have been here before are familiar, but just to

remember one mic, one speaker, take space, make space.

So if you ask a question, wait for others to ask before you

ask another one.

If you don't want to ask a question, pause and let others

take a chance to speak.

And if you don't usually speak in a public venue, we invite

you to say what's on your mind.

Kindness, just that we -- the work is hard, but that we be

gentle with each other.

And obviously hate speech is not permitted in this space.

Forward motion.

We start by focusing on what's possible.

And we note obstacles and come back to them, but we reroute

around them and do what is possible in the moment.

We seek solutions.

And we know that that is vulnerable, but it is crucial and

that we are all needed in this work.

And are there any other -- any other community agreements that

we have for this meeting today?

Okay.

So -- playing with my windows one moment.

Okay.

There we go.

Okay.

So, yes, as you all know, our objective for 2024 is to have a

stable version of the open source AI definition and that is

still scheduled for October.

Where are we now?

We have a couple slides that are similar to our last meeting,

but the last meeting was in a different time zone, so I'm

hoping this won't be redundant for anyone.

We are on version 0.0.8, which is feature complete.

It's our feature complete version.

So we have the preamble, the four freedoms, which have been

here for a while.

And then we now have a checklist, legal checklist for

required and optional components that has the required legal

checklist for every single component.

So that has been the new content for this version.

And very briefly, how did we get here?

I see there's chat, and I will trust Stefano and Nick to pause

me if I need to attend to that.

So we started with the four freedoms in the fall of 2023.

I know some of you are actually part of this process.

And this was study, use, modify, and share.

What should these open source principles mean for AI?

And so we had in-person co-design workshops.

We had one at All Things Open.

We had one at Linux Foundation Member Summit.

We had one at the Digital Public Goods Alliance member meeting

in Addis Ababa.

And from that, we came up with the definitions of the four

freedoms for AI.

So these are in 0.0.8.

And they should not surprise anyone, but we've now formalized

them for this technological context.

So we have use the system for any purpose without asking permission,

study the system and inspect its components, modify for any purpose,

and then also to use with or without modification, again,

for any purpose.

I actually will pause for comments at this point.

Let's see.

Yep.

Oh, I see.

Great.

So in the winter, we asked this very big question.

What components must be open in order for an AI system to be used,

studied, modified, and shared, of which there are many,

many different opinions and many, many valid opinions?

And we started doing this, again, by having in-person workshops.

We were at AI Dev in December in San Jose.

And then we got some really good feedback,

which is that working in person only is exclusionary because not

everyone can be in the room.

And so we shifted into virtual work groups in January of this year.

And we also decided to have our work groups focus on specific AI

systems self-described as open so that we could get specific in all

these different questions and debates around open-source AI.

And we're basically looking for systems that represent a diversity of

approaches to AI openness.

And we chose Wama2, Bloom, Pythia, and OpenCV.

And then we recruited members for these groups.

And we were very concerned about having global representation.

So we conducted specific outreach to Black, Indigenous,

and other people of color, particularly women and individuals

from the global South.

And part of being a member of the work group is to have your name and

affiliation shared publicly for the sake of transparency.

And over 50% of work group participants are people of color.

And you can see them here.

And, again, the deck will be available on the website.

So the first thing that the work groups did is they selected the required

components.

So we started with the model openness framework,

which was created by Matt White and colleagues at Linux Foundation.

And you can see those components from that paper on the left,

things like data pre-processing code, training code, evaluation code.

And then there's also model and data components as well that aren't shown.

And then we had work group members vote, initialed vote.

So that's a public vote of is this component required to use or study or

modify or share the system as a whole.

And then I, and this is also public,

created a Likert scale based on the number of votes per component.

And we came up with certain components that were, yes,

this definitely should be required down to no,

there really aren't many votes saying that this should be required.

And then that, that results of that Likert scale, the required, likely,

maybe, probably not, not required,

but into a public forum post for further feedback.

And that became version 0.0.6 of the definition.

So that is the first version of the definition where we actually said,

these are the components that we think should be required for something to be

open source.

And what we just finished early spring was a second activity of the work

groups,

which is to look at the legal documents for these required components and see

are the,

are there legal documents in these systems that are associated with these

components as described?

So we had the required components, which are, there's code components.

As you can see a couple of model components and then a number of data

information or in this earlier version,

data documentation components.

And then we asked volunteers to find links to the documents or licenses that

reference the rights to access and use those components.

And then to evaluate, to look through the document and say,

is use restricted or allowed is modification restricted or allowed is sharing

restricted or allowed for all these different components.

And these are the, so, and this is just a zoom in on the result,

which is 0.0.8. As you saw in the beginning, we have,

we are calling it data information now.

And so data sets are not required,

but information about training and methodologies, scope,

and characteristics provenance labeling procedures,

if used and cleaning methodology is required.

And then we have code components, data, pre-processing code,

training, validation, and testing inference and supporting libraries and

tools. And then two model components, architecture and parameters.

And you can see on the right,

the legal frameworks that we're using for each and then a longer list of

optional components.

This is basically the remainder of the model openness framework components

because obviously we want as many components as possible to be open,

but these are not required. So then, so basically all these data sets,

we say we would love if they're available,

but they are not required to for the system to be called open according to

our definition, additional code elements model.

I see for some reason, I didn't put a highlight on model,

but you can see it in there and other, which is for example,

a research paper or a technical report.

And then just again,

that it's very important that we have a representative process.

It's a global definition. And so this requires global consultation and we

have various stakeholder groups that we're,

that as part of our outreach,

particularly as we move into the next phases of the project and I can go back

to this if people are interested in it,

most involved in the current phase are system creators and licensed creators

and licensees. So people seeking to study, use, modify, and share the system.

And then to increase, I guess, identity-based diversity.

We, I'm using phrases like this one that are specifically inviting,

for example, Black, Indigenous, Latina, other people of color, women,

you can read that paragraph.

And then we also do outreach,

specific outreach to bring underrepresented groups into the process.

So next steps, spring through fall.

So now through October, basically. Right now we're doing definition validation.

So we are seeking volunteers to review. It says one to three.

This is not accurate anymore because now we've decided that we want to do about

10 systems total. So it's actually about six additional systems.

Using that same procedure as of the spreadsheet.

So finding the legal document and doing the analysis of each component,

according to these definitions of study, use, modify, and share.

And we're hoping to have that complete by the 20th.

So in about two and a half weeks.

And these are the systems that we're currently looking for to review.

And we have at least one volunteer for everything except Arctic,

Snowflake Arctic, which is a new addition.

But additional volunteers are welcome on all systems. It's a big task.

So I'm sure that Casey and Mark and Victor and Jan and Racine would love to

have a pal to share that review task with.

And you can email me if you're interested in that,

being a volunteer on any of those systems.

Again, to test the definition against the documentation available for these

systems, the legal documents and licenses.

And our timeline for the rest of the year, we did just release 0.0.8.

We may do a 0.0.9, depending on if there are changes that come back,

major changes that come back from this definition validation activity we're

currently engaged in.

We will have a virtual launch event associated with the release of RC1 in

June, and that date will be TBD.

We had been thinking of doing something in person, and then we thought

inclusion, this is a very important event.

We want as many people to be able to participate as possible.

So we decided to do virtual.

And then we will have a stable version released in October,

and that will be in person.

That will be at All Things Open in North Carolina.

And we have additional virtual and in-person meetings where we'll be

sharing and seeking feedback on, I guess, RC1, release candidate 1.

You can see where we'll be.

And some events, you can see we have the month but not the date.

So we're still working on certain details of this road show.

So, yes, we would love for you to be on the public forum discussed at

opensource.org, and I think that's the QR code.

We'll take you to that site, which you can join for free or become a

paid member.

And we have these biweekly town halls, which you're at right now, so you

know about those.

And then if you're interested in volunteering for definition validation,

you can email me or you can direct message me on the -- on that discussed

platform.

So thank you.

And, yes, Stefano, do you have anything to say before we do the Q&A?

>> I don't know.

Maybe we can share the news.

Shall we?

>> Oh, yes, Stefano.

>> Well, you know, we got -- we have received a grant from the Sloan

Foundation.

So we'll be doing a lot of the -- we're well positioned to have a lot of

participation, a lot of those travel, a lot of those trips to those events

will be supported by this program.

Maybe you can go back.

I had something also I wanted to mention.

Go to slide 28.

I don't know why I remembered this in my head.

I said -- mental note that I wanted to say something here.

Oh, yes.

So here you can see how the legal frameworks in the column legal

frameworks, we have the legal frameworks, the legal frameworks, the

legal frameworks, we have -- we talk about data information available

under OSD compliant license.

And when you look at the code, like inference or data preprocessing, you

see that the legal framework is available under OSI approved license.

And then if you look at the model -- oh, no, yes.

Parameters -- oh, it's cut.

Available under OSD -- parameter says OSD conformant terms.

I think it's interesting here because code, we know that is licensed -- I

mean, we know the licenses, we know the legal frameworks, we know it's

copyright mostly, there is some patent issue, but we've been using OSI

approved license for a long time.

So straightforward, we don't have any problem.

Judging whether the code component are suitable, are available under the

open source principles.

For data information, which is mostly documentation, it's a little bit

fuzzy, but still we can debate -- we know we can identify -- there is no

definition of open documentation.

But I think we can easily identify licenses that give us the possibility

to read the documentation, modify, and redistribute to others.

So that's why we're using the term OSD compliant license.

Although there is a question whether we should use OSD compliant or OSD

compatible.

So compatible with the open source definition or compliant with the open

source definition.

So it's a little bit of a debate and it's ongoing on the forum.

I encourage you to go find the thread and vote.

There is actually a little poll in there.

But the model parameters is interesting because model parameters don't seem

to fall under copyright law.

And there is discussion whether any other exclusive rights apply in

different jurisdictions.

So it's different between like Europe, United States, China, UK.

There is still a little bit of a debate.

So that's why we're using a more generic term that says OSD conformant.

So we want to have -- leave the flexibility to interpret how the

principles or how these parameters are distributed.

Until the dust settles on the legal point of view.

These are the questions -- these are the points that I think will have

to be clarified in the next few weeks during the validation process

among other things.

So if you have opinions, if you know someone who might have opinions,

now is the time to go and check the document.

Because the definition, the draft 08, 008 is feature complete.

It has all the elements that we want.

And if no one really objects or if there are no strong pushback, I think

it's going to be -- the release candidate is going to look very similar

to what we have now.

So any questions, I'm happy to -- me and Mer here are happy to answer.

>> A question on the GDPR.

I can read it.

Shall I read it for the recording or Jan, do you want to come off mute?

>> Yeah, go ahead.

>> I can unmute.

So there's been questions about like when it's -- a model is generating

results that someone is saying, oh, this isn't -- I want to remove this

from this.

From your results according to GDPR.

Wouldn't it be very nice to also have a possibility to do it?

Because if you just have the model, you cannot really remove it.

Because you have to remove it from the training data and then retrain to

get a new thing.

>> Yeah.

I -- yes.

But that is such a big question in fact.

And I'm really curious to see what the results of the lawsuit that just

happened against open AI.

Granted that is a closed, opaque, we don't know what's happening inside

there.

The fact that the source data is not required is because it's exactly for

this reason.

So if there is private information in the source data sets, those -- that

data set cannot be distributed legally.

So that's why we want to know what's going in there.

You know, we went into the training data set.

We want to know exactly how it was filtered.

You know, the duplication, all that thing.

That's why there is a requirement on data preprocessing in the code

section.

Because that's what it means.

You should -- you know, sometimes it's very valuable also to know exactly

how to have the exact same instruments that went into the training.

Building the data set for the training so that one can retrain the model

and/or readjust the parameters with their own data.

Or similar data.

In fact, the exact spelling of the data information requirement is -- says

it needs to be sufficiently detailed information about the data used to

train the system so that a skilled person can recreate a substantially

equivalent system using the same or similar data.

We hope that this solves the problem.

And if -- honestly, yes, if there is GDPR data inside the data set and the

model itself has it, then you should be able to rebuild the -- with your own

data without it.

And maybe that model itself is illegal, right?

In some legislation.

So there is a higher standard that applies here.

>> Thanks.

Any other questions?

You can chat or take yourself off mute.

If anyone has any other questions or thoughts.

>> I can come back on and just ask a little bit of a background question

here because I missed a couple of town halls.

So what is the idea of not requiring the training data in full and just have

the opaque model?

Because that sort of seems to me to be counterintuitive to the spirit of the

open source definition.

And I understand for the legality, but one can also say, well, all open

source models should be legal.

Is that the only thing or is there something more as well?

>> No, I think there is something more.

So many -- the fact that data set did not make it into the draft 06, was it?

Is because the working group as they were evaluating the various systems,

not enough of them put the requirement of the original data set as strictly

required to modify, study, use, and share.

So they ranked higher other -- like the training information.

Like the training code, the documentation on the data used were ranked

higher.

And so because there are so many machine learning systems that don't have

the original data set, like it just doesn't exist because it's not created.

Like for anything that is used with -- learning and other ways that are

privacy preserving.

Then there is that question of private data.

Where it might go -- I mean, it may be part -- I mean, technically part of

the -- good part of the originating data set.

But can be obfuscated or hidden from the model itself.

Like we were concerned -- we are concerned.

I mean, all of us are concerned about generating -- putting the bar so high

that there is no incentive.

Not only there is no incentive into releasing open source, but there is

actually a very strong disincentive into the open source AI.

And in fact, if you look at the amount of lawsuits that any of the more

open foundation models that have been released, they're receiving just

because they've been transparently saying, hey, we have scour the web and

incorporated pretty much anything that we could find.

That, you know, give us -- while on the other side of the spectrum, we

have things like Lama 3 or open AI, they don't say what's inside the

data sets, what went into their training sets, because they don't want to

be sued.

So we're trying to see if there is a balance to be found.

And let's -- the validation is also for this.

Like do we have a set of models out there that already exist that can

fit into the open source AI definition and we can actually work with

them?

Yeah, we want to be pragmatic, but we also want to maintain the

principles right.

The principles that we want to give users freedom, agency, control

over the technical choices doesn't necessarily mean that we want to

have the full spectrum of everything always open all the time.

Because it may be that there is enough elements even without having

the complete spectrum.

If you have looked at the model openness framework paper, it's an

interesting read because it has -- lists all of those components and

then gives a sliding scale of what's required for the -- to be included

in the Linux foundation projects.

And it scales from basically just give us the model parameters all the

way to give us everything.

And they call it open models, open tooling, when some more extra

pieces are available.

In open science where there is everything.

So we're trying to find a balance in there where there is a bar where

we can say, okay, this is open source AI, but -- and then everything

else goes on top.

Yeah.

All right.

So the transparency is a feature of open source.

>> I just want to pause.

I just want to pause.

Because we can continue this conversation for a long time.

I just want to pause.

Is there anyone else on the call who has a different kind of question?

And if not, we can continue this conversation for a bit of time.

Okay.

No.

All right.

So, yeah.

So we can continue, I don't know, to the half hour maybe talking about

this topic?

>> Yeah.

I just want to also announce the fact that we're going to be talking

about data in a separate talk.

Like there is absolutely a need to better understand the space also

as data becomes functional.

Which is a new thing.

Fairly new thing.

And we want to understand it a little bit better.

One of the stops in September is in France.

And we're working on a workshop specifically to start the

conversation that I'm quite sure is going to take a little bit longer.

Because transparency is the feature.

I want to highlight that.

That's why we're insisting on having data information, provenance

and all of that.

And the code for the training.

The code used for the creation of that data set.

I think it's going to be -- it's a good compromise.

But let's see what else exists in there.

>> I see Claire, you have a comment.

Do you want to come off mute, Claire?

>> Sure.

Thank you.

So this is just a question to see if there is any current effort

going into keeping track of any other definitions of open source

AI.

And specifically thinking about anything that might be referenced

in any emerging regulation or policies that might be coming at a

government level.

Knowing that I think it was referenced in the AI act, but I'm

not sure how it was referenced or what they defined it as in that

act.

>> Yeah.

So thanks for the question.

Because the AI act mentions multiple times, a couple of times

that it's a free and open source AI system without providing any

explanation of what that means.

So it was one of the triggers to push for this project to start

two years ago when we saw -- when I saw the first draft of the

AI act, I was like, oh, we need to have -- we need to help

regulators understand this space.

And we're having fairly good, intense conversations also with

the American agencies which are now under pressure to come up

with regulations inside to -- right.

To control a little bit this market.

As it comes out, there are so many foundation models that it

talks about risks and they all want to know what open source

means, what open means in this space and what the implications

are for public in general, for public interest.

>> Thank you.

>> Maybe one final thought or comment and then we'll close the

session.

I saw you typing.

If you want to have a last thought, you're more than welcome

to share it.

>> Maybe I see types.

I can say watch the space, watch our blog, too, because we're

going to be continuing the conversations around data.

I think it's a really important space where we don't have a lot

of practice.

There are new legal questions that are being raised like what

is exactly right, acceptable when it comes to text and data

mining.

New regulation around text and data mining specifically

appearing around the world like Japan has an approach that is

very -- Europe has introduced it as a new right and it's still

having -- there are some limitations to it, though.

So policies are going to be written and all the lawsuits in

the United States which are very interesting and we're waiting

for them to be clarified.

Yes, so Claire, the outreach plan is vast.

Like we've scrolled through with Mayor, but yes, we are reaching

out to a lot of the AI communities, startups, developers,

conferences like new rips and others.

Yeah.

Granted, it's going to -- remember what I like to remind

everyone, that the open source definition came out after at

least 15 years of experience in the free software world and when

the developers were few, computers were not as ubiquitous as

they are now, and it took a while to become so well-known and

widely respected, so we'll have to be doing this work of open

source AI.

We're defining it in a few months.

So we're going to have to do a lot of work after -- continue to

do a lot of this outreach work in the next years.

Yes, if you're coming to PyCon, you'll find us there.

That's our next stop.

All right.

Thanks, everyone.

We host this every two weeks.

I think that next week I'll be at PyCon, so we will not be able

to have this.

But we'll meet again in two weeks and the forums are still

going to be active and available.

Thanks, everyone.

### End of last town hall held on 2024-05-03 ###

### Start of next town hall held on 2024-05-31 ###
--- Presentation for 2024-05-31 ---
OPEN SOURCE AI DEFINITION
Online public townhall
May 31, 2024
last updated: May 28, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

OSI’s objective for 2024

Open Source AI Definition

3

Open Source AI Deﬁnition

Where Are We Now?

4

Open
Source AI
Definition

Preamble
4 Freedoms

v.0.0.8

Legal Checklist

-

Open
Source AI
Definition

Preamble
4 Freedoms

v.0.0.8

Working on review
processes for
determining if an
AI system meets
the definition
requirements

Legal Checklist

-

Open Source AI Deﬁnition

How Did We Get Here?
May 2024

7

Validation Reviewers
1. Arctic
1.

Jesús M.
Gonzalez-Barahona
Universidad Rey Juan
Carlos

2. BLOOM*
2.
3.

Danish Contractor
BLOOM Model Gov.
Work Group
Jaan Li University of
Tartu, One Fact
Foundation

3. Falcon
1.
2.

Casey Valk Nutanix
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France

4. Grok
1.
2.

Victor Lu independent
database consultant
Karsten Wade Open
Community Architects

We’re interested in reviewing about 10 AI systems self-described as open as part of
this definition validation phase. Those marked (*) have were reviewed in previous
phases.

5. Llama 2*
1.
2.
3.
4.

Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute of
Paris
Victor Lu independent
database consultant

7. OLMo
1.
2.

Amanda Casari
Google
Abdoulaye Diack
Google

8. OpenCV*
1.

Rasim Sen Oasis
Software Technology
Ltd.

10. Pythia*
1.
2.

Seo-Young Isabelle
Hwang Samsung
Stella Biderman
EleutherAI

3.

Hailey Schoelkopf
EleutherAI

4.

Aviya Skowron
EleutherAI

6. Mistral
5.
6.
7.

Mark Collier
OpenInfra Foundation
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
Cailean Osborne
University of Oxford,
Linux Foundation

9. Phi-2
3.

Seo-Young Isabelle
Hwang Samsung

11. T5
5.

Jaan Li University of
Tartu, One Fact
Foundation

Open Source AI Definition
Validation phase
v.0.0.8

Open Source AI Definition
Validation phase
v.0.0.8

It was hard for
volunteer reviewers
to find required
documents to do the
review.

Open Source AI Definition
Validation phase
v.0.0.8

This meant a lot of
the review analysis
was left incomplete

Open Source AI Deﬁnition

What’s Next?

June - October 2024

● Complete validation phase (June 10)
● Resolve comments, release v. 0.0.9 after
validation
● Cut the release candidate with sufficient
endorsement
12

Complete the Validation
Phase

Thanks,
LLM360
team!

1. Reach out to AI system creators to
ﬁll in the blanks on their own systems
by pointing us to correct documentation
2. Invite volunteers to also help us ﬁll in these
blanks (forum post forthcoming)
3. We’re also currently engaging in email and
phone debriefs with reviewers to better
understand the blockers they faced.
13

Seek Public Feedback on Initial Results

Please
comment on the
initial report of
our validation
process.

14

Simplify the Validation Process
We’re exploring
replacing the
spreadsheet with
an Evaluation
Card like this
prototype.

15

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Townhalls +

Townhall +

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7 and 8

PyCon
Workshop
May 17th,
Pittsburgh)

(≈

Draft 0.0.9

… October
Monthly Virtual
Meetings

Release stable
version

Virtual Launch
Event (date
TBD)

RC1

Stable
Version

In-Person Meetings
Region

Country

City

Conference

Date

North America

United States

Pittsburgh

✓ PyCon US

May 17

Europe

France

Paris

OW2

June 11-12

Africa

Virtual

Virtual

Sustain Africa

June

North America

United States

New York

OSPOs for Good

July 9 - 11

Asia Paciﬁc

China

Hong Kong

AI_dev

August 23

Latin America

Argentina

Buenos Aires

Nerdearla

September

Europe

France

Paris

(data governance)

October

North America

United States

Raleigh

All Things Open

Oct 27 - 29

17

The renewed discussion on data
1. The AWS Open Source team posted a
range of concerns with v 0.0.8, foremost on
data.
2. Linux Foundation team recommended
adding Data card to the required
components. Also they argued that Data
preprocessing code is unlikely to be shared
if the dataset is not shared, too.
18

Other relevant posts
1. The LLM360 team voluntarily ran their system
through the v.0.0.8 review process.
2. Stefano posted on whether and how OSI should
certify Open Source AI.

19

Participation Options
● Public forum: discuss.opensource.org
● Become an OSI member
○ Free or or full
○ SSO with other OSI websites
● Biweekly virtual townhalls… like this one!
● Volunteer for to fill in the blanks on definition
validation (email or DM Mer or Stefano)
20

Q&A

21

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the
deﬁnitional process.

22


--- Subtitles for 2024-05-31 --- ###
So, thank you.

So hi everyone.

My name is Mare and I'm leading the code of design process for the open source AI definition

and Stefano is with me and this is the public town hall for May 31st.

And those of you who have been here before will recognize our community agreements.

I'll go through them very quickly.

Basically one person speaks at a time.

And we ask that you obviously mute yourself unless we're in the Q&A session.

Take space, make space just means that if you tend to speak up, take a moment to pause

to let others speak and if you do tend to be quiet, we also invite you to share your

thoughts.

And then also once we do get into Q&A, we can have whoever asks a question, there will

be a response and then we'll say wait for another person to ask a question so we don't

just have a back and forth with one speaker.

Kindness this work is hard, but let's be gentle with each other.

Forward motion, focus on what is possible in doing it because this is hard work.

So we note obstacles and we come back to them, but we do what is possible in the moment.

Likewise solution seeking.

So saying something is not possible, yes, and it's very vulnerable to say, hey, how

about this, but that is what we need to have as a mindset to get this work done.

And are there any other community agreements that people would like to propose that are

not here and you can just put them in the chat.

Oh, hi, Anna.

Hi, Anna.

Okay.

I'll just continue.

So yes, so we are creating the open source AI definition.

That's our project for this year.

And where are we now?

We're on version 0.0.8, which was released in April and the parts should be familiar.

We have a preamble.

We have the four freedoms, which we're not going to go into today, but they're used,

we modify and share.

And then we have the legal checklist, which is basically operationalizing the four freedoms

by identifying which components are required, which was voted on by our community co-design

process.

And then what is the license or legal framework for each component.

And Stefano, step in if you have any additions.

What we're working on now is to review, is the review process for determining if an AI

system meets the definition requirements.

And yeah, we would like to review about 10 systems before we release, do release candidate

one in June, which is coming up soon.

A little bit of how did we get here?

This is the recent past, not the story of the whole project as some previous town halls

have shared.

So these are the people who've been working on this.

At this point, we have 11 systems that we're looking at, and this is listing the reviewers.

We started with the asterisked systems, Bloom, Lama2, Pythia and OpenCV.

And then we added on seven more.

So you can see.

And we had this spreadsheet-based validation process where component listed on the far

left, then the legal framework from the definition, then the individual reviewers asked to find

on the internet, which I'll get to later, the legal document as provided by the system

creators, and then to look at that document and determine, does this document give the

ability to study, use, modify, share that particular required component?

And it was hard.

It was in most cases not possible for volunteer reviewers to find the required documents necessary

to do the review.

And as a result, the analysis was also not possible.

So let me just see what my next slide is.

So what this means is that -- oh, there's a new slide here.

I see.

So what that means is that we are still needing to work on the validation, and we're needing

to work with system creators.

We need from system creators their identification of this is the document that you need, this

is the license on this component of our system.

We've just realized that that's -- it's a required component of even being able to test

our own definition.

And okay, we're going to complete this validation phase by the 10th and resolve comments and

release a version 0.0.9 after the validation and cut a release candidate with sufficient

endorsement.

Stefano, did you want to say anything else on the slide?

>> Well, maybe just add a little bit about the validation phase and how it's going.

We realize that basically that checklist is complicated to -- for people, even for experts,

computer experts, to find these components without the expertise of the actual -- the

people who have created the systems is really complicated.

So we really -- at this point, we really have to engage with system creators, the original

creators of PHY, and LLAMA, LLAMA 2 and 3, and GROK, and Mestral, and PTI, et cetera,

Falco, and ask them to provide the list of components.

Or we need to find another way of validating.

Because we had conversations with the Linux Foundation also, and they have a similar concern

for the model openness framework, which we have -- we are reusing for the list of components.

So it is complicated.

But the intention here needs to be -- you know, I'd like to clarify.

The intention here is to provide a definition that is general purpose, that we can apply

to different technology, that can to some extent resist the test of time.

This components piece is really targeted at the latest generation of transformers and

large language models.

The architectures that -- of the systems that we have here, neural networks, et cetera.

So we're really trying to strike a balance between setting principles that are high level

and valid for a longer term.

And provide a checklist for the evaluation of the openness of these systems.

So yeah.

That's it.

We're a little bit -- and I just posted a few minutes ago, probably an hour ago, on

the forum, like a comment along the same lines.

Of what I just said.

There is one curiosity here that probably some people have been -- that I've heard people

asking.

Go back one slide, Nat, please.

Where it says -- the column that says legal document.

And why not call it license?

And that's because the licenses are -- is a term that is really tied to the concept

of copyright.

So it works really for documentation and code.

But for model parameters, the copyright is most likely not applicable.

And the same also for data.

Copyright is not necessarily applicable.

So those are usually referred to as agreements in legal terms.

So that's why we're not calling them -- legal document is more of a generic term that covers

both licenses and agreements in terms of service and other names.

>> So I'll just comment a little on Nick.

And then Dan, I'm going to leave your question to the Q&A.

So just to clarify, because this is a concern that people have of the idea that would system

creators be evaluating their own systems as part of a formal process?

No.

I think it would be that system creators are providing documentation and then there are

independent reviewers looking at that documentation and confirming, yes, this describes the component

as required.

I don't know, Stefano, if you have anything to add on that.

But just this idea of independent review is still part of the process.

Okay.

All right.

So yeah, this is just basically saying what Stefano was talking about.

Reaching out to system creators, I would add that, yeah, we are also looking into collaborating

with the Linux Foundation on this because we are using their component list.

And they do have -- I guess I can't -- I'm not sure what I can announce.

I know they have a launch.

But they're also working on a solution to this documentation challenge.

And so we're looking at how can we collaborate with them.

So that we're not both going to system creators and both asking them for documents, but where

we can be asking the system creators to funnel their documentation into the same location.

This volunteers, I'm not sure that's going to work.

But if volunteers do have this knowledge and can help us fill in the blanks, that's great.

Yes, and we're learning from reviewers, which is basically what Stefano has talked about.

This idea of needing the collaboration of creators, system creators is what we found

from talking to reviewers.

Yeah.

So this is -- yes, there is a report that Stefano referenced, which is just basically

in text talking through what I'm sharing with you now.

And that's a QR code to the forum.

And yeah, we've been thinking through what are ways to simplify the validation process.

At this point, it seems like making the documentation for each component easy to find and review

is probably the number one blocker.

There may also be blockers related to format.

And we're looking at the idea -- Stefano created this design, the idea of an evaluation card.

Maybe that format would be easier to work with than a spreadsheet.

But in any case, having the document to review is probably the number one need that we have

right now.

And Josh, I see your hand.

And I will answer during the Q&A.

And then just to have our timeline.

So we are still looking to release RC1 next month.

And then the stable version in October.

Yeah.

And also a virtual launch event, I guess, is still something we're planning for next

month.

RC1.

We'll see how that goes.

And then we have some in-person meetings.

We were at PyCon.

And Nick created a forum post about that, summaring what we're up to at PyCon.

And yeah, throughout the summer, we have a roadshow going.

And we'll have a data event in October.

That's an issue that's come up throughout the process, is what the definition should

be saying with regards to particularly training data.

So yes, speaking of which.

So yeah, so this is a huge issue.

It's a very important issue in the definition.

And the AWS, Amazon Web Services, open source team posted a range of different concerns

with our current version on the forum.

And the Linux team, primarily the issue of wanting data to be included as a requirement.

And then also the Linux Foundation has recommended adding a data card and removing data processing

code.

So there are various institutional actors and individuals that have made requests about

changing the definition.

And I also just want to affirm to everyone on the call that no changes will be made without

a very clear, structured public process.

So you're not going to wake up one morning and a new requirement is in there, or a requirement

has been removed.

We're sharing with you the requests for transparency.

But we will have a public decision-making process about any changes to the definition.

Let's see how much.

Yes.

So this was helpful and useful.

So the LLM 360 team voluntarily ran their system through version 8 review process.

So again, self-review wouldn't be something that would happen in a formal review process,

but this was very, very helpful just that they were able to look through the component

list and the description of the components and said, yes, we understand what each one

says.

Yes, we have documentation associated with each of these components.

Yes, we think it's fair and well-structured.

And they have their post.

Again, that QR code will take you to the forum, which includes all these different posts I'm

describing.

And then, yes, Stefano also posted about certification.

So what is the process for determining that an AI system meets or does not meet the open

source AI definition?

Is that a certification process that lives at OSI?

Does it live somewhere else?

That's something we're also considering.

And Stefano has a post on that.

If you have thoughts, please comment on that.

Yeah.

And this was also prompted by--

Go ahead.

Yeah.

That request was also prompted by the AWS team, which is something that we were already,

you know, back of our mind.

It's definitely for the future.

It's not an immediate urgency now to decide whether we want to have more certifications

and how that would look like.

But I think it's an interesting question to pose.

And if you have any thoughts, please join the forum and contribute to that conversation.

The question is if OSI should engage in the certification and how.

If yes, how?

It's not necessary.

I don't think it's mandatory for OSI to necessarily engage into this process of certification.

Yeah.

And that was also something that came out of the PyCon workshop that we did.

The number one question from participants was how do I know if an open source-- a system

is open source according to a definition?

You know, what's the process?

How do I know as a system creator even?

So that's also something that directed us in that-- toward that question.

Okay.

Yes.

So just ways to participate have been shared already.

But just the link to the forum is discussed at opensource.org.

You need to create an account, which is free if you want.

Or you can become a member and give us a little donation.

OSI is a nonprofit.

We have the biweekly town halls, which you obviously know about.

And then, yeah, if you would like to volunteer, you can DM myself or Stefano.

But primarily me, since it's my role to manage that.

And now we will get to the Q&A.

So I'll start with Dan, and then I'll call on Josh.

So Dan, I'll just read your question.

Are we looking all the way down to the library level for SBOMs?

And I don't know, Stefano, if you need additional information on that or--

I was wondering, I'm not sure what you mean, Dan.

I can give you voice if you want to speak out loud or if you want to elaborate a little

bit more, because I'm not sure which library level or which SBOMs you're referring to.

Okay.

Dan's typing.

Yeah, there you go.

Is that clarifying?

Yeah.

I'm thinking GitHub repositories.

So for AI systems, there are three type of components that are required.

Then they're grouped into data information, which is mainly made of documentation.

There is model parameters, which is basically a set of one and zero organized in tables.

And then there is code components that include the architecture of the system, the code used

for assembling and creating the data set, the code for running the training, and the

code for inference.

So are we looking at the library level?

I mean, for the code piece, SBOMs, I'm assuming you're talking about the code.

I don't understand the question.

Right.

Yeah.

Code, we're looking at is the code open source or not?

And it's usually pretty easy to understand if it's open source or not.

If it carries an open source license and source code is available, you should be able to figure

it out.

SBOMs are -- no.

So if you're asking how deep we are investigating it, you know, someone was asking yesterday

in a conversation, like, if you -- for inference, you need to run a proprietary system or you

need to run on a proprietary platform.

You can only do inference on G Cloud or something else.

We'll have to think specifically.

We'll have to look at specific examples.

Because we want to -- because there is a thing called the system library exception or there

is an experience that we have from the old days when we didn't have the Linux kernel.

And there was a lot of open source software running on proprietary hardware, on very proprietary

operating systems.

And that was okay.

That was fine.

Because we were working towards having more open source code.

So it didn't matter if you were running an open source photo editor on Windows or, you

know, a kernel, a known free kernel with a GNU user space.

It was still open source software.

So we will have to look at specific examples in these cases to see how deep we want to

go into -- it needs to be open all the way down to the last turtle.

>> Thank you.

Okay.

Josh.

>> I hope that explains.

If you have more questions -- okay.

Good.

Josh.

>> First off, thanks for bringing up the system library extension.

That's the first thing I thought of when I've been thinking about these things.

And the reason why that came about.

Just as you explained so succinctly.

And OSI came out of -- the open source definition came out of all of that.

Having criteria for determining, you know, what's going to be part of this operating

system and whatnot.

Where I feel this -- what I feel this is most analogous to, this process that I've experienced,

is actually the free software foundation's respect to your freedom hardware certification.

Because it had nothing to do with hardware in a sense.

Because they didn't -- they weren't looking at hardware design and things.

That was a nice thing.

If anybody wanted to share their hardware designs, that would be great.

But in designing that program, which is -- I led the launch of that.

And the initial certifications.

It really was about thinking about an ecosystem in a context.

Right?

And having to come up with the set of criteria.

How you go about -- okay.

Here's a person selling a product.

And we want to certify that it's, you know, respects your freedom in these ways.

Right?

But it wasn't just looking at that product.

And what code it shipped with.

That was what we would do to give them certification or not.

But what we did as a community and in working with them, is really encourage them to think

about how they're shipping that.

How they're treating the entire ecosystem.

Not just to support this product, but the idea of product lines and the ability for

a person to take this and make their own potential products or adapt the existing products.

And it feels very similar to that.

That you're going to have a lot of different kinds of hardware.

Or in this case, open AI systems or laboratories, as I kind of think of them.

Or open AI ecosystems.

And it feels like it's a little bit broader than, say, a definition.

But more like, you know, a tree of conditions.

Like, well, for these kinds of systems, there are levels of what a person can do.

You know?

If you ship all of this, it gives them this starting point.

And they can then adapt on top of it.

If you give them, you know, you can give them all of this, but it's not going to be any

of the data.

They're going to have to go out and find all of that to just get started.

To have day one.

It's going to be maybe a year out for them.

Or if they're going to need a certain amount of money.

But we had to do the same kinds of things in the open -- in the hardware certification.

And partly why I bring that up is because we didn't do actual certification.

You know?

Now that I'm in the world of standards development with IEEE, I understand what certification

is much better than I did when I was with the FSF.

But really, it was this criteria.

You could use a trademark.

The FSF's trademark.

You could self-certify was one of the ideas that we were pursuing.

And say, I'm delivering what I believe meets all of these criteria of some version of this

criteria.

And I just want to put that out there.

Because I think there are some amazing historical examples that would be -- that we could run

through this without feeling like we're having a moving target.

Things like Cafe.

And then Facebook's creation of Cafe 2 is, to me, one of the greatest case studies that

we can look at.

A lot of people aren't familiar with it.

And I don't do my civic duty of writing about it.

But to me, it's literally one of the best available sort of things that has gone through

a whole -- its whole life cycle from kind of beginning to end.

Because it's now moved on to other things.

But it's -- I'll leave it -- well, I'll leave everything there.

And then if another time I can come back and I can discuss why I think it's a great learning

example for what is happening here and how it could apply.

But my main kind of point -- and it's kind of a question, I guess -- is, do you feel

this is more like this multi -- like, OSI definition is kind of binary.

Your license is either -- when applied to code, is either meeting this definition or

not.

But I feel the open AI definition really is, it's more like a set of criteria for kinds

of systems or laboratories or like a lab of the box or something that is evaluated and

then potentially given kinds of -- not scores, but, you know, meet certain types of criteria.

And is that where you feel this might be going?

Or are you looking to try to get it to be simpler?

I can't really tell.

>> No, thanks, Josh.

What's your comment?

>> No, I get it.

So it's a frequently asked question, I guess.

Only recently there was another one request on the forum about this.

So I believe that strictly the open source AI definition must be binary.

And it must be binary because if it's not binary, then people will -- people, the public,

politicians, regulators, business managers, and business owners, venture capitals, et

cetera, will expect that also the open source definition will imply a range of openness.

Which is already there.

If you want, like if you look very carefully, you will see that some software is open source.

And then on top of that open source layer, there is a proprietary piece that renders

the whole stack less useful.

But still it's better than nothing.

So there is in practice, there are -- I can see that some people might interpret them

as ranges of open.

But for the definition itself is binary.

And that's where we're -- what we're aiming at.

We have an open source AI definition that is binary.

Meaning you provide these data information, code, and required data information, required

code components, and required model components, and you're done.

You pass the bar.

Then if you provide more, you are more open.

If you provide less, you're not open source AI.

That's it.

It's crystal clear.

Now there is something, though, that keeps coming into my mind.

The concept of what you can do, and there was someone posting recently on the forum

again.

What you can do with a full open source AI, in other words, or with some of the artifacts

of the machine learning, without having access to some of the components, is immensely more

useful and more powerful and more -- you can do more than you can do with a binary piece

of software without having the source code.

In other words, if I don't give you -- so the open source AI definition requires very

detailed information about the data set, so that -- and the code that you use to build

it so that you can retrain the -- or you can train a new model that has similar capabilities,

similar scoring, for example, in benchmarks, et cetera.

That's the intention of the Draft008.

That capability of retraining a model, especially if it's a large one, is not something that

will happen very often.

It's not like rebuilding a binary, even if it's a large one.

It's still within reach, and it makes a lot of sense for security, for research, for a

lot of other things.

The retraining of models is -- I don't think it's going to be very, very popular as an

activity.

But at the same time, fine tuning and splitting models, re-architecting and things like that

is the most, in my mind, in my -- you know, I'm not an expert, but from what I've already

-- we've already started to see those activities being a lot more exciting and popular.

So in the future, there might be some other -- I mean, in practice, as we go into practice,

we may see some -- something else pop up.

Yeah.

>> Thank you.

>> Yeah.

Custom models are time-consuming, expensive, et cetera.

Yeah.

So more questions.

>> Yeah.

Does anyone who hasn't asked a question have a question?

And you can raise your hand or write in the chat.

And any follow-up questions?

Someone who's already asked a question and wanted to ask a follow-up.

Okay.

Josh.

>> Yeah.

So part of where I'm still struggling here, right, is that -- for good reasons, I should

say, I'll start there.

So that I don't -- I don't want to offend anybody.

I think people have made a lot of good choices and has tried to do good things.

But in general, our community has tried to, except for some, avoided talking about the

fact that when we say an operating system is open source, we don't really mean that.

Right?

We don't really mean that you go and if I pick a piece of code at random, it is going

to be open source.

When we're talking about the operating system.

We mean for the most part, practically speaking, with some exceptions here and there.

And that's important to note.

Those are the exceptions that make -- those are the only parts that are the non-open source

parts at times.

And they're there to enable -- to practically allow people to run on different hardware

systems to allow for things that in life are important.

Right?

Whether they were browser add-ons or they were kernel modules or what have you.

Right?

And so I think it's kind of maybe important to note that if the level of things we're

judging are these multifaceted systems, our definition might not need to be when applied

in normally might not need to be perfect.

Because we've never really done that.

People don't want to take the free software foundation stance of, you know, Debian is

not a free software operating system.

Right?

Like, that's just been brutal.

I lived that for ten years when I worked there.

It was terrible.

I hated it.

But I understood why they took that line.

Because they felt somebody needed to.

Even if it -- but everybody else, and I'm very happy everybody else made the good choice

of being practical and saying Debian is a free and open source operating system and

Red Hat is and whatnot.

Right?

But I wonder if we could do something similar with this.

Where we say, look, here's the pristine version of it.

If there are just things that are kind of added on to enable this to happen in various

contexts, then we don't throw -- we don't just label the whole thing as not open source

AI.

Right?

I think that we -- I think that maybe we should say, when we apply this definition, we can

do it in a way that says, is the bulk sort of kernel of this?

Is there a single way in which you could take all of the -- take a subset, a majority subset

of this and apply it in a circumstance where it is 100% AI and these other things are just

for practical compromises to allow it to run in more systems, use certain data sources,

or what have you.

They're not necessarily necessary for what we're evaluating when we say open source AI,

but they're practically needed to allow people to actually use these.

And that's how we apply it.

It still gets us to binary, it's still criteria, but I mean -- sorry, I'm just trying to really

think about real world.

>> Great question.

Yeah.

>> Josh, I hear you.

And in fact, you know, probably as veterans of the open source and free software, I think

you recognize that there is a piece above the checklist.

The checklist is very specific.

And let's say it's a sort of experiment.

That's why it's going through the validation phase.

But what really, in my mind, what really counts is what's above that.

And above that, there is the definition that looks pretty much like the free software foundation,

the free software definition, not just the four freedoms, but also what's written below

as the preferred form to make modifications to a machine learning system.

Those pieces are the ones that in my mind count a lot more.

Because in those pieces, we can have that flexibility to judge and evaluate.

From a distance, we're going to be able to see, hey, do I know enough about the prominence

of this data so that I can say how you've trained your system and therefore I can say

I can replicate it and that will tell me that it's really an open source AI.

And if not, like, dude, I don't even need to go through the checklist.

Like, you know, it's very quick and clear.

But if I have plenty of information, then if it's skipping one of the elements of those

checklists, I can probably say confidently, like, yeah, this is open source enough.

I can live with it.

Because I know that I can do this, this, and that.

I can modify, I can study, share with confidence.

So a lot of it, remember that this is it took 20 plus years to go from the free software

definition to the open source definition.

Like, that required that generate I mean, those 20 years generated a huge amount of

code licenses, there was plenty to draw from to write those 10 points for the Debian free

software guidelines.

We don't have that luxury.

We're really flying and building the plane at the same time.

But yeah, the experience is really valuable.

And if you share with me that cafe that you mentioned that via email, I'm really curious

to see what that is.

Yeah, I'll do that.

I've written it up for sharing to a co worker somewhat recently.

And I'll adapt that.

Just a quick little follow up.

Oh, sorry.

I didn't capitalize.

Yep, yep.

Look, Peter, I need to just absolutely.

Sorry.

So what I'm going to do is I'm going to go to Dan's question.

And then I'll do a last call for questions.

And I think it might make sense, Josh to take the any continuing, continuing conversation

into email.

Just so that we can can wrap up the meeting.

But yeah, so I'll take Dan's question, then we'll do the last call.

So Dan is asking, how will OSI partnerships work, particularly a OS, OSI AI partnerships.

So I think we might need more clarification, but Stefano, do you have enough to respond

to that?

Yeah, I it's not clear to me the concept of partnership, because we don't have partners

now we have the OSI has affiliate organizations, which are other nonprofits that support the

mission of the OSI.

We have individual members who donate to us and decide donate or not, but decide to support

the mission of OSI with money or just by following our activities.

And we have individual sponsors, sorry, corporate sponsors and and but we don't have partners.

So I'm not sure.

We don't envision to have AI partnerships.

So if you want to type in there, Dan, what you're clarifying follow up, then we are happy

to respond to your questions.

And then I think I will just do one last call for comments, actually for questions.

Yes, and then and then yeah, we can take the conversation Josh, the quick conversation

offline to continue if you'd like.

So as I scroll to the last, thank you, slide.

I'm not seeing any.

Okay, cool.

All right.

So then thank you so much.

Anna.

I see I see a raised hand from Anna.

I think it might be a clapping hand from Anna.

Oh, I see.

Okay.

Thank you, Anna.

We appreciate it.

Yeah, we met on at PyCon.

Oh, just clapping.

Okay.

All right.

We appreciate it.

Okay, bye.

Thank you, everyone.

And hang out in the forum.

That's where we share all our updates and opportunities for interaction and feedback.

Thank you.

Thanks.

Bye.

Bye.

Bye.

Thanks.

### End of last town hall held on 2024-05-31 ###

### Start of next town hall held on 2024-06-14 ###
--- Presentation for 2024-06-14 ---
OPEN SOURCE AI DEFINITION
Online public townhall
June 14, 2024
last updated: June 11, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

OSI’s objective for 2024

Open Source AI Definition

3

Open Source AI Deﬁnition

Current Version
OSAID v.0.0.8

4

Open
Source AI
Definition

Preamble
4 Freedoms

v.0.0.8

Legal Checklist

-

Open Source AI Deﬁnition

Key Feedback
OSAID v.0.0.8

6

Open
Source AI
Definition
Data
Information
v.0.0.8

Requiring only data
information…

…instead of training
datasets is the
greatest point of
debate now.

Open
Source AI
Definition
Other
Components
v.0.0.8

Others have
proposed…
… removing data
pre-processing
code requirement if
training data is not
required.

…requiring a model
card
… and data card to
standardize system
documentation.

Open Source
AI Definition
Describing Legal
Requirements
v.0.0.8

In contrast to the clear
“OSI-approved”
licenses available for
code components…
… the “OSD
compliant”
requirement for data
information...
…and “OSD
conformant”
requirement for
model parameters
have been
challenging for
reviewers to
interpret.

Preferred form to make modiﬁcations
Data information

Code

Model

Sufficiently detailed
information about
the data used to
train the system, so
that a skilled person
can recreate a
substantially
equivalent system
using the same or
similar data.

The source code
used to train and run
the system.

The model
parameters
(weights and biases)

Data Information Explained
◦ The intention of Data information is to allow
developers to recreate a substantially
equivalent system using the same or similar
data.
◦ Came out of the systems review process, with
votes by volunteers.

11

Zooming in on the issues with datasets
◦ The Pile taken down after an alleged copyright
infringement in the US. But legal in Japan. Maybe
legal in EU
◦ DOLMA, initially had a restrictive license. Later
switched to a permissive one. Suffers from the
same legal uncertainties of the Pile, however the
Allen Institute has not been sued, yet.
◦ Training techniques that preserve privacy like
federated learning don’t create datasets.
12

Alternative proposals
● Use synthetic data: Experimental,
unproven technology, limited to
corner cases
● All their components must be “open
source”: This integralism ignores that
even the GNU project accepts system
library exceptions and other
compromises.

13

Open Source AI Deﬁnition

System Validation
OSAID v.0.0.8

14

Validation Reviewers
1. Arctic
1.

Jesús M.
Gonzalez-Barahona
Universidad Rey Juan
Carlos

2. BLOOM*
2.
3.

Danish Contractor
BLOOM Model Gov.
Work Group
Jaan Li University of
Tartu, One Fact
Foundation

3. Falcon
1.
2.

Casey Valk Nutanix
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France

4. Grok
1.
2.

Victor Lu independent
database consultant
Karsten Wade Open
Community Architects

We’re interested in reviewing about 10 AI systems self-described as open as part of
this definition validation phase. Those marked (*) have were reviewed in previous
phases.

5. Llama 2*
1.
2.
3.
4.

Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute of
Paris
Victor Lu independent
database consultant

9. LLM360
5.

[Team member TBD]
LLM360

8. Mistral
1.
2.
3.

Mark Collier
OpenInfra Foundation
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
Cailean Osborne
University of Oxford,
Linux Foundation

7. OLMo
4.
5.

Amanda Casari
Google
Abdoulaye Diack
Google

10. Pythia*
1.
2.
3.

Hailey Schoelkopf
EleutherAI

4.

Aviya Skowron
EleutherAI

11. T5
5.

8. OpenCV*
We will need an
independent reviewer
for LLM360

1.

Rasim Sen Oasis
Software Technology
Ltd.

9. Phi-2
6.

Seo-Young Isabelle
Hwang Samsung

Seo-Young Isabelle
Hwang Samsung
Stella Biderman
EleutherAI

Jaan Li University of
Tartu, One Fact
Foundation

Viking
6.

Merlijn Sebrechts
Ghent University

Validation Challenges

It is hard for volunteer reviewers
to find required documents
independently..

Validation Challenges

This meant a lot of the review
analysis has been incomplete.

Validation Solutions

Having the help of
system creators to locate
documents has been
crucial.

Thank you,
Arctic!

Validation Expectations

Given current system information, our expected
review results are as follows. If we are missing
information, please let us know.

Open Source AI Deﬁnition

What’s Next?

June - October 2024

● Complete validation phase
● Resolve comments, release v. 0.0.9 after
validation
● Cut the release candidate with sufficient
endorsement
20

Complete the Validation
Phase

Thanks,
LLM360!

1. Reach out to AI system creators to
ﬁll in the blanks on their own systems
by pointing us to correct
documentation
2. Invite volunteers to also help us ﬁll in
these blanks

21

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

March

April

May

June …

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review
Meetings
Begin

Virtual System
Review
Meetings
Continue

Virtual System
Review
Meetings
END

Feedback
Informs Content
of OSI In-Person
Stakeholder
Meeting

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Townhalls +

Townhall +

Draft 0.0.5

Draft 0.0.6

Draft 0.0.7 and 8

PyCon
Workshop
May 17th,
Pittsburgh)

(≈

Draft 0.0.9

… October
Monthly Virtual
Meetings

Release stable
version

Virtual Launch
Event (date
TBD)

RC1

Stable
Version

In-Person Meetings
Region

Country

City

Conference

Date

North America

United States

Pittsburgh

✓ PyCon US

May 17

Europe

France

Paris

✓ OW2

June 11 - 12

North America

United States

New York

OSPOs for Good

July 9 - 11

Africa

Virtual

Virtual

Sustain Africa

July

Asia Paciﬁc

China

Hong Kong

AI_dev

August 23

Latin America

Argentina

Buenos Aires

Nerdearla

September

Europe

TBD

TBD

(data governance)

October

North America

United States

Raleigh

All Things Open

Oct 27 - 29
23

Participation Options
● Public forum: discuss.opensource.org
● Become an OSI member
○ Free or or full
○ SSO with other OSI websites
● Biweekly virtual townhalls… like this one!
● Volunteer to help with validation (email or DM Mer
Joyce)
24

Q&A

25

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the deﬁnition.

26


--- Subtitles for 2024-06-14 --- ###
All right, folks, thanks for joining this town hall.

We meet every two weeks, try to keep up to date the community about the evolution of

the draft and summarizing the conversations that we've been having on the forums and in

conferences like the conference that I just presented at here in Paris, in Cologne, Paris,

in a hotel.

So hopefully the network gods support us to go through this recording.

Just the community agreement, remember that we're trying, the one that I'm really focused

on and love the most is the forward motion, the fact that we are trying to understand

where the problems are and if we don't find an immediate solution, still we've marked

the spot, we move around, we'll get back to it because we do have to find a solution.

We do have a tremendous amount of pressure from all over the place, from politicians,

policymakers and from the industry, from academia, from the nonprofit and civil society to provide

some sort of guidance of what open source AI really means since everyone is using this

term.

And reminding that this is our objective to have by the end of the year a workable definition,

something that is acceptable even though it may not be the most perfect test thing that

we can imagine because the world is moving very rapidly and things might change in the

future.

So we need to find ways to provide solid principles that maybe will not change but allow for some

parts to be adapted.

We'll talk about some of the topics that emerged last week.

So the current version of the definition is still draft 008 and this was released a little

bit over a month ago at this point and it's made of some parts and parts that have received

very little comments in the past months are the preamble which is the place where we define

what we're talking about which is we decided to adopt the definition of an AI system provided

by the Organization for Economic Collaboration and Development or ECD.

It seems to be a widely accepted definition so we're going to use that as a reference.

Maybe it's worth going back and remind people at this stage that the reason why we have

a definition of an AI system is because we needed to have an anchor for the conversation.

In the free software definition, the free software definition refers to the program

and everyone understands what the program is or at least there is a very small margin

for error or misinterpretations.

But when it comes to AI there are misinterpretations and that's why there is a definition and these

definitions are also stated in law like the AI Act mentions, defines an AI system in a

very similar way to the OECD text.

So that's what we have.

And then we have in the preamble the reason why we are working on and the reason why we

want the definition of open source AI which is a very short summary of the intention to

give users the same rights that they have in software, the same independence, control

of the technology to enable permissionless innovation and collaboration.

Now the concept of user is also not defined in the free software space and this is an

area that has received some comments.

We want to be explicit and I think I'm working on a draft 0.9 and that will specify, will

contain a suggestion for what the recipients of the rights should be.

And draft 0.09 will probably mention the fact that we want end users, so anyone who is interacting

with the system, putting input and receiving outputs and also developers and deployers

of AI systems needs to be able to enjoy those freedoms.

Now below this part have not received a lot of comments so they seem to be fairly stable

to me.

The one part that is new in draft 0.08 is the concept of preferred form to make modifications.

That is something that is described in the free software definition as access to the

source code that is necessary for the actions of study the software and modify the software.

Now to study an AI system and to modify an AI system it's necessary to define what the

preferred form to make modification is and that's where there is a new section in 0.08

that says what the preferred form to make modification is.

I'll go into the details later.

And finally the bottom part is a legal checklist.

This is what I refer to as it's based on a paper from the Linux Foundation called the

Model Openness Framework.

You will see often referred to with the acronym MOF.

And this lists components of machine learning systems and in generic terms but they're defined

in the paper.

We use this as an ideal checklist that a future certifier or reviewer of AI systems might

use as a reference to say if this component is available under licenses or terms or legal

terms that allow the same grant, the same freedoms of the open source definition, the

original one, then if the required components are available under those acceptable conditions

then the AI system is an open source AI.

If not, most likely it's not.

Okay, so let's go a little bit into the details.

The key feedback that we have received is around what is required and what is optional.

So the pieces of optional components, I mean required

components are the biggest conversation is about data.

The original datasets are seen, some people have seen the training dataset into the optional

components and I believe they may have jumped to conclusions because the, well I'll talk

about it, but these are replaced with data information.

So let's skip through.

The other required components that I want to draw your attention on is the fact that

the data processing and like one of the components is actually required and data processing and

labeling techniques and all the disclosures about how the dataset has been built are part

of the draft.

And I'll go into more details later.

So there is a very lots of confusion around this part of the definition and we need to

spend a little bit more time to discuss.

Other minor requests are comments that we have received that are around the fact that

the legal requirements are described as available with terms like available under OSD, the original

open source definition, OSD compliant terms or OSD conformant terms.

Quick explanation of what this means.

The data information, I mean the concept here in data information like training methodologies,

et cetera, training, training scope, the data, the scope of the data, where the sources,

et cetera, are in documentation are probably going to be in the form of documentation.

The documentation uses different licenses and different agreements for sharing and distributing

for distribution.

However, the OSI has reviewed licenses that are not specifically targeting software.

So we don't have a way to say right now, we don't have a list of OSI approved licenses

for documentation.

So we know what they look like and they conform, they comply with the open source definition.

In other words, they allow for no discrimination of use, no discrimination of people, no field

of use, strict restrictions, ability of preferred form to make modification to the text, like

the source code of the documentation, et cetera.

So like you don't distribute a PDF encrypted as documentation.

That's not acceptable.

So that's what these words say.

And for the model parameters, we do talk about the OSD conformant.

So we use a different term because most likely model parameters don't fall.

Actually it's quite clear at this point, they don't fall into copyright law.

So using the word licenses and license approved, OSI approved, OSI compliant terms is not really

useful.

We need to be using a different framework and it's probably going to be more in the

contract law, at least that's what many of the lawyers that I talk to seem to think.

And that's, you know, OSD conformant means you still need to give us access to the, give

us the possibility to share, modify, give out free, without asking for permissions,

et cetera.

So it's a word that it will be more explicit in draft 09.

There will be a description in that lawyers can interpret more clearly.

So let's get into the concept of data information.

And maybe I need to take a little bit of a step back.

The intention of the definition is to provide in the upper part, so above the checklist,

what we call the checklist, in the upper part of the document, the stated intentions and

sort of a general, unmutable, general purpose reference point that can resist the test of

time.

That's why we have principles in the preamble.

The definition of open source AI is synthetic in the four freedoms.

The definition of preferred form to make modifications to a machine learning system is because machine

learning is the place where we have the challenges today of recognizing the new artifacts in

these AI, modern AI systems.

And so when we get into the preferred form to make modifications, we were looking for,

we were pushing the community to find a way to describe in generic terms, the intention.

And the intention is to have the possibility to recreate from scratch.

If I receive an AI system that I like and I wanted to give it to others, I need to be

able to have all the instructions and all the tools and all the data to recreate a substantially

equivalent system.

Because that's important.

That's one of the fundamental principles of open source has always been to be able to

have the instructions and be able to share those with others.

Now during the review process and during the co-design process, we asked volunteers to

evaluate existing systems and to rank the importance of some of the components.

And during that phase, a recommendation came out when they voted that many people voted

much higher the availability of the details about how the datasets were built rather than

the actual datasets.

So that gave us our suggestion that maybe it was worth testing the waters and understand

a little bit better what the issue around data is.

From the high level perspective, when approaching the problem, we realized, I mean, all of us

have had the same impression, data, the pipeline to build an AI system starts with data that

gets filtered, mangled, assembled, tokenized into a dataset.

The dataset gets fed into the training machine.

Training is an iterative process.

Data comes in at different stages.

All of this is complicated but should be described and made available.

And after the training is done, you get the parameters.

And with the parameters, you load them into an inference engine.

And that is what responds to, well, and you put an UI on top that gives you input and

outputs like think of chat GPT or other systems like that.

When you look from the distance at this whole pipeline, the intuition is that the whole

pipeline needs to be made available.

That whole pipeline is what you need to modify the preferred form to make modifications to

the system.

Now, when you start to zoom in, that's where the problem arises.

So when I started looking into one of these systems that in my mind were the two systems

that are the most open, the most freely licensed, freely made available, and that one is called

Pythia from the nonprofit called Eleuther AI.

The other one is from the research institute, ALEN AI Institute.

And Pythia has been trained on a dataset called the pile.

The pile is fully described.

There is that community working on it.

All the tools that have been used to assemble the pile, filter the pile, train Pythia using

the pile and all that, they're all released with open source licenses.

Now the pile has been an object of a takedown request for alleged copyright infringement

in the United States.

And since then, the original distributor of the pile has stopped distributing it.

Now you can still ask the Eleuther AI group to get the dataset, but the legal status of

the distribution of the pile is in jeopardy, or at least it's unclear in the United States.

But as discussions on the forum have revealed, the pile is perfectly legal in Japan.

And because it's distributed by a nonprofit and it's distributed for nonprofit uses,

maybe it's also legal in Europe, because Europe has reformed its copyright act a few years

ago and they have included an explicit exception for nonprofit text and data mining, which

is what the pile does.

So this raises a question, like what happens when you have...

Well, Dolma is in a similar situation.

Initially it was released with a license that doesn't obey, it's not compliant with the

open source definition.

It is imposing restrictions and permissions that needed to be asked to the island institute

before it could be used.

And then they changed the license.

So initially it would be not an open source dataset or an open dataset.

It has become an open dataset now with the change of license.

But upon looking at more closely, it contains probably the same issues that the pile has.

So someone could sue or request Dolma to be taken down for copyright infringement in the

United States.

So there are these legal issues around copyright, the fact that datasets can be open at a certain

point in time and not open at a later stage or vice versa.

And the legality of the distribution of this dataset may change over time and changes over

geographies.

So calling an open...

Anchoring the definition of open source AI to something that can change so quickly and

can change over time is challenging in many ways.

And there is another issue that is more technical.

There are ways to train systems without actually creating a dataset.

And one of these is called federated learning.

And in federated learning, each provider of datasets is more common.

It's common or, you know, yeah, it's common.

It's used with privacy preserving techniques.

If you have data that is owned by a different entity and they don't want to share it with

others, they don't want to create a pool for different reasons.

If they cannot create a pool because law, like privacy laws for medical records, for

example, doesn't allow hospitals to share data of their patients, then what they can

do is to set up training engines inside their own data centers.

And these training engines collaborate remotely in a privacy preserving way, training a model

without the data actually ever leaving their data centers.

So this technique creates models, parameters, but doesn't create datasets.

So when we were keeping this in mind, then we thought, OK, so this is a challenge and

we need to find another way to approach it.

And that's where we came up with the definition of data information.

Data information is, I didn't put this in the slides, but data information is described

in the draft, which I encourage everyone to look at.

The draft says that data information is, the intention here is to recreate an equivalent

system.

And the text says sufficiently detailed information about the data used to train the system.

So that, and this is the very important part, it's not just the information about this data

used to train the system, but the objective here needs to be taken into consideration

so that a skilled person can recreate a substantially equivalent system using the same or similar

data.

And this concept of the same or similar is important.

And I'll give you one example.

Let's say you have received a model that the original developer trained on Reddit.

This was an example brought up by Tom Callaway's bot from the AWS team, who doesn't agree with

the concept of data information.

And he said, what if someone trained on Reddit, but licensed the data from the Reddit corporations,

let's say for $100 million.

So you receive now, they have disclosed the data information, and they have given you

all the code, the source code used to train and run the system.

Now what about the, does that qualify, would that qualify as an open source AI?

Now, my answer to that, looking at the concept of data information, I want to be able, to

give an answer, I need to be able to know if I can build a substantially equivalent

system using the same or similar data.

So the same data would require me to enter into $100 million agreement with Reddit corporation.

But if you think about it, while thinking about it, I know that a data set called Common

Crawl contains the Reddit data already, despite the fact that Reddit tries to remove, to have

Common Crawl remove that data.

But that's a different story.

So Common Crawl has the Reddit data.

So before I can answer to the question, whether something trained on Reddit licensed data,

I need to extract, try to extract the Reddit data from Common Crawl, run the training.

If the model that I find, that I obtained at the end of the training, using the same

code from the people who have given it to me initially, if I get something that behaves

the same way, then I would say it's an open source AI.

If the original training data set from Reddit contains some really special source that makes

it impossible to replicate, then it would not be an open source AI.

And so I leave it at that.

I want to make clear that the intention at this stage of the definition, the preferred

form to make modifications to the system, is written in generic terms to accommodate

the fact that sometimes data sets don't exist and sometimes data sets cannot be distributed

or they can be distributed, but only in some geographies and only at different times.

So it's been written by lawyers and you can recognize in there some concepts like the

concept of the word skilled person, which is a term of art.

And it's meant to be a generic application of the principles of open source.

Now we have received also on the forums there have been proposals from Giulio Ferraglioli

and Tom to use something like synthetic data instead.

It's a fascinating example, definitely, and synthetic data is data created from scratch

by large language models and other techniques.

But it's really an unproven technology.

It would be really detrimental, I think, to anchor a definition to some technology that

is unproven, that is expensive and may not work in all cases.

Also this doesn't leave...

Yeah, it's unproven and it may not scale.

So what if?

And the other position that we have read in one of the comments, I think also this was

coming from Giulio, is that the whole pipeline must be open source before something can be

considered an open source system.

And I push back a little bit on this because if the GNU project, when it started and even

today, contemplates the option of running open source and free software, however you

want to call it, it's the same thing, on top of Windows, for example.

You can run...

You can...

The concept of free software that depends on proprietary libraries because they're part

of the system.

So the whole concept of complete, pure open source components in a system is not something

that exists in nature.

We have...

We, the communities around the world, have always accepted compromises when that led

to having more openness.

And I really want to have this clear and taken into consideration when we get into this debate.

And so these are the most important points.

There are other considerations that we have received.

I think, if we don't strictly require datasets, what are the incentives for other corporations

to reveal their...

To share, to create more open, more common datasets?

That is a very good question.

And in fact, I think that given the status of the legal status of policies around the

world that make the pile or dolma complicated to share is the reason why at the OSI, together

with Creative Commons, together with Open Future, we want to have a separate conversation

about the issue of data datasets and policies around that.

And we're working on a conference this year, sometime in October, to get this conversation

started because it's a very complex one.

We do recognize that there is an issue with creating datasets and sharing them.

And we wanted...

But we don't have right now clarity about how to fix this issue, how to create incentives,

how to create concepts like copyleft inside between data and training and models.

So that, for example, aggregators of large datasets who want to do the right thing, they

want to create more open models, they want to share their data in a way that preserves

the possibility for society to have access to models that can be controlled and shared

by larger groups, not just single vendors.

We don't know what the mechanisms are because copyright, which has helped us create copyleft,

does not help us cross the boundary between what is data and what is the trained model.

We need to think about contract laws, maybe, and maybe even policies like new law that

help us tie data to train models.

It's a complex topic, and that's why I think we're having such a tremendous amount of discussions

over two years of the investigations and then later the co-design process around the open

source AI definition.

All the hardest conversations have been around this concept of what about the data?

And I think we need to...

We really need to come to the conclusion that this is a very complex topic and that needs

to be...

The data issue needs to be taken in a separate trial.

And the other thing that I want to say is that the concept of data information, if you

read the definition and start from the end, start from the end, what is the intention?

The intention is to recreate a substantially equivalent system, whether you are using the

same data, exact data, because it's available, or whether you're using similar data because

one way or another you find it, but you end up with the same model, same behavior, then

that should be enough in the definition.

And by the way, so let's look at what...

Let's move on.

Let's look at what we have done to validate this hypothesis because that's how we've been

operating.

Let's look at examples.

Let's see what's happening out there in the wild.

We validated...

We went through a few systems.

We asked people to...

A few, more than...

Now we are at 12.

So we're trying to look at what happens with these systems.

Some we know, they are not passing the bar, like Lama and Mistral and Falcon and Grok.

Where does the definition fail?

We find that it's hard to find the components, right?

With people who don't know about it.

So for example, if you look at Grok, Grok is one perfect example.

It was developed by XAI, the Elon Musk thing, and they just share the model weights very

freely and nothing else.

Now if you don't find the other components, is it because they don't exist, which is probably

most likely, or is it because you couldn't find it?

The other thing is it's hard to understand that licenses sometimes if you don't have...

I mean, the volunteers, they may have limited knowledge about the terms of use and terms

of distribution.

So some of these reviews have been incomplete.

But despite this, we ended up, I think that we get a very easy sense.

We know that Falcon is missing information about 3M technology.

Their licenses have been modified.

They're not really compliant with the open source definition.

Grok, we know it's opaque.

Lama, we know it fails because of a variety of reasons, like lack of transparency, but

also it's missing other...

The license is not compliant.

But we know Alma, for example, they've been doing the right thing, and we expect it to

be a positive, passing the bar of open source AI.

By the way, they also released the data set.

And the similar is for PTA.

They're fully transparent, and they released the data set.

You can ask for it, and you can get it also.

But the issue remains with legal uncertainties around the world.

The other, Bloom, we know that we have everything.

It's transparent, but it fails because the license it uses for many of its components

are imposing restrictions and things like that.

So the concept of data information seems to be behaving exactly as expected.

And it's showing also that there is a very strong correlation.

Granted, it's a small sample, but there is a strong correlation between requiring data

information and having access to the data set to caveat those legal issues.

So I think it's working, and I'm not convinced that the alternative proposals are positive,

because the alternative proposals put PTA and even Olmo outside of the approved licenses.

And that is really not an acceptable outcome.

We cannot go credibly to either commercial partners, academia, and policymakers and say,

"This is the open source AI definition," and not have an answer when they say, "Okay,

which one is open source AI?"

And we cannot point at any examples, or we can only point at small, trivial academic

experiments as examples.

It's not going to work.

And it's not going to work because the industry and policymakers are already being pushed

to look at Lama and Mistral, and they consider those open source.

So if we don't come up with a counterproposal quickly, we will have lost an opportunity

here.

So what's next?

I really hope that we resolve these comments and we resolve this conversation around the

concept of data information with a release in 0.9, which we get support from organizations

that understand the principles behind it and validate it.

We started to get some positive feedback this week at a conference in Paris from Lina Gora

and publicly announced support for this concept, and others are coming in.

And then between July and October, we're going to have a series of release candidates with

trying to get more endorsements.

So there are two ways for you to help.

One is to look, keep on searching for systems that seem to be complying with the definition

0.8 or not, like complete, go on with the validation phase.

And yeah, and this is the timeline, and these are the things that we are, the places where

we're going to be speaking next and presenting and discussing with the community.

And as usual, try to join the forums.

I know I may have said in the past, also give us feedback through social media channels.

If you do that, please tag us because the algorithms on LinkedIn, some people are still

using X, et cetera.

We miss comments.

We miss the discussions.

They're very hard to find, and instead, the forums are the perfect place.

And of course, join the town halls because it's a time when we can ask live Q&A.

And with that, I will stop the speaking and see if there are any questions.

Well, I see that there's been quite a jump on the written form.

Trying to summarize.

Is there, do you want to?

Yeah, I think you all have voice rights.

You should be able to speak.

Do I have a path on the open source AI definition where Facebook's llama goes green on the list?

Yeah.

They release all of their training information, training data, and we can rebuild something

similar like that.

Yeah.

Yeah, exactly.

I got to say, conversations with commercial operators, I think that they tell me that

the secret sauce is actually in the training techniques because they seem to, that's where

the secret goes.

It looks to me, they tell me that that's where their secrets are.

How they score high on the leaderboards for benchmarks is how they train, and they don't

want to share it.

But I spoke with, for example, Lina Gora, they have this project called OpenLLM360,

France OpenLLM360, something like that.

And they've been training a system from scratch and they are releasing all of their information

and data, et cetera, because they want to do the right thing and they want to [inaudible

00:10:50] a model that is optimized for the French language.

So that other, and then they want to generate that collaboration on top of that.

So Honey Sabak comments that if we think the definitions settles on the training data method

must be open as well, then we may end up with few or no open source AI models.

It's one of the risks.

But also I want to point out that there is a little bit more than that.

The reason why I want to move on with the conversation, because it's a highlight how

complicated this is and how different from software this is.

On software, when you modify, you get access to the source code, you modify it and you

have to rebuild before you can ship it again.

So the concept of modification and studying are like that.

You study, you see the source code and you modify, rebuild and ship it.

For AI, you don't do this.

You can study just for the purpose to see if there are bugs you don't need to rebuild

or if there are issues, biases, et cetera, to evaluate a model around AI.

But for modifications, you have multiple ways of achieving the same goal without having

to retrain, which really is a much more interesting question to me than the debate about data.

How do we treat models that are fully disclosed, share their datasets, share the techniques

for the training when that training is fine tuning on proprietary models?

And I'll say more, that fine tuning is so deep that every layer of the neural network

has been rewritten so deeply that none of the behaviors and the benchmarks from the

original model apply to the retrained, fine-tuned model.

That is a huge question that we need to find an answer for today.

And it's been raised on the forum with an example of an AI system developed by Mozilla

to write captions for descriptions of images in the PDF.js tool.

And they mixed two proprietary models.

One is an object detection vision, computer vision model, and one is GPT-2.

It's a large language model.

We don't know anything about the training.

They have biases, etc.

Mozilla has fine-tuned these models, assembled them together to achieve a new system, a new

behavior.

It's that open source.

And they have released everything that they have done in a very reproducible fashion.

So what are we going to call this?

Is this open source AI built on top of non-open models?

Yes.

Interesting question.

Okay.

So, let's go back to the slides.

So, I'm going to show you a few slides.

And I'm going to show you a few examples.

So, let's go back to the slides.

So, this is the first slide.

And this is the second slide.

And this is the third slide.

And this is the fourth slide.

And this is the fifth slide.

And this is the sixth slide.

And this is the seventh slide.

And this is the eighth slide.

And this is the ninth slide.

And this is the tenth slide.

And this is the twelfth slide.

And this is the eighth slide.

And this is the ninth slide.

And this is the twelfth slide.

And this is the tenth slide.

And this is the eleventh slide.

And this is the twelfth slide.

And this is the thirteenth slide.

And this is the fifteenth slide.

And this is the sixteenth slide.

And this is the seventeenth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the seventeenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the seventeenth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the twelfth slide.

And this is the twelfth slide.

### End of last town hall held on 2024-06-14 ###

### Start of next town hall held on 2024-06-28 ###
--- Presentation for 2024-06-28 ---
OPEN SOURCE AI DEFINITION
Online public townhall
June 28, 2024
last updated: June 25, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

OSI’s objective for 2024

Open Source AI Definition

3

Open Source AI Deﬁnition

Current Version
OSAID v.0.0.8

4

Open
Source AI
Definition

Preamble
4 Freedoms

v.0.0.8

Legal Checklist

-

Open Source AI Deﬁnition

What We’re Working On
OSAID v.0.0.9

6

Open
Source AI
Definition
Preamble
v.0.0.9 plans
Clarifying that
the recipients
of the freedoms
are developers,
deployers and
end-users

Open
Source AI
Definition
Four
Freedoms
v.0.0.9 plans

Clarifying that the
four freedoms of
open source AI are
derived from the
Free Software
Definition

Open
Source AI
Definition
Four
Freedoms
v.0.0.9 plans

Underlining that
components and
systems must be
free from
encumbrances that
prevent any
developer, deployer,
or users from
exercising those
freedoms.

Open Source
AI Definition
Preferred
Form
v.0.0.9 plans

Adding definitions of…
… the “OSD
compliant”
requirement for data
information...
…and the “OSD
conformant”
requirement for model
parameters
..so legal
requirements are
clear for each
component

Open
Source AI
Definition
Checklist
v.0.0.9 plans

Checklist will be a
separate document
and process and its
components will be
updated to follow the
Model Openness
Framework (MOF)
precisely.

Open Source AI Deﬁnition

System Validation

OSAID v.0.0.8 (and soon v. 0.0.9)

12

Validation Updates

Thanks to Arctic and
LLM360 for helping identify
documentation!

13

Open Source AI Deﬁnition

What’s Next?

June - October 2024

● Complete validation phase
● Resolve comments, release v. 0.0.9 after
validation
● Cut the release candidate with sufficient
endorsement
14

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

June

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.8

July

August

September

Virtual System
Review

Virtual System
Review

Virtual System
Review Ends

Townhalls +

Townhalls +

Townhalls +

Townhalls +

- OSPOs for
Good (NYC)
- Sustain
Africa (virtual)

- AI-dev (Hong
Kong)

- Nerdearla
(Buenos Aires)

- All Things
Open (Raleigh)
- Data Workshop
(Europe TBD)

Draft 0.0.9

RC1

RC1

October

Stable
Version

In-Person Meetings
Region

Country

City

Conference

Date

North America

United States

Pittsburgh

✓ PyCon US

May 17

Europe

France

Paris

✓ OW2

June 11 - 12

North America

United States

New York

OSPOs for Good

July 9 - 11

Africa

Virtual

Virtual

Sustain Africa

July 15

Asia Paciﬁc

China

Hong Kong

AI_dev

August 23

Latin America

Argentina

Buenos Aires

Nerdearla

September 24 - 28

Europe

TBD

TBD

(data governance)

October

North America

United States

Raleigh

All Things Open

Oct 27 - 29
16

How to Participate :)
● Public forum: discuss.opensource.org
● Become an OSI member
○ Free or or full
○ SSO with other OSI websites
● Biweekly virtual townhalls… like this one!
● Volunteer to help with validation (email or DM Mer
Joyce)
17

Q&A

18

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the deﬁnition.

19


--- Subtitles for 2024-06-28 --- ###
to start the recording. Thank you. Yes. So welcome everyone to our biweekly town hall

for the open source AI definition process. And you can hear I've got a little bit of

a sore throat, but I'll hopefully be able to make it through. I will start. So these

are our community agreements that we have at every meeting. Some of you may have already

seen these. One mic, one speaker is about non-interrupting. Also when we get to the

Q&A, if you have multiple questions, please ask your question and then pause and let at

least one other person ask their own question before you ask a second question. Take space,

make space is a similar spirit. You know, just to invite others to share space with

us. And that some feel more shy and some feel more extroverted and everyone's voice matters.

Kindness is just that the work is hard, but we don't have to be. And just to remind ourselves

to be gentle and curious with each other, even when we disagree. Forward motion means

focusing on what's possible and not letting obstacles prevent the process from moving

forward. Similarly, solution seeking, just this work is very complex and it's vulnerable

to suggest a solution, but that is how we move forward. And anything else that people

would like to add to our community agreements for this meeting? You can say it in the chat

if you want. Okay. I'll continue. So yes, we are creating an open source AI definition

this year. And the current version is still 0.0.8. That's been the case for about a month.

And these are the pieces of it. Maybe Nick could drop the link to the HackMD page into

the chat because this is very hard to read. It just shows you the parts kind of as a map.

So we have a preamble. We have the four freedoms, studies, modify, and share as applied to AI.

And then we have the it's not circled, but we have preferred form for data information,

code and model. There's some description there. And then the current version also has a legal

thank you, Nick, has a legal checklist of what the licenses would be on the specific

components that would be required in those three categories of data information, code

and model. And what we're working on is versions. Yes. And we're open to comments. That's right.

And you can actually comment on that document. HackMD is a commenting platform. So what we're

working on right now is 0.0.9. And there will be some changes, a few changes. So in the

preamble, we are clarifying that recipients of the freedoms are developers, players, and

end users. So those freedoms of study, use, modification, and sharing. We are crediting

the Free Software Foundation for initially developing these four freedoms because crediting

people is a good thing to do. And so we're adding that in. And you can see in this larger

box how those freedoms are enumerated or described. The language should not be surprising to anyone.

And we did develop these four freedoms in a series of co-design workshops at the end

of last year. Also in the four freedoms, we are going to, in 0.0.9, underline that the

components must be free from encumbrance. That prevents any of those three user types,

developer, deployer, or end user from exercising the freedoms. So just underlining that, yes,

the four freedoms must be respected. And also if you're a little confused, you're not seeing

0.0.9 in these images. You're seeing 0.0.8. But I'm just indicating where the changes

will be. Also in preferred form, we are going to add

definitions which will be just a phrase, not a sentence, for the terms OSD compliant, which

is a requirement of data information, and OSD conformant, which is a requirement of

model parameters so that the legal requirements are clear. And the code components just need

to be licensed under an OSI approved license. So that's very straightforward. The code or

software can exist under those licenses. And the licensing and legal requirements are slightly

different for those other types of components. And so we're going to define what these terms

mean, compliant and conformant, the next version. And then, oh, someone unmuted themselves.

Please just stand by until the Q&A. If you have a question that you'd like to ask before

the Q&A, you can drop it in the chat. Okay. So the checklist. The checklist, we are in

the next version going to actually move it into a separate document. We realized that

in trying to create the definition and also to operationalize the definition in the same

process was a bit like jogging and juggling at the same time. And so we thought, let's

just focus on the definition. Let's basically the definition will stop at preferred form.

And then obviously operationalization of the definition is quite important. And that is

the checklist. And we're just going to separate those documents and also those processes.

One change that you will see in the checklist in version 9, and I guess we'll figure out

how to label the versions of these documents as well. But if you're not, we will figure

that out. It will be updated so that all the components are from the model openness framework.

So right now, if you look on the left, the data information components are coming from

the EU AI Act. So training methodologies and techniques, training, data scope and characteristics,

training data providence, etc. Those are not coming from the model openness framework,

which is a list of components from the Linux Foundation. It's coming from the EU AI Act.

And we just because of all the great work that the Linux Foundation is doing to create

an online compendium of AI systems and the openness of their components, we really want

to be able to rely on that for our own definition. And so we are going to use their component

list exclusively in our in our checklist. And I'll just read Stefano's comment, the

data information piece is going to look the same in 0.0.9. Oh, not because it's decided,

but because the topic is still being discussed. Okay, got it. So okay, so we're not yet. So

eventually, we will be transitioning over to model openness framework components. That's

not happening in 0.0.9. Thank you for the clarification. Okay, system validation. It's

pretty much the same as last time. So thank you to Arctic and LLM 360 for helping to identify

documentation, we found that it's really crucial to have creators help out with identifying

the legal documents describing the rights and permissions associated with the components

of their systems. So this screenshot of the progress and validation based on the process

of the review, which is being done by volunteers. And also the the results of that review so

far have not have not changed since last time. And yeah, we just find that we do need creators

to help provide documentation in order to to know whether a system would meet the requirements

of the open source AI definition. And Stefano's typing. I'll just wait for that if it's on

validation. Okay, pause. I'll read I'll read the comments if it comes up. Okay, so what's

next June, which we're almost at the end of through October, we do we want to obviously

complete the validation phase resolve comments and release versions 0.7.9. And then cut the

release candidate with sufficient endorsement, organizational endorsement. Okay, just keep

going. And this is our timeline, we had to update our timeline, because it ended at June,

I believe. And now we have to think through to the end of the project in October. So we

will be at hospitals for good in New York, both the UN event and the side event. We will

this is in July, I'll be doing a virtual event for sustain Africa. And this is to share the

OSAID and also to get further feedback. Let me pause and read what Stefano is writing.

The 0.0.9 draft includes a lot of small changes accumulated over two months since the release

of the previous draft, but all the pieces of 0.0.9 can still change based on community

feedback. Okay, that makes sense. Okay, so August, we'll be in Hong Kong for AI dev. And

September. Gosh, let's see if I can pronounce this correctly with my cold. Merdeala. Okay,

that's pretty good. And Buenos Aires. And then October, we will be launching the stable

version of the definition at all things open in Raleigh in the US. And then we will also

be doing a data workshop in Europe, in a city TBD. And the focus of that workshop, it will

be to write a policy paper to try to resolve some of these challenges with the sharing

of data sets. Yeah. Yeah. And as Stefano is saying, nothing is set in stone yet. Okay.

So yes, and actually, you've actually already seen most of these. Yep. The different events

that we're going to and when they are. So how to participate in this process. We do

share updates on the process and opportunities for volunteering also discuss issues of you

know, disagreement and difference of opinion on the public forum, which is discussed on

open source.org, which you can join for free, you do have to sign up just to prevent spam.

And then we have these bi weekly town halls, both for the this is one for the Europe, North

America and our Americas time zone. And then we have a second one. That is Europe, Africa

and Asia. So we cycle back between those two times. And then yes, if you would like to

volunteer a validation, particularly I think about volunteering we need at this point is

if you are the creator of a an AI system and would like to, you know, show that it is open

according to the definition that we have now, that that would be the most valuable type

of volunteer just because those are those are the those individuals that have this documentation

information most at hand. Yes, there's also a blog that we update and I can share that

and their summaries are shared every Monday on the blog. And yes, we highly recommend

the weekly summaries. So yeah, we will now do a Q&A. And what you can do is, I think,

raise, raise your hand and you can come off mute or you can just ask in the chat and I'll

read it like I've been doing throughout the meeting up to you. Love to hear your thoughts.

And for all those who who are not as familiar with our organization, Stefano, whose shots

I was reading is the executive director of the OSI. So if anyone was wondering why, why

is she reading aloud all these comments from this one participant? That is why he can't

participate live today. But that's why I was reading his comments. So yeah, I will just

be shy for a bit. Yeah, don't be shy. Yeah, don't be shy. You can actually click on the

microphone and speak or you can just chat as well. It's OK. Yes. OK. Oh, you're welcome,

Stefano. Yeah, thank you so much for coming. OK, yeah, go ahead, Gerardo, you can unmute

yourself. Hi. Yes. What's your question? I've been participating in several standard committees

on IEEE about the ethical use of AI and several AI definitions, and I'm finding that most

of the people I met there have not yet, do not yet know about this initiative and I'm

changing that. But I've been wondering if we don't need to push this discussion a little

bit forward with the scientific community, especially with certain researchers that are

dealing with this on several bases. I think I've covered most of the AI ethics discussions

that are occurring, but it seems to me there's more going on that probably we should be a

part of. OK, yeah, I may not be the person to respond to that. My primary role is or

my role is running the co-design process of the definition itself within OSI. But Stefano's

typing, but that sounds very, does sound very useful. And thank you for bringing those experiences

you had in other organization and standards making processes here. That's very, very helpful

to us. Gerardo, so we're working with several researchers and several organizations as well

and we would love if you have contacts with other researchers with whom we could work

with, that would be splendid. I just would like to highlight something because you mentioned

ethics, right? So even though, yes, ethics is really important for us, we want to see

open source AI being used for good, right? For the benefit of humanity. But ethics, as

the open source AI definition is concerned, is out of scope. It doesn't mean it doesn't

matter. It does matter that open source AI is used for the good, but it's just something

out of scope. I'm not sure if that clarifies your question.

Well, it's more on the way that for most of the discussions we are having, some of them

are about the age of tools and so on. There is a need for those groups to know a little

bit of the strains that we want to impose on these AI models to be labeled open source.

Because it's something, when you're talking about the ethics of using AI, that also brings

in the fact that the open source approach is more ethical in the terms of the way things

are constructed, in terms of the transparency, the sharing of knowledge. And one of the concerns

most of all of these groups are in is the issue of explainability. And probably that's

something else, but probably something that we should be addressing. The explainability

becomes easier when something is really transparent and clear and open source, more or less forces

you into this. And so it's more the other way around. It's not that this issue depends

on them. It's more that they, that's my part, they have to be aware of all of this.

That's a very good point. In fact, we are in touch with a few researchers around explainable

AI. And it's really, really interesting. So happy to connect with you. Thank you.

Thank you. Thank you. Does anyone else have a different question? Thank you, Gerardo and

Rick.

Hello, Anastasia. So I see a comment about how the data information piece is going to

stay the same in 0.9. Is that talking about how you're not going to change how you address

the topic of data and the availability of information about the data? And I guess I'm

curious about the general thinking since open data may not always be realistic, but it is

this potentially important piece. So I'm curious about the focus or lack of focus on open data.

I guess just in general.

Yeah, I would actually, Stefano, if you want to chat or come off mute, I would love for

you to answer that since it seems like you I mean, Stefano is is the leader on that particular

element of this. If he is on the chat. He is. Oh, but he is not. I see his. So I'm I

in the absence of Stefano, who made a correction on something in my slide. So obviously he

has information I don't. I actually can't give anything other than what he just said.

So there's two pieces of information shared. One one is that data information will not

change from output. Oh, Stefano is coming back on. Stefano, we were wondering if you

could answer. OK, I would still just love for you to answer Anastasia's question.

Did you want her to ask again? Did you hear it? OK, I know all he knows. OK, so then I'll

just continue. So there's two pieces of information shared once that data information will not

change from 0.0.8, the link to which Nick shared and also that the checklist will conform

to the MOF. So the way that I take that to mean. Is that.

Stefano, do you want to do you want to speak? I don't know if you're maybe you're not

know that you can speak. OK, it won't change only because the discussion is not complete.

OK, OK, OK, can't speak. OK, yes. So there will be there will be a shift to the components

coming from the model openness framework or MOF. And there may be I guess there may be

other changes as well, because Stefano is saying the discussion is not complete.

So maybe I can, Ximing, mirror. So there has been a lot of discussions around the data

information and I'll share a blog post as well that Stef wrote, which is very interesting

and also point a discussion topic that we have here. This is something that we're receiving

a lot of feedback and hearing the working group members also participated in those discussions

and to try to understand the role of data and data information. And this is actually

a crucial point of the open source CI definition. So let me just drop some links here and we

look forward to hearing more feedback on the discussion forum.

OK, thank you. And Stefano has just written, we may even remove the text altogether and

put a placeholder instead. And thank you, Nick, for that explainer link to the explainer

post on data information. I I'm sorry if that wasn't satisfying, Anastasia. That is that

is the level of response that I think we can give to you right now. But thank you for asking

the question. Does anyone else have a question? Yes, Gerardo, go ahead.

Just one more probably comes from the model we are working with, but I have an issue with

defining codes that trains and codes that trains a model and code that uses a model

of the same thing. And I think we should be splitting those and make it so that it's more

explicit to say that both parts are to be open source, first of all, because they are

probably not the same thing and and that most of the "open" AI things usually have that

second part of the code open and open source, the thing that uses the model to generate

stuff. But they keep close the code that was used to generate the model. And I think it

may be important to split and make it explicit that both parts are considered codes and they

are and they have to be open license and open source for the whole thing to be open source.

And something I haven't yet seen and why it's defined here as just one thing, but usually

it can become those two codes can be developed separately by different people on different

teams. And there could be, let us say, the temptation to license to open license one

and not the other.

Okay, so regarding the three kind of categories of AI systems, we have data information, code

and model, we are basically trying to have as few categories as possible that were still

descriptive of the different types. And obviously, there were other types of categorization we

could have used. That one seems pretty solid. In terms of the types of code, we are using

this maybe, maybe you're aware of this, and maybe not. This list of types of code components

or artifacts used to create AI systems, or used in AI systems from this model openness

framework that was developed by a group of researchers and practitioners at and affiliated

with the Linux Foundation. And we so as not to invent the wheel, because there's so much

that we are doing ourselves, we said, How can we rely on the brilliance of others. And

so we are using those code components. So we are we are not going to, I believe, change

those components as listed in this document. And maybe Nick could even share a link to

that it's a white paper is where those components live. Now, I think the Linux Foundation is

also spinning up some websites and landing pages. But as of now, I know that they that

you can find those in the white paper. So we are we're, we will just rely on that work

that they've done. Let's maybe take one more question. And then Yeah, you're welcome to

order. And then we'll call it a day. And Stefan, I was just saying we all care about open data.

And we're very concerned about the issue of accessing data suitable to train an AI, which

is true. Yep, absolutely. So, um, okay. Any, any other question from someone? I would say

another question from someone who hasn't asked one yet. And I'll just keep reading what Stefan

was saying, because he would be presenting with me if he were available. So he's saying

we're also planning a conference specifically on this topic, which is that event in October,

in in Europe in the city TBD is that comments or workshop on data, the issue of data and

AI, which is such a substantial one. Um, okay, I'm not seeing any questions. Thank you. Thank

you to everyone who came and who did ask a question that was really useful. Yeah, thank

you, Gerardo. Thumbs up. Yeah, so I think we can turn off the recording. And thank you

everyone for coming and have a have a wonderful weekend and do find us

### End of last town hall held on 2024-06-28 ###

### Start of next town hall held on 2024-07-26 ###
--- Presentation for 2024-07-26 ---
OPEN SOURCE AI DEFINITION
Online public townhall
July 26, 2024
last updated: July 26, 2024 (NV)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

OSI’s objective for 2024

Open Source AI Definition

3

Open Source AI Deﬁnition

Current Version
OSAID v.0.0.8

4

Open
Source AI
Definition

Preamble
4 Freedoms

v.0.0.8

Legal Checklist

-

Open Source AI Deﬁnition

What We’re Working On
OSAID v.0.0.9

6

Open
Source AI
Definition
Preamble
v.0.0.9 plans
Clarifying that
the recipients
of the freedoms
are developers,
deployers and
end-users

Open
Source AI
Definition
Four
Freedoms
v.0.0.9 plans

Clarifying that the
four freedoms of
open source AI are
derived from the
Free Software
Definition

Open
Source AI
Definition
Four
Freedoms
v.0.0.9 plans

Underlining that
components and
systems must be
free from
encumbrances that
prevent any
developer, deployer,
or users from
exercising those
freedoms.

Open Source
AI Definition
Preferred
Form
v.0.0.9 plans

Adding definitions of…
… the “OSD
compliant”
requirement for data
information...
…and the “OSD
conformant”
requirement for model
parameters
..so legal
requirements are
clear for each
component

Open
Source AI
Definition
Checklist
v.0.0.9 plans

Checklist will be a
separate document
and process and its
components will be
updated to follow the
Model Openness
Framework (MOF)
precisely.

Open Source AI Deﬁnition

System Validation

OSAID v.0.0.8 (and soon v. 0.0.9)

12

Validation Reviewers
1. Arctic
1.

Jesús M.
Gonzalez-Barahona
Universidad Rey Juan
Carlos

2. BLOOM
2.
3.

Danish Contractor
BLOOM Model Gov.
Work Group
Jaan Li University of
Tartu, One Fact
Foundation

3. Falcon
1.
2.

Casey Valk Nutanix
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France

4. Grok
1.
2.

Victor Lu independent
database consultant
Karsten Wade Open
Community Architects

We were interested in reviewing about 10 AI systems self-described as
open to validate the definition.

5. Llama 2
1.
2.
3.
4.

Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute of
Paris
Victor Lu independent
database consultant

9. LLM360
5.

[Team member TBD]
LLM360

8. Mistral
1.
2.
3.

Mark Collier
OpenInfra Foundation
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
Cailean Osborne
University of Oxford,
Linux Foundation

7. OLMo
4.
5.

Amanda Casari
Google
Abdoulaye Diack
Google

10. Pythia*
1.
2.
3.

Hailey Schoelkopf
EleutherAI

4.

Aviya Skowron
EleutherAI

11. T5
5.

8. OpenCV*
1.

We will need an
independent
reviewer for
LLM360

Rasim Sen Oasis
Software Technology
Ltd.

9. Phi-2
6.

Seo-Young Isabelle
Hwang Samsung

Seo-Young Isabelle
Hwang Samsung
Stella Biderman
EleutherAI

Jaan Li University of
Tartu, One Fact
Foundation

Viking
6.

Merlijn Sebrechts
Ghent University

Validation Updates

Thanks to Arctic and
LLM360 for helping identify
documentation!

14

Open Source AI Deﬁnition

What’s Next?

June - October 2024

● Complete validation phase
● Resolve comments, release v. 0.0.9 after
validation
● Cut the release candidate with sufficient
endorsement
15

Board Guidance
The OSI Board requires a deﬁnition that is:
Supported by diverse
stakeholders

Provides real-life
examples

Ready by October
2024

The deﬁnition needs to
have approval by end
users, developers,
deployers and subjects of
AI, globally.

The deﬁnition must include
relevant examples of AI
systems that comply with it
at the time of approval, so
cannot have an empty set.

A usable version of the
deﬁnition needs to be
ready for approval by the
board at the October
board meeting.

Approved June 21, 2024

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

June

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.8

July

August

September

Virtual System
Review

Virtual System
Review

Virtual System
Review Ends

Townhalls +

Townhalls +

Townhalls +

Townhalls +

- OSPOs for
Good (NYC)
- Sustain
Africa (virtual)

- AI-dev (Hong
Kong)

- Nerdearla
(Buenos Aires)

- All Things
Open (Raleigh)
- Data Workshop
(Europe TBD)

Draft 0.0.9

RC1

RC1

October

Stable
Version

In-Person Meetings
Region

Country

City

Conference

Date

North America

United States

Pittsburgh

✓ PyCon US

May 17

Europe

France

Paris

✓ OW2

June 11 - 12

North America

United States

New York

✓ OSPOs for Good

July 9 - 11

Africa

Virtual

Virtual

✓ Sustain Africa

July 15

Asia Paciﬁc

China

Hong Kong

AI_dev

August 23

Latin America

Argentina

Buenos Aires

Nerdearla

September 24 - 28

Europe

France

Paris

Data governance

October

North America

United States

Raleigh

All Things Open

Oct 27 - 29
18

Co-Design Workshop in Raleigh, USA
All Things Open Conference | October 2023

19

Co-Design Workshop in Monterey, USA
Linux Foundation Member Summit | October 2023

20

Co-Design Workshop in Addis Ababa, Ethiopia
Digital Public Goods Alliance Members Meeting | November 2023

21

How to Participate :)
● Public forum: discuss.opensource.org
● Become an OSI member
○ Free or or full
○ SSO with other OSI websites
● Biweekly virtual townhalls… like this one!
● Volunteer to help with validation (email or DM Mer
Joyce)
22

Q&A

23

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the deﬁnition.

24


--- Subtitles for 2024-07-26 --- ###
So, first of all, let me introduce myself.

My name is Nick Vidal.

I'm the community manager at the OSI, the Open Source Initiative.

And every two weeks, we organize a public town hall about the open source AI definition.

The goal of this town hall is to give updates and news about what has been happening with

the definition and also to hear your feedback and see how we can make it better.

So let's jump to the rules, right?

What are some agreements that we have here?

I think we can all be very open and very kind.

The idea here, even though if we have any differences, we can agree to disagree.

And so this is especially important when I open space for questions.

You're free to ask any questions and I'll be happy to answer them as best as possible.

So let's talk about the open source AI definition and where we are.

We have been at version 0.0.8 for quite some time right now.

And the reason for that is that we received a lot of feedback and we are working those

details because the next one, the next version will be something much more stable and really

with very few changes going forward.

So the current definition, what we have right now is we have the preamble, we have the four

freedoms and a checklist.

Now what are we working for version 0.0.9?

There are going to be some significant changes based on this feedback and we're about to

release version 0.0.9.

It's just a matter of a final approval.

And we still have the preamble and we try to clarify who are the recipients of the freedoms.

We also have the what's open source AI and we clarify those four freedoms.

As you know, we have the freedom to use, to study, to modify and to share the system.

And for those who know, who have some background on the history of free software and open source,

you know very well that those four freedoms are from the free software definition.

And this has been very stable.

We have been using those four freedoms as the basis throughout most of the moment.

Now one observation that we're also making is that we are underlining that components

and systems must be free from encumbrances that prevent any developer, deployer or user

from exercising those freedoms.

So this is something that we highlighted for this version as well.

And now we made some substantial changes to the preferred form to make modifications to

machine learning systems.

And the reason why we did that, we received a lot of feedback and we wanted to really

make this as precise as possible.

So we added the definitions, right?

Also there's the question of OSD compliance and OSD conformance for each one of those

requirements, right?

And also the legal requirements for each components.

So we made this text here, the preferred form, clearer for us to understand.

And now this is a big one.

Since the definition is going to be something very stable, we cannot make, we shouldn't

make many changes with every version.

We want to have something very solid.

So this, the definition itself should not change much.

However, we know that the technologies are evolving very rapidly and there might be some

changes to the legal framework or to each one of those components.

And so what we're doing for 0.0.9 is actually we're going to make the checklist as a separate

document because the definition is going to be stable.

And the checklist, we might have some smaller changes, of course, but it's going to evolve,

right?

And I wanted to highlight that we use as the list of components, the model openness

framework.

This is something that was created by the Linux Foundation and they have 17 components

and we're using that as a basis, right?

For the checklist.

Now we are currently validating the open source CI definition, looking at several models.

Right now we're looking at Arctic, Bloom, Falcon, Grok, Yamachu, LLM360, Mistral, Oumu,

OpenCV, Fitu, Pythia, T5, and also I believe Vykan, we added that as well.

So the idea behind this is we are looking at the open source CI definition and looking

at the different models and different AI systems that exist.

And we are matching that, looking at the checklist and seeing if those systems are in fact, if

they achieve this, right?

If the open source CI definition applies well to them and we're validating this.

And so as part of this validation updates, here are the current results so far.

So looking at Arctic, for example, this is a large language model by Snowflake and it's

actually pretty good.

It's pretty open.

And we are looking at those different systems and for Arctic, we believe that it's expected

that it does, yes, fulfill the open source CI definition, all the checklists.

So it's very likely that Arctic is an open source AI, right?

Now we have other systems which can be a bit more challenging, right?

So Bloom, Bloom is regarded as an open model by some, but at the same time, they use Rail,

which is very restrictive.

It does not match the open source CI definition on that regard.

And if we look at all other models as well, we see that a few of them, the ones that we

expect to actually be considered open, in fact, they are, they are validating.

So for example, Omo, it's a very open and it's likely that it meets the open source

CI definition requirements.

And AlphaBifia, it's a confirmed yes right now.

So this validation process is important, right?

Now this, what's next?

What's the timeline?

What's happening?

We have this validation phase.

We are looking at the comments.

We're about to release version 0.0.9 after this validation.

We want to have a release candidate.

Also there's a guidance from the board and this is really important.

So the board has three requirements, right, for this definition.

It has to be supported by diverse stakeholders, right?

Also it must provide real life examples.

We don't want a definition that there's no AI system that actually matches that.

So it's important for us to have this, at least a few cases where those AI systems match

the open source CI definition.

They fulfill the open source CI definition.

And we really want to have this stable version by October, at all things open, where we're

going to be announcing this.

So we have this, this restriction on time.

We cannot just go on for this forever.

In fact, a lot of, there's a lot going on around policies and legislation around the

world.

And a definition, a clear definition really is really important.

So we're trying to run against the clock, right?

Basically this is a timeline throughout this past month, we've been attending several events

worldwide.

So July, right now we were in New York City for an event called Auspice for Good that

happened in the United Nations headquarters in New York.

And we also participated in Sustain Africa.

August is coming up.

We're still going to organize those online events, especially because not everyone can

travel, right?

And this makes it more accessible.

But we're going to attend AI Dev in Hong Kong.

This is an event by the Linux Foundation.

We're going to give a talk there.

We're also going to be in Northern Ireland, Buenos Aires.

So we want to make sure that we keep AI Dev will happen in Hong Kong, in Asia.

Northern Ireland, in Buenos Aires, in Latin America.

We just came from an event in New York.

So we really try to make this as representative as possible.

We're trying to organize an in-person event in Africa as well.

And I think we're finalizing that as well.

So we're trying to make the events as accessible as possible by making it online, but also

in-person events and representative of the whole world, right?

For October, then we have the All Things Open events, an important event around open source.

And by then, we hope to announce the stable version of the definition.

Also there's an event, a very small meeting around data.

But this is, we've been gathering mostly nonprofit organizations to be part of this meeting.

It's really small and it's fully booked.

So apologies if we cannot open it up more.

We will try to organize other events as well and invite people to be part of that.

This is the list of some events that have been happening these past months.

We were also in France for OW2.

And so you can see the dates here.

And this in-person events, they have been important.

We have been able to hear a lot of good feedback from everyone and really try to come up with

a definition that it has a lot of backing from people, right?

And so I would like to invite you to participate at these events, the events in person as well.

Also the public forum, you can go to discuss.opensource.org and comments on the drafts or any other topic

that you like to understand.

It's totally free.

You can join.

You don't have to join as an OSI paying member.

You can join as a free member as well.

And you have an access to the forum.

We're going to continue organizing this biweekly virtual townhouse.

And here is an opportunity for you to ask questions and try to understand what's really

happening, right?

Invite you if you want to volunteer for the validation process.

I believe right now it's the working groups are closed, but you can still email us to

know if there's still an opportunity.

And that's it.

So right now I'm going to open up spaces for questions and answers.

You can either ask questions on chats, if you have your microphone option open as well,

you can ask that question live.

And I'm available to answer your questions as best as I can.

>> I have a quick question.

Do you think there are only a few people on this call because there's not a release of

the .9 to discuss or sort of is that why this call is so quiet?

>> Yes.

So this is our 13th townhouse.

And so it has been we do this every two weeks.

And I think right now there's a high expectation for version 0.0.9.

We've been discussing 0.0.8 for quite some time right now.

And I think most of the questions around this version have been answered.

So people are really expecting a new version.

And highly so.

So are we.

We're just waiting for a final decision from the board to release the version.

I expect that we're going to have more questions around that.

>> Okay.

I have another question.

What about the events in Hong Kong and Buenos Aires?

Are there going to be more discussions, like presentations or more discussions or are they

panels?

Can you tell me any more about what's planned specifically for Hong Kong?

>> Of course.

Yeah.

For AI Dev Hong Kong, we're going to have a talk from Mare Joyce, who is the facilitator

of the open source AI definition.

And also from Annie Lai, who is the chair of the Linux Foundation AI and Data.

So they're going to give this talk.

And I believe they're also going to be available for any discussions.

I don't think we have a panel there.

Now for Buenos Aires, for Nerdiarla, there's going to be I see that there's a yes.

So we're going to have a presentation by Mare Joyce and staff.

And are we going to have a panel there or a I believe we're going to have a workshop

as well.

This is being confirmed right now by Holo, who is organizing this.

Yeah.

We're going to have a workshop as well.

It's very likely we're going to have a workshop there.

And it's this event in Buenos Aires is pretty huge.

It's 10,000 participants.

And very well organized events.

So I highly recommend it as well.

Anyone has any other questions?

Of course.

Yeah.

So let me share the link here.

Oh, thanks, Holo.

Holo has already added that.

In fact, Holo is one of the organizers of the events.

The leading organizer.

If you'd like to reach out to him directly, Holo, maybe if you could base your email

or all right.

Yeah.

Feel free to reach out to Holo regarding the events.

All right.

So if there are no other questions, this is going to be made available, the slides and

the recording.

I'm going to be basing this on the forum.

And thank you so much.

We really appreciate it.

And we look forward to your feedback on the forum as well.

All right?

Have a great weekend.

Bye bye.

Bye bye.

Bye bye.

### End of last town hall held on 2024-07-26 ###

### Start of next town hall held on 2024-08-23 ###
--- Presentation for 2024-08-23 ---
OPEN SOURCE AI DEFINITION
Online public townhall
August 23, 2024
last updated: August 23, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

Open Source AI Deﬁnition

New Version
OSAID v.0.0.9

3

Unveiling the Future:
Nurturing Openness in AI Development
揭示未来: 培育人工智能开放性发展
Anni Lai

Chair, Generative AI Commons, LF
AI & Data
Head of Open Source Operations,
Futurewei

Mer Joyce

Founder
Do Big Good LLC
Co-Design Facilitator, Open Source AI
Deﬁnition
Open Source Initiative

🥳 New Today: OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open
Source AI System must include:

Open

Weights
Model weights and
parameters

Open

+ Code +
Source code used
to train and run
the system

Data

Information
The dataset or
detailed information
about the data used
to train the system

New Version: OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Weights
The model weights and
parameters, made available
under OSI-approved terms
Examples: checkpoints from key intermediate stages of training as
well as the ﬁnal optimizer state

New Version: OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Code
The source code used to train and
run the system, made available
with OSI-approved licenses
Examples: code used for pre-processing data, training, validation and testing,
supporting libraries like tokenizers and hyperparameters search code,
inference code, and model architecture.

New Version: OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Data

Information
Sufﬁciently detailed information about the data used to
train the system, so that a skilled person can recreate a
substantially equivalent system using the same or
similar data. Data information shall be made available
with licenses that comply with the Open Source
Deﬁnition.
Examples: training methodologies and
techniques, training data sets used, information
about the provenance of those data sets, their scope and characteristics, how the data
was obtained and selected, the labeling procedures and data cleaning methodologies.

Training Data in the OSAID
OSI afﬁrms the beneﬁts of full access to training data while acknowledging it
is not always possible for reasons of law, privacy norms, technical feasibility,
and cultural practice.
• Training data is valuable to study AI systems: to understand the biases that have been
learned, which can impact system behavior. But training data is not part of the preferred
form for making modiﬁcations to an existing AI system
• Data can be hard to share. Laws that permit training on data often limit the resharing of that
same data to protect copyright or other interests.
• Privacy rules also give a person the rightful ability to control their most sensitive information,
such as decisions about their health.
• Similarly, much of the world’s Indigenous knowledge is protected through mechanisms that
are not compatible with later-developed frameworks for rights exclusivity and sharing.
• Open training data (data that can be reshared) provides the best way to enable users to study
the system, along with the preferred form of making modiﬁcations.
• Public training data (data others can inspect as long as it remains available) also enables
users to study the work, along with the preferred form.

OSAID Approval Criteria
OSI Board requires a deﬁnition that is:
Supported
by diverse
stakeholders

Provides
real-life
examples

Ready by
October 2024

The deﬁnition
needs to have
approval by end
users, developers,
deployers and
subjects of AI,
globally.

The deﬁnition must
include relevant
examples of AI
systems that comply
with it at the time of
approval, so cannot
have an empty set.

A usable version
of the deﬁnition
needs to be ready
for approval by
the board at the
October board
meeting.

Approved June 21, 2024

Open Source AI Deﬁnition

What’s Next?

September - October 2024

● Resolve comments, release RC1
● Launch stable version at All Things Opens

11

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

June

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.8

July

August

September

Virtual System
Review

Virtual System
Review

Virtual System
Review Ends

October

Hi!

Townhalls +

Townhalls +

Townhalls +

Townhalls +

- OSPOs for
Good (NYC)
- OSCA (virtual)

- AI-dev (Hong
Kong)

- Deep Learning Indaba
(Dakar)
- IndiaFOSS (Bengaluru)
- Nerdearla (Buenos Aires)

- All Things Open
(Raleigh)
- OSAI Data
Workshop (Paris)

Draft 0.0.8

Draft 0.0.9

RC1

Stable
Version

How to Participate :)
● Public forum: discuss.opensource.org
● Become an OSI member
○ Free or or full
○ SSO with other OSI websites
● Biweekly virtual townhalls… like this one!
● Volunteer to help with validation (email or DM Mer
Joyce)
13

Q&A

14

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the deﬁnition.

15


--- Subtitles for 2024-08-23 --- ###
I don't... oh now it's being recorded. Okay. Yeah. Okay. So now we're being recorded.

This is the Q&A session for those who are watching the recording. The

presentation has already occurred. Yeah. Sounds good. Nick. Nick is commenting. He's

going to record the Q&A. I believe Stefano will be in Vienna. I do not know

if there will be a workshop or session on the OSAID, but I think Stefano will

be in Vienna personally. Yeah. It's not on my official list, but Nick maybe you have

some information about that. Oh he will be presenting, but not giving a workshop.

Okay. Thanks Nick. All right. Oh okay. Yeah. She and I presented today as I

mentioned earlier. I don't know if people in the recording can see the chat, but

we're just saying that Stefano is going to present with Annie Lai of the Linux

Foundation in Vienna. Yeah. I'll hang out here at least till the half hour to chat

with him, but the formal program has ended.

And Nick will also hang out.

You're welcome.

Ah could I share a bit about my presentation in Hong Kong? Yeah. So it was

those slides that you all saw. I guess it's not I can go back so it's in the

recording, but these are the slides. This is what it what it was called unveiling

the future nurturing openness in AI development, which was Annie's creation.

And Annie talked about the Linux Foundation generative AI Commons

projects, the model openness framework, and the model openness tool. And then I

spoke about the OSAID and specifically talked about not only version 0.0.9

which you saw, but I also spoke about the co-design process both creating the

for freedoms for open source AI and also identifying the required

components using our virtual work groups. And that's been covered in past

workshops. But that was the that was what I presented in Hong Kong. And then

Stefano was also there and so he participated in the Q&A and that was

great. What was the questions? I think there was there was a question about AU

policy and the feasibility of implementation. And then there was a

question in Chinese and Annie fortunately speaks Chinese. And I believe it was

about there were two. One was about the legal implications of the definition. And

the second question was about just asking for why why use open source AI?

Why make a system open source? And so Annie reiterated the benefits of openness

for AI. So yeah.

Oh, loss of connection.

I think I'm still I can still see you chatting. Okay. It said I had lost

internet. Okay. Early impressions on the new, so I'm just going to read Martin's

comment. My early impressions on the new data requirements in 0.0.9 have been good.

Okay. It seems to do the best with a complex situation. We'll keep thinking

about any loopholes. Thank you, Martin. That is basically what we have also

found is this is a compromise. There are people that wish that the definition

were more stringent and there are people that wish it were looser. So there's pull

on both ends. But that's probably some symptom of a compromise. So yeah. I'm

glad that you're seeing that too.

Okay. If training data had been required, how many models would have met that? Yes.

So I think there would have been a few. I think Olmo I think might have met it. I

think the concern was about the legality of the data that there is a risk of

lawsuits or of the data being legally shareable in certain jurisdictions but

not others. And that we wanted to have a definition that would have a global

could be implemented globally and that systems wouldn't be hung up on or be on

possible legal actions. So that is my understanding. And Nick, feel free to

yeah there you go. Olmo and Pythia. Yes. Right. Yes. Yes. So there's a nice forum

post about yeah I could try to find it that talks about the legal

uncertainties of training data and how that could make it helpful to people who

want access to AI open source AI systems to simply pull that X factor out of the

requirements.

See if I can find those.

Maybe. I don't think no it's not something that I wrote. I think it was I

was something in June. Anyway I was reading it this morning. Oh yes

explaining the concept of data information I think it might have been

that one.

Yeah so yeah this is some someone called Sen Ficon. People can be pseudonymous

in the forum but it's just I'll just copy and paste it. It just felt very

clear and well written. This is just a part of that person's post. And that's

the link.

It might be Felix. I don't know. Could be.

Oh great. Thank you. Thank you to Felix. I've actually heard about Felix and

didn't know that this was what he'd written. But yeah it's very good. Very

well put. What else? What are people thinking about? Anyone to chat about?

So there are a couple folks. Maybe not both. There's at least one person on the

call who is from META but I won't ask them to represent that affiliation

unless they want to. But so the answer is yes they're on the call today. And if

that person wants to say anything they're welcome to but they don't have

to say anything if they don't want to.

Mm-hmm yeah for future LLAMA models. Yep. Yep. Do you want to ask? Yeah you can put

the question out there and the person can answer or not. I imagine it's

something they're discussing internally.

Yeah anyone who hasn't asked a question or participated in the chat.

Ralph or DB, Gerardo,

Toka.

Yes Nick that's yeah that's correct. Yeah the current

version of LLAMA does not meet those but they could in the future.

That would be great.

I see Martin is typing. Nick.

I guess is everyone else who's still on the call

is there anything else that you'd like

to me to cover? Anything else you'd like me to talk about?

Nick is just writing a clear definition will help organizations

to make a choice as to whether they want to release an AI system

as an open source AI or not. Okay yeah.

Okay Martin is saying hoping if any indications made about

if in desiring to conform but it sees not yet and it's obviously

fine. Yeah I imagine it's their conversations happening internally.

Releasing smaller models that do miss the OSAID.

That's one option. Yep.

Yep.

Yes that's well put. Nick is saying a clear definition will help guide

policymakers around the world and that was

the reason that we started this in the first place. I actually wasn't even

there in the beginning. Nick was there and Stefano was there.

The board was there but yeah that was the goal for doing this is to have

something clear that policymakers can rely on globally like the

open source definition currently. Yes and the EU AI Act is

is one clear application of this work.

Okay I see people dropping off which is fine. I think I will do a last

call for questions or comments.

And then

okay

Oh you posted on the forum. Kitty I'll post on the forum.

Okay discussing a forum post.

I'm not sure if folks have read it. I would say ideally

this is your opportunity to click on that link that Kitty has

just shared and take a read and comment

on his post. I think that's probably the thing to do.

Yes and thank you for participating in the forum.

Thank you.

All right I think let's call it Nick. Yes beautiful perfect.

Yes Nick has just dropped the link to the

forum and I guess we can turn off the recording and

Nick if you could hang out for a minute I just wanted to ask you something.

### End of last town hall held on 2024-08-23 ###

### Start of next town hall held on 2024-09-06 ###
--- Presentation for 2024-09-06 ---
OPEN SOURCE AI DEFINITION
Online public townhall
September 6, 2024
last updated: September 4, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

Open Source AI Deﬁnition

New Version 0.0.9

Released August 22, 2024

3

OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open
Source AI System must include:

Open

Weights
Model weights and
parameters

Open

+ Code +
Source code used
to train and run
the system

Data

Information
The dataset or
detailed information
about the data used
to train the system

OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Weights
The model weights and
parameters, made available
under OSI-approved terms
Examples: checkpoints from key intermediate stages of training as
well as the ﬁnal optimizer state

OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Code
The source code used to train and
run the system, made available
with OSI-approved licenses
Examples: code used for pre-processing data, training, validation and testing,
supporting libraries like tokenizers and hyperparameters search code,
inference code, and model architecture.

OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Data

Information
Sufﬁciently detailed information about the data used to
train the system, so that a skilled person can recreate a
substantially equivalent system using the same or
similar data. Data information shall be made available
with licenses that comply with the Open Source
Deﬁnition.
Examples: training methodologies and
techniques, training data sets used, information
about the provenance of those data sets, their scope and characteristics, how the data
was obtained and selected, the labeling procedures and data cleaning methodologies.

Training Data in the OSAID
OSI afﬁrms the beneﬁts of full access to training data while acknowledging it
is not always possible for reasons of law, privacy norms, technical feasibility,
and cultural practice.
• Training data is valuable to study AI systems: to understand the biases that have been
learned, which can impact system behavior. But training data is not part of the preferred
form for making modiﬁcations to an existing AI system
• Data can be hard to share. Laws that permit training on data often limit the resharing of that
same data to protect copyright or other interests.
• Privacy rules also give a person the rightful ability to control their most sensitive information,
such as decisions about their health.
• Similarly, much of the world’s Indigenous knowledge is protected through mechanisms that
are not compatible with later-developed frameworks for rights exclusivity and sharing.
• Open training data (data that can be reshared) provides the best way to enable users to study
the system, along with the preferred form of making modiﬁcations.
• Public training data (data others can inspect as long as it remains available) also enables
users to study the work, along with the preferred form.

OSAID Approval Criteria
OSI Board requires a deﬁnition that is:
Supported
by diverse
stakeholders

Provides
real-life
examples

Ready by
October 2024

The deﬁnition
needs to have
approval by end
users, developers,
deployers and
subjects of AI,
globally.

The deﬁnition must
include relevant
examples of AI
systems that comply
with it at the time of
approval, so cannot
have an empty set.

A usable version
of the deﬁnition
needs to be ready
for approval by
the board at the
October board
meeting.

Approved June 21, 2024

Open Source AI Deﬁnition

What’s Next?

September - October 2024

● Resolve comments, release RC1
● Launch stable version at All Things Opens

10

Endorse the OSAID!
● In preparation for the ﬁnalization of RC1 at the
end of this month, we are seeking both individual
and organizational endorsements of the OSAID.
● “Endorsement” means your name and
organizational affiliation will be appended to a
press release announcing RC1.
● If you or your organization are interested in
endorsing the OSAID, email me or Mer at
Mer@dobiggood.com
11

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

June

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.8

July

August

September

October

Virtual System
Review

Virtual System
Review

Pause in Virtual
System Review

Pause in Virtual
System Review

Townhalls +

Townhalls +

Townhalls +

- OSPOs for
Good (NYC)
- OSCA (virtual)

- AI-dev (Hong
Kong)

Townhalls +
- Deep Learning Indaba
(Dakar)
- IndiaFOSS (Bengaluru)
- RegenAI (Ashland)
- Nerdearla (Buenos Aires)

Draft 0.0.8

Draft 0.0.9

RC1

- OSAI Data
Workshop (Paris)
- All Things Open
(Raleigh - launch!)

Stable
Version

How to Participate :)
● Endorse the OSAID!
○ Email Stefano or Mer
● Public forum: discuss.opensource.org
● Become an OSI member
○ Free or or full
○ SSO with other OSI websites
● Biweekly virtual townhalls… like this one!
13

Q&A

14

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the deﬁnition.

15


--- Subtitles for 2024-09-06 --- ###
Let's start recording our session and get started.

Welcome, everyone.

This is our new format--

well, slightly new format in the sense

that we're going to be doing these town halls now weekly,

going into the session, going into the final stretch

before we have the open source AI definition reviewed

and approved by the board at the end of October.

At the board meeting that we have scheduled then.

So a quick reminder of our rules of engagement,

our community agreements that we call them.

This is our rules.

We want to have--

making sure that there are no overlaps

and people keep space for speaking and listening.

So take space if you are shy and tend not to speak.

But also, if you tend to speak a lot, take a break.

Consider others and ask questions.

Give space for others to come in and give their own things.

Be kind.

And the ones that I look always with in mind

is the think about the fact that we want to continue moving.

We can't stop discussing for too long.

We need to notice the places where

we have disagreement or difficult, complicated issues.

Maybe put a note in there and get back to this later.

And always look for solutions.

Listing the problems is OK to start the conversation,

but moving on.

And so let's review for-- this is the first time

we do this at this time of the week.

So you may have not seen the new version that

was released a couple of weeks ago, version 0.9.

We have presented it in--

I mean, we were in China with Mayor Joyce when this came out.

And basically, the principles haven't changed between 0.8

and 0.9.

The principles are that we want to have-- for an open source

AI, we want to have three kind of components

that can be grouped into three buckets.

The weights, the parameters, the architecture,

anything that is related to what we

call the model in machine learning

needs to be made available under--

needs to be made available.

We'll talk about the conditions for openness or availability.

The open-- the code used to train the system

needs to be made available also.

And also, you need to have a way to run the model,

run the AI system.

And then you need the data.

Everyone understands and agrees on the fact

that the data is where the parameters, the weights come

from.

And you need the data.

And the coalition, the group that

has discussed for many months how to solve the--

how to pass the big boulder of data

being many things in different legislations of the world

came with the description of the data, the requirement

the data has sufficiently detailed information

about the data used to train the system.

And that includes either the data set itself,

when it's possible and legally plausible to distribute safely,

or in alternative--

and also-- not in alternative, but also--

also the code with the full instructions

on how to replicate that data set.

And that includes the scripts to download the original data

and content, the code to run all the interesting--

all the interesting manipulation to go from the raw data

to the training data set.

And so the definition itself has the text

of what is required in a paragraph titled,

what is the preferred form to make modifications

for a machine learning system?

And describes the weights and gives some high level examples.

These are not-- this is not text that is strictly correct,

always--

always the-- always valid for every possible--

very strictly prescriptive about every possible system,

every possible kind of technology

that we can see today or available in the future.

These are examples that are useful to interpret

the actual meaning of the words above.

So for the model weights parameters,

that might include the checkpoints, for example,

if the training in the system is a large language model,

for example.

From the code perspective, it's the source code

used to train the system.

And this includes all the pre-processing code,

the training, the validation, the testing,

how it's been done, the supporting libraries,

and all of that code software.

And this, obviously, need to be made available

with open source AI approved licenses.

And for the data--

for the database, again, there is a-- this

is a little bit more worthy.

The intention here is that the open source AI,

the developers of open source AI,

must be sharing with others all the instructions

and all the knowledge that they have on how they built.

That's the intention.

The intention is to make sure that open source

AI carries the same meaning and the same practical values

that the open source software definition carries.

You need to be able to understand--

you need to be able to understand

how the system's been built, its intention, et cetera.

And you need to be able to learn from them,

from the original developers, and build on top of them

without having to reinvent the wheel or try to guess.

Maybe this thing has been done this way,

so I can improve it by doing this other thing.

No, it's building on top.

And this is where the--

building on top of what others have built,

one of the basic tenets of open source.

But we do have spent--

I mean, the community, and together with the--

also with the board.

And we have reviewed a lot of the comments

that we have received in the past.

And we have clarified also that we do have--

there is a-- we do have-- we do care about data.

We do care about the availability of the training

data.

We do know that the training data

is valuable to understand and study the AI systems.

And we also want to acknowledge that there

is different kind of data.

There is data that computers share,

and that would be--

make sense to always have open in terms of openly accessible

and as open data, following the definition of-- maintained

by the Open Knowledge Foundation.

But there is also training data that is simply public,

cannot be redistributed.

And that is basically the whole of the whole internet.

And where you have the right to crawl and build indexes on it.

This is one of the basic rights that Google

has had as a search engine for forever, since its existence.

And we need to continue to acknowledge the fact

that while search engines can crawl the internet,

they don't have the right to redistribute

what they have crawled.

But they have the right to offer the public

some new and transformative activity, actions,

and services.

So this is the same thing.

This is the concept of public training data

that is publicly available.

And then there is private data, which is another category

of data for which you may have the right to train on,

but you don't have the right to redistribute.

And so a reminder that we are working

within the constraints of the policies

that the board has set as criteria to have a definition.

The board wanted to have--

would ask us to work with the community

to understand, to have a definition that

is supported by a large coalition of individuals,

organizations, and groups with globally representative--

so a sample that is representative

of global communities, but also represent

various different interests.

We're not just representing the interest of research

and academia of individual developers,

or large corporations, small corporations,

European corporations, or governments

from other parts of the country.

But it's the whole--

we try to be as global and diverse as possible.

The other constraints that the board set for us

is that we need to provide real-life examples.

You can't really have a definition

that defines theoretical models, theoretical systems that

don't have any application in practice.

It would be not acceptable by the board.

And we also wanted to set a deadline,

because it's a hard deadline, because otherwise--

because the world needs this definition soon.

And it's better to have something

that is done rather than perfect.

So what's next?

In the next few months, we are working

to really solve the comments as they come,

and maybe release in the next weeks, couple of weeks,

release candidate version.

And then get a quick feedback with the top organizations,

groups that have worked in the process

to gain their endorsements, gather the last comments,

and march towards a stable version for all things

open on October 27.

So we are seeking now--

we're at the stage where we are seeking the comments

from individuals and organizational endorsements

for--

comments and endorsements for the draft.

So if you have--

if you're ready to say, yeah, we're

ready to endorse these principles,

just send us an email.

And you can email me or you can email Claire.

I've been assisting our project.

You can get in touch with Nick.

You can even go public on the forum already as you prefer.

We want to have--

we need to start moving.

We are already at the first week of September,

and we have only six weeks of time

basically left before we finish the process.

And yeah, we've covered a lot of space, a lot of time

over the months.

We've been traveling quite a bit.

We're trying to be presenting in many parts of the world,

presenting and discussing with the community

to make sure that there are the least amount of surprises

by the time we issue the version, version 1,

stable version in all things open.

I can also give you a preview.

You see here in October, there is--

we have two events scheduled.

One is the all things open launch,

but also there is a workshop that we're

organizing for around specifically about the issue

to discuss and understand better the space of data governance

distribution, et cetera.

We'll have more details this coming week made available.

And this is all thanks-- all the travel and all the--

and the workshop that we're organizing in Paris

is thanks to a grant, a large grant given to us

by the Alfred P. Sloan Foundation.

So how to participate?

You can definitely still email me or Mer,

the preferred for the endorsements.

You can also send public comments

on discuss.opensource.org.

Can definitely signal that you appreciate

the stewardship and the role of the Open Source

Initiative in driving this process

by becoming an OSI member.

You can also donate as you become a member.

And you can join these downloads that--

realize this slide needs to be updated.

Coming-- there's-- there being--

there being-- they're opening now weekly at alternating time.

One week is going to be at this time.

One other week is going to be at 9 AM Central European time

so that the Asian community can join.

And now-- yeah, now we've got time for Q&A.

So a comment from YouTube, an open AI

should prove that its training data is all legally licensed

open source data.

Right, so this is a very interesting question

because it's a frequently asked question, actually.

And so it's been debated for many months.

The short answer is that legally licensed open source data is--

is a-- is a big--

is a big-- is a different--

is a different set of what you think it might be.

And we may want to qualify.

So think about the fact that Google Books, for example,

has built a product built on legally--

legally acquired books, scanned, and done object character

recognition on it, and created a transformative work,

and was sued.

And then they won the lawsuit.

Makes me-- makes us think that the concept of training data

legally licensed open source data

is something that needs to be--

needs to be clarified.

So it's a gut reaction that we all go towards.

But we need to think about the consequences.

It's a big-- it's a big topic.

And that's why we're hosting that conference in Paris also.

So Joshua.

Hello.

This is Joshua.

So in the latest draft, I've been

spending most of my time really trying

to think through reading the definition

from different viewpoints of users, especially

a developer viewpoint.

And so I've been really digging in and thinking about

if I'm using Protobuf or TensorFlow

or these other common frameworks and formats for AI models, what

my world view looks like.

And one thing that really stands out to me

is that generally speaking, we're

gravitating towards these binary formats as what

we understand as the model.

And this is different than the abstract kind of approach

to thinking about what an AI model is in general.

It's, in a sense, broader than the AI model,

which is more narrow, which is counterintuitive.

You would think it would be just the opposite.

And the reason why it's somewhat broader

is because these binary formats allow

you to do a lot of things that go perhaps

beyond what you would normally think of as part of the AI

model.

But when you need to identify in your code base what

is the model, you point to that file.

That's the model.

And so I think that there's going

to be some gap between a lot of people's

intuitive understanding of what the model is

and what the intent of the model is by OS in this definition.

I think it would be helpful to put a little bit more

in the definition.

In the online feedback forum for the latest definition,

I added some comments specifically around this idea

that you should be encouraging you

to be explicit about saying that you should not

use the AI model as a way to pass through, say,

binary blobs or object code.

And the reason why I sort of came to that conclusion

is because I was looking at real examples

where people were using things like Protobuf and other--

in TensorFlow and using variables that just

store data effectively as part of their training.

So they're just storing verbatim blobs of information

that are then used as part of the program.

But it's that interaction, but it's stored in the model

from their perspective, from the user's perspective,

and in the documentation.

So I think it would be helpful to have a little bit more

nuance in the definition to clarify that a trained model is

not the same as merely storing files that can then be reused,

that it should be about a little bit more detail around that,

just to help abuse of the open source AI definition.

I think-- yeah.

So I'm not sure I understand exactly--

in fact, I was emailing you to have a conversation

to clarify what you actually meant.

And I'm glad you came for this and explained it via voice.

So I'm still a little bit puzzled

by the technical details here.

But the general principle of the definition

is that it must resist as much as possible the test of time.

And it needs to set high-level principles at this stage.

If you want to have a mental map to frame the intention here,

the open source AI definition file,

the way you see it linked in the chat,

is the page that the FSF, the Free Software Foundation,

hosts and calls what is free software.

It's the basic principles that we

want to have represented in a view of the world, what

needs to be achieved.

That page has gone through multiple iterations.

Like, if you go below and you read it,

the initial freedoms were three, and then a fourth was added.

And wording has been changed on that page to clarify.

But the principles, what is free software, those three,

and then letter four freedoms have pretty much

remained the same.

What has changed and has evolved and derived from that

is the open source definition, which

is a sort of a checklist to evaluate,

in practical forms, software packages used by--

in order to be included in the FTP servers at the Debian

project first, and then became the open source definition

that are currently used, those 10 principles,

to evaluate the licenses and legal documents.

We want-- we're trying to do the same thing here.

The open source AI definition is what is free software page.

And then the new split document, the checklist,

is more of those 10 points practical interpretation

of, in practice, of what will have

to happen for an AI system to be judged, evaluated,

to be respecting the original intention written

in the definition.

So what I would recommend is that we

spend a little bit more time, collectively,

to think about the interpretation.

Instead of making the first document longer,

we could be spending a little bit more time

to refine and review the-- and we

have more time with another set deadline

to finish the checklist.

Make that document a little bit more rich.

Bentley?

Yeah, I noticed this definition doesn't

mention content generated by models

under an open source license.

This might be much a bigger question,

but is there a plan to address the content generated

by an open source model, how that will be licensed,

or is that part of a much bigger discussion?

That's a good question.

So the jury's still out of what are the legal ramifications

for that part.

But definitely, the definition does not

touch that the same way that, more or less,

the open source software definition

doesn't say whether you can use a C compiler to build

malware or other things like that.

It's a separate-- it would be a separate conversation.

There might be legal documents that

say you cannot use this model, this AI system,

to create--

to infringe on someone else's copyright

or to invent things that have already been invented

or do other things.

But that's something that will have to be evaluated

by the legal community.

[AUDIO OUT]

- I have a question.

Can you hear me, Stefano?

- Yes.

- By way of introduction, I'm a tech attorney.

I've been practicing for 15 years.

And for better or for worse, I've

done a lot of work in the open source space.

The one question I had is, at the top of the call,

you went through the definition.

And you explained that there are three parts to the definition.

Is it fair to state that the first two

parts of that definition have not generated

any controversy versus the third?

- Yeah.

Well, not completely true.

So the first two parts, meaning the model weights

and parameters, and the second part--

- And the source code.

- --the source code of--

so there has been debate.

And there will continue to be a little bit.

In the legal community, I believe

that the legal nature of the weights parameters

is still being debated.

Some legislations may not consider those subject

to any exclusive right.

And whether they should be considered

under any IP law or other exclusive rights

is to be debated.

It's not ferocious debate, but it's an intellectually

stimulating one.

And on the code front, on the source code front,

there is debate over whether the training code should

be strictly required or not.

And there is a little bit of a push and pull.

I've heard rumors about that requirement,

strict requirement, as being a little bit too limiting.

Too limiting.

- Got it.

But just to clarify, the third component of the definition,

with respect to the training data,

is the most controversial.

Is that correct?

- Yeah.

Correct, yes.

Because, yes, instinctively, all of us,

at the beginning of the process, everyone had the same thought.

Data is where the weights come from.

Some people use the term source, which is confusing.

It's not source code in the same way.

But it's where it comes from.

If without the data, you don't have the models.

You don't have the parameters.

And therefore, given that requirement,

all of the pipe, the whole pipeline

needs to be open and open source.

But data is not source code.

It doesn't fall under the same easy, air quotes,

legal framework.

It's a whole different beast.

And realizing that became the big boulder

that we had to navigate around, find a way to navigate around.

- Got it.

Thank you.

That's very helpful, Stefano.

And I apologize.

I have read a bunch of the comments on the various versions.

But obviously, I don't have the full history here.

And nobody knows this stuff better than yourself.

Did OSI, at any point, consider using different words

to describe models that would fit within this definition

rather than open source as a way to resolve

the complaints from various members of the community?

Was that considered as an option?

- That is a very awesome question.

That is a very awesome question.

It was one of the very first questions,

is what we're going to call this thing.

And yeah, I'm on the left.

But yes, unfortunately, though, our hand

was forced by the fact that open source AI, as a term,

was already being used.

And even abused by some players.

And I can be public about it, because I've

been public about it.

Meta is one of the abusers of the term.

They keep on using, referring to open source AI.

So in order to safeguard open source, the term itself,

we don't have another choice but to call it open source AI

and work around it.

- Thank you.

That's very helpful context.

That's all I have.

- Yeah.

I see Joshua typing.

Are there any other questions from the Mozilla group or YouTube?

Josh, I see you typing.

Feel free to grab the mic.

- Thanks.

Yeah, it was just sort of a follow up.

My point is that, in principle, we

know that when training a model, that we

know that when training a model, that it gets trained on code

at times.

Some of the data is code.

Some of the data is object code.

We know this because GitHub and other things

are often used as the training data.

And we know that models sometimes make use of just

verbatim storage.

Instead of taking the data and trying to learn something

from it, sometimes you just save blobs of data in your model.

All major models, model formats, TensorFlow, and so forth,

have facilities for doing exactly that function.

TensorFlow Save Models has a bunch of things.

Protobuf has options.

And I don't think, in principle, that is not what you're saying.

You're not saying that training can be taking data,

like an object code blob, storing it in the model.

And then when you build your AI system and you use the model,

copy that data, load it into an executable area of memory,

and run it.

Now, if I'm building consumer electronics, though,

and I'm sending updates using my model, which

is going to be an increasingly common paradigm, given

the fact that we have just huge amounts of AI hardware being

put out there, then it would be an attractive thing for me

to update my platform via that AI model.

And some of the things I'll put in there are, yes,

they're technically trained.

They're trained to say, here's a lookup table of what

should be executed when the system initializes,

the AI system.

And I think it would be good to just draw a bright line

and say, no, you can't just say that--

you can't just move something technically

into what is the model and get around these principles

that we're making clear.

And that's the same thing as if you

were to move that code elsewhere in your AI model.

I see your point.

I see your point.

Now, it's more clear.

But I would recommend that we go back

to the reason why we put, at the beginning of the document,

the definition of what is an AI system.

Maybe that helps.

Because if we go back to the definition, what is the AI

system that we are defining in this work, in this document?

The AI system is anything that, for implicit objectives,

given an input spits out an output.

So whatever you call that, whether you package it

in a binary that loads a blob and executes

a virtual machine that executes something else,

if what we're calling here is what we're defining

and what we need the corresponding--

the preferred form to make modification of

is whatever that system is, however it's packaged,

however it's shipped, whatever it ships.

So when we go into the implementation,

some reviewer who wants to--

someone like, I don't know, the Linux Foundation

wants to--

may want to have a requirement some day,

maybe will have a requirement that says,

we only accept AI systems in our projects that are open source

AI following the definition of DOSI.

Then they will have a standard set for specifically

that technology, the same way that they have the model

openness framework now for the generative AI models.

And in that place, they can put all of the requirements

specifically for that technology to say,

nope, that loading of that binary

here is not a good thing.

It's basically a workaround.

It's not acceptable.

Or we'll have to wait and see.

I mean, another way, another approach that we could have

is to wait and see what--

if this threat that you have in mind

is actually going to show up.

It's not just a theoretical threat.

If it will be showing up, we're thinking one of the tasks

that we have to do by the launch is to really come up

with suggest recommendations on how we're going to be

monitoring the efficacy, the adoption of the open source AI

definition, the availability of other--

availability and reviewing of the existence of open source

AI systems besides the initial ones that we have identified,

which, by the way, are the ones released by the Eleuther AI,

Alen AI Institute, LLM 360, and most likely,

DII, we're working to understand those better.

So those are the ones that pass the open source AI definition

right now.

Thank you.

I see.

Yeah.

Ben?

So when a company modifies an open source AI model

for commercial use, at what point

does the modification become a derivative work subject

to the original license?

And would existing legal tests around open source licensing

be sufficient to determine the AI model modifications

and the derivative work aspect of it?

Or do you foresee a whole new level of legal guidance

needed with regards to these type of things?

Yeah, that's a very good question.

Frankly, lots of it depends on what the models themselves

are considered under laws.

Because right now, yeah, it all depends

on what contracts get built around them

and how those propagate between--

all the rights propagate between this new artifact,

the trained weights, trained parameters, to derivatives.

Yeah.

Not easy.

So there is a conversation now happening on the license

review mailing list, which is the community of volunteers

who've been reviewing licenses, software licenses.

And they've been asked to consider

how to handle licenses and other legal documents that

are not covering software, so the traditional space.

So if you're interested in joining that conversation,

I would highly recommend to join the license-review mailing

list.

I see a question from Peter.

Other non-profits in OSI ecosystems,

like GNOME, Alliance Foundation, Physotek Foundation, et cetera,

have any of them attempted to independently define

open-source AI or provided input to OSI about OSI's definition?

Oh, Peter, yeah, this is a great question

because it allows us to explain a little bit more

what the process has been.

So this is not OSI's definition, the same way

that the open-source definition is not OSI's definition.

We merely maintain it for the community.

So we have worked from the very beginning with Linux Foundation

and FSF and others, reached out to them

and asked them to contribute to the definition.

This definition is not written by us.

It's written by a process held by a co-design process.

It's a process designed to work with the people affected

by the decision, not for them.

So yes, all of these organizations

mentioned, plus many others-- Creative Commons, Eleuthera

AI, Mozilla Foundation, many other groups

that have participated to the list.

And we have somewhere on the website,

opensource.org/deepdive, we have a list of the groups

that have been-- and the volunteers that

have been included.

, All right.

Are there any more questions?

[AUDIO OUT]

OK, then.

I'm going to call it a day, call it a week.

Thanks, everyone.

This has been very useful, very interesting for me.

I hope it's been informative for you, too.

And I would like Nick is saying on the chat,

our discussions continue on our forum,

discuss.opensource.org.

And the license review working group is available.

Peter, stay on the chat here.

I will send you the link where to join it.

It's old school, meaningless.

Thank you, everyone.

### End of last town hall held on 2024-09-06 ###

### Start of next town hall held on 2024-09-13 ###
--- Presentation for 2024-09-13 ---
OPEN SOURCE AI DEFINITION
Online public townhall
September 6, 2024
last updated: September 4, 2024 (MJ)

1

Community agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

Open Source AI Deﬁnition

New Version 0.0.9

Released August 22, 2024

3

OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open
Source AI System must include:

Open

Weights
Model weights and
parameters

Open

+ Code +
Source code used
to train and run
the system

Data

Information
The dataset or
detailed information
about the data used
to train the system

OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Weights
The model weights and
parameters, made available
under OSI-approved terms
Examples: checkpoints from key intermediate stages of training as
well as the ﬁnal optimizer state

OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Code
The source code used to train and
run the system, made available
with OSI-approved licenses
Examples: code used for pre-processing data, training, validation and testing,
supporting libraries like tokenizers and hyperparameters search code,
inference code, and model architecture.

OSAID v.0.0.9
The preferred form of making modiﬁcations for a machine-learning Open Source AI System must
include:

Data

Information
Sufﬁciently detailed information about the data used to
train the system, so that a skilled person can recreate a
substantially equivalent system using the same or
similar data. Data information shall be made available
with licenses that comply with the Open Source
Deﬁnition.
Examples: training methodologies and
techniques, training data sets used, information
about the provenance of those data sets, their scope and characteristics, how the data
was obtained and selected, the labeling procedures and data cleaning methodologies.

Training Data in the OSAID
OSI afﬁrms the beneﬁts of full access to training data while acknowledging it
is not always possible for reasons of law, privacy norms, technical feasibility,
and cultural practice.
• Training data is valuable to study AI systems: to understand the biases that have been
learned, which can impact system behavior. But training data is not part of the preferred
form for making modiﬁcations to an existing AI system
• Data can be hard to share. Laws that permit training on data often limit the resharing of that
same data to protect copyright or other interests.
• Privacy rules also give a person the rightful ability to control their most sensitive information,
such as decisions about their health.
• Similarly, much of the world’s Indigenous knowledge is protected through mechanisms that
are not compatible with later-developed frameworks for rights exclusivity and sharing.
• Open training data (data that can be reshared) provides the best way to enable users to study
the system, along with the preferred form of making modiﬁcations.
• Public training data (data others can inspect as long as it remains available) also enables
users to study the work, along with the preferred form.

OSAID Approval Criteria
OSI Board requires a deﬁnition that is:
Supported
by diverse
stakeholders

Provides
real-life
examples

Ready by
October 2024

The deﬁnition
needs to have
approval by end
users, developers,
deployers and
subjects of AI,
globally.

The deﬁnition must
include relevant
examples of AI
systems that comply
with it at the time of
approval, so cannot
have an empty set.

A usable version
of the deﬁnition
needs to be ready
for approval by
the board at the
October board
meeting.

Approved June 21, 2024

Relevant comments
Summary of the discussions on the forum and on hackmd

10

Clariﬁcations of the text
- Randall:

- Rename data as "source data"
- Be explicit that public data needs
enumeration
- Be explicit that one can require downstream
users to open their data if they ﬁne tune on
your model

https://discuss.opensource.org/t/welco
me-diverse-approaches-to-training-data
-within-a-uniﬁed-open-source-ai-deﬁniti
on/531
11

Clariﬁcations of the text

From just the data, it is hard to understand *why* certain tokens are included
or excluded. For this, you really need the code for the *full* data processing
pipeline.
A open-source deﬁnition proposal: the following should be released:
- Code for entire procedure
- Any part of the executed versions (data, weights) without copyright/privacy
concerns
- Pointers to all the raw data (CommonCrawl, torrent link, etc.

12

Hardware considerations
Mariana Taglio and Allison Randall
mention hardware.
“include the detailed technical
aspects of model training, such as
hardware speciﬁcations, training time
and carbon footprint (if available)”
https://discuss.opensource.org/t/sha
re-your-thoughts-about-draft-v0-0-9
/514/8
13

Map dataset’s right to distribute
Wade:
- a framework to
describe the
commitment to
releasing data
information, or the
dataset when legally
possible
https://discuss.opensourc
e.org/t/proposal-to-handl
e-data-openness-in-the-o
pen-source-ai-deﬁnition-rf
c/561
14

Open Source AI Deﬁnition

What’s Next?

September - October 2024

● Resolve comments, release RC1
● Launch stable version at All Things Opens

15

Endorse the OSAID!
● In preparation for the ﬁnalization of RC1 at the
end of this month, we are seeking both individual
and organizational endorsements of the OSAID.
● “Endorsement” means your name and
organizational affiliation will be appended to a
press release announcing RC1.
● If you or your organization are interested in
endorsing the OSAID, email me or Mer at
Mer@dobiggood.com
16

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

June

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.8

July

August

September

October

Virtual System
Review

Virtual System
Review

Pause in Virtual
System Review

Pause in Virtual
System Review

Townhalls +

Townhalls +

Townhalls +

- OSPOs for
Good (NYC)
- OSCA (virtual)

- AI-dev (Hong
Kong)

Townhalls +
- Deep Learning Indaba
(Dakar)
- IndiaFOSS (Bengaluru)
- RegenAI (Ashland)
- Nerdearla (Buenos Aires)

Draft 0.0.8

Draft 0.0.9

RC1

- OSAI Data
Workshop (Paris)
- All Things Open
(Raleigh - launch!)

Stable
Version

How to Participate :)
● Endorse the OSAID!
○ Email Stefano or Mer
● Public forum: discuss.opensource.org
● Become an OSI member
○ Free or or full
○ SSO with other OSI websites
● Biweekly virtual townhalls… like this one!
18

Q&A

19

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the deﬁnition.

20


--- Subtitles for 2024-09-13 --- ###
The open source AI definition came out at the end of August with a new version

009. This is made of three main elements. It defines machine learning, open source

AI. The preferred form for making modifications is tied to the concepts of

machine learning. Because this is the technology that

requires a little bit more thinking because it has

this concept of trained models, trained weights and parameters. So the

weights are defined as the model weights and parameters made available under

open source initiative approved terms. And then there are

examples. Here what's important is the fact that we're trying to be vague

enough but signal precisely the intention. So the vagueness is because

we want to make sure that the text can resist time. It doesn't have to be updated

every time a new technology, a new model architecture, a new AI technology or

technique gets pushed out and made available. But also we want to use

the text so that the intention of the drafters is clear. The examples

provided are just part of the definition and they need to be

read together to understand it, to evaluate whether that signal, that

signaling of intention is clear enough. That should be clear. So from the source

code requirements also, this is a space that we know a lot more about.

Like what is the source code and how to deal with all the licenses etc.

But what's important here is that the requirement to release the source code

used to train the system. So one needs to be able, one who releases software

needs to be able to understand, one who releases an AI system needs to share all

the instructions, details including all the software used for training,

for validation, for testing. It's very important because that's the part where

collaboration can happen and improvements can happen iteratively.

And data information from the data front, the text here hasn't changed yet.

Although it's still quite convoluted and complicated, it could be refined. We'll

talk about that later. It needs to deal with the fact that laws are

complicated. And so this, again, the intention here is to give whoever

receives the software enough of the code itself and the datasets or the

provenance of the data so that the science can continue. And then also

innovation can keep on happening, building on the shoulder of the giants

exactly like it happens with the open source software where you don't have to

reinvent the wheel. You can build on top of someone else's work. So when

we released the version 009 of the open source AI definition, we

also released text to explain why the data set is considered, the release of

the training dataset is considered a benefit and not a requirement. It's

because training data are covered by laws that limit the resharing of the

datasets because of privacy rules, but also copyright law and even other

legislations like indigenous knowledge is not protected with copyright, it's

protected by other rules. And we need to take that diversity of legislation into

account and we need to make a difference between open training data, public

training data, and private data. So all of these have to be covered in a

different way, have to be treated differently because they are

different. And so the other thing worth reminding everyone all the time is

that the OSI board has set some basic criteria to approve the open

source, the results of the co-design process. We presented these slides a

couple of weeks ago in China, but the board requires that the

definition is supported by a diverse type of stakeholder and by

diversity it's listed not only into interest groups like users, developers,

deployers, subject of AI, but also geographic distribution. So we don't

want to have only Europeans or North Americans or South Americans, etc. We're

making an effort to go around the world to disseminate this work

and gather approval around the world and this is thanks to a grant from the

Alfred P Sloan Foundation. The other requirement is that the definition needs

to provide real-life examples. So once approved we need to make sure that

we have systems that we can point at and say these are open

source AI. And right now comfortably we can say that the

complying systems are PTI, the set of models released by

Yale AI Institute and LLM 360 and TII also. So non-profit research

institutions who have released the large language models and similarly

powerful AI systems. And we need to be ready by the October board

meeting that will happen on October 27th in North Carolina. So let's go through

the relevant comments that we have received this past few days on the

forums. We had Alison Randall basically requesting to be more

explicit about the requirements. This is a fair request. The text

tends to, the text of the definition tends to be more vague, to leave some vague

words in there. Like I said before, the intention is to be vague enough but

signal clearly the intentions. So it's worth rereading the text to

make sure that those intentions are clear. And especially one of the

intentions that Alison points out is the requirement to be explicit about

allowing, adding requirements the same way that the open source definition, the

classic open source definition allows for some requirements that are considered

to be good. Like a requirement for copyleft, you know, the persistence of

propagating the rights to downstream users is something that needs to be

evaluated. Whether the text that exists today allows that or if the text is

too vague and doesn't allow for that propagation downstream.

Technically, also legally, we need to understand how that can happen but

that's a different story most likely. Also be explicit about the fact that if the

training is done on public data, so data that actually can be distributed, there

are no exclusive IP rights, no natural exclusive IP rights. Like content created

by humans are, they always will have, I mean most parts of the world will have

copyright or civil rights, due to in European continental and moral rights.

But that doesn't mean that, for example, temperatures of the ocean, that

kind of data, that information doesn't have any right naturally. So

we want to consider that. She also suggests renaming data as source data.

This is something that I'm personally skeptical about. I would love to see more

people leaving comments on the forum because there is no, I mean, so data

is not source. Source is the word that has been traditionally used to

signal the source code or the preferred form for making modification to the

software. It's also mentioned in the original open source definition as such

and data is not the source of the training, training the outputs like

the weights and parameters. So I'm less reluctant. I mean it's called

training data in literature. So anyway I'd love to hear more comments

about this on the forum. And speaking of that concept of source as data, an

interesting comment received by a person, Professor Leon, he's a professor at

Stanford University. He made a good comment on the document on the

text. He's saying that the data is basically the data set is the output of

the processing of the original data and he's arguing that it's a lot more

important to get access to all the scripts used to build the data set

rather than the data set itself because the data set is not very comprehensible

without the code. And it's an interesting comment because it

really gives you, changes the perception. The data set is more like a

binary of the original data. And the source code is actually the code used

to create those tokens. So a very interesting comment in there and one

that might require also some refining, fine-tuning of the text of the

definition. Then we have comments on, we have received comments on hardware

considerations from Mariana Taglio and Alison Randall. This is an area, hardware

is an area where the open source initiative and open source in general

has not considered because it's a completely different layer and

can be isolated. Even in AI I think it can be isolated. Adding

hardware considerations would make the whole specification, the whole definition

a lot more complicated and I'm not sure it's viable. But you know if you think it

is, this is your time to leave your comments on the forums on this topic.

To me getting detailed aspects like hardware specifications, the

carbon footprint and things like that is interesting from the social benefit

perspective. But I don't think it really helps with the concept of improving,

collaborating, innovate on the AI systems. It's a little

bit the considerations about ethical use. They're valuable but they need to be put

at a different level, like a legislation level for example. But your comments, I

mean please leave your comments in this part if you think they are part of

the, if they're important for studying, share, modify and distribute AI

systems. And finally just a couple of days ago Carsten Wade made this proposal

to map visually the rights to distribute data set. I think it's an interesting

representation in a quadrant type of way where if you're

building on data, I mean he has this quadrant with two axes. One is on the

vertical axe, you have the IP intellectual property rights, present or

absent. And then if you want to have an integrity of the

pipeline stack, just another axis. So if you're

training something on public data, then basically anyone have high integrity

then you must release everything including the

original data set because basically why shouldn't you? Since there are no, I mean

since you should have all the IP rights. But if you're training on

private data then it's open source AI minus the data, D minus.

I think it's an interesting visual on this. Or if you don't have

the, if you choose not to release the data then it's

definitely going to be a closed, not open source AI. So let's talk about what's

next and that is we're going to be reviewing the text,

close some of the comments, most of the comments and release a release

candidate, have a release candidate version by probably in the next, within a

couple of weeks. So if you have more comments, please do it as soon as

possible. Although there will still be time to change after the release

candidate. And then if you're ready to endorse the open source AI definition, we

are looking for individuals and organizations who can endorse it and

that means that your name or your organization affiliation will be

appended to the press release and the announcement page of the open source AI

definition. So if you want to be part of this release, please email me or Mer,

the email address is on the deck. And just to give a timeline, we are

in September now, we gave a few talks around the world. We are going to

Buenos Aires next week, we Ashland in Oregon this weekend, we've been in

Daba and Bangalore to present this definition and we're going to

be holding more town halls every week until basically until the end of

October for the official launch in North Carolina at All Things Open.

We're going to be holding a special data workshop on data

in Paris also in October thanks to the Alfred P. Sloan Foundation grant.

Alright, so the way to participate is to endorse, so you can email me or

Stefano or Mer and you can keep on commenting on the forum. And with that,

time for Q&A. So take the floor as you want, open your mic or type

questions if you prefer.

I can see Ted comment saying not sure why hardware is needed.

Yeah, go ahead Ted. Yes, Stefano, thank you for sharing, this is really helpful.

Two questions, one is can you share the slides that we can distribute to many

people who cannot attend this town hall? Yes, so the session is recorded, I'm

going to cut the part without the audio and we're going to be sharing the deck, yes.

Okay, so you will share through email? Yeah, all of them are

shared on the forum, so I will put the link on where we're going to be

putting it so you can subscribe and get that one. But yeah, I can send it to you via email.

Okay, and secondly that endorsement, so it's just an email, is there any

template or just a simple email that endorses the RC1 unstable version?

Just an email saying, hey, I'm interested, my organization is

interested in endorsing this and we're going to be putting you in the

loop, so every release candidate will make sure that you have it and

once we get closer to the press release time, we will ask you formally, this

is probably going to be at the beginning of October, for a quote. Okay, can I

suggest that we put a link on the relevant website, so that I

can propagate or send to whoever is interested in endorsing it.

Just one click, one click link, so whatever individual or

organizations, we can hit on the quick list of names or organizations and

that would be it, instead of just a separate email.

Oh no, absolutely, yes, we're thinking about also creating a landing page with

the text and the button below that says, yes, I endorse it, name and

affiliation. Yeah, okay, all right, that'd be great, thank you, I have no more

questions. Thank you. Anyone else, any doubts, ideas?

Overall, it looks good to you?

All right then, oh, Jay, is someone typing?

All right, if there are no more questions, I mean, if you have more questions, you

can always email me or ask directly on the forum, really feel free to use all

the resources we have. I want to thank everyone and

### End of last town hall held on 2024-09-13 ###

### Start of next town hall held on 2024-09-20 ###
--- Presentation for 2024-09-20 ---
OPEN SOURCE AI DEFINITION
Online public townhall
September 20, 2024
last updated: September 18, 2024 (MJ)

1

Community Agreements
●
●

●

●

●

●

One Mic, One Speaker -- Please allow one person to speak at a time.
Take Space, Make Space -- If you tend to talk more, we invite you to
make space for others to share. If you tend not to share, we invite you
to speak up.
Kindness -- This work is hard, but we don't have to be. Gentleness and
curiosity help. Those who use insults or hate speech will need to leave
the meeting.
Forward Motion -- We advance by focusing on what is possible in the
moment and doing it. Obstacles are marked for later discussion, not
used to stop the process. If we hit a boulder, we note it on the map and
keep walking. We'll come back and unearth it later on.
Solution-Seeking -- This work is so complex that focusing on what
won't work will stop it. Suggesting new ideas, options, and proposals is
vulnerable, but crucial. All of us are needed to make this work.
Anything else?

2

Open Source AI Deﬁnition

Version 0.0.9

Released Aug. 22, 2024

3

OSAID: 4 Freedoms

An Open Source AI is an AI system made available under
terms and in a way that grant the freedoms to:

1. Use the system for any purpose and without having
to ask for permission.
2. Study how the system works and inspect its
components.
3. Modify the system for any purpose, including to
change its output.
4. Share the system for others to use with or without
modiﬁcations, for any purpose.
4

OSAID: Preferred Form

The preferred form of making modiﬁcations for a machine-learning
Open Source AI System must include:

Open

Open

Model weights and
parameters

Source code used
to train and run
the system

Weights + Code +

Data

Information
The dataset or
detailed information
about the data used
to train the system

Open Source AI Deﬁnition

What’s Next?

September - October 2024

● Resolve comments, release RC1 this week
● Launch stable version at All Things Opens
on October 28th

6

Board Approval Criteria for the OSAID
Supported
by diverse
stakeholders

Provides
real-life
examples

Ready by
October

The deﬁnition
needs to have
approval by end
users, developers,
deployers and
subjects of AI,
globally.

The deﬁnition must
include relevant
examples of AI
systems that comply
with it at the time of
approval, so cannot
have an empty set.

A usable version of
the deﬁnition needs
to be ready for
approval by the
board at the
October board
meeting.

2024

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

April

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.8

August

September

October

Virtual System
Review

Virtual System
Review

Feedback and
review
Hardening WG

Feedback and
review
Hardening WG

Townhalls +

Townhalls +

- OSPOs for
Good (NYC)
- OS Community
Africa (virtual)

- AI-dev (Hong
Kong)
- OSC (Beijing)

July

Draft 0.0.8

Draft 0.0.9

Weekly townhalls
- DL Indaba (Dakar)
- FOSSIndia (Bangalore)
- RegenAI (Ashland)
- LF Europe (Vienna)
- Nerdearla (Buenos
Aires)

RC1

Weekly townhalls
- All Things
Open (Raleigh)
- Data Workshop
(Paris)

Stable
Version

Open Source AI Deﬁnition

Get Involved!

Endorse The OSAID

9

Call for
Public Participation

Endorse the OSAID!
opensource.org/osaid-endorse

Endorse the OSAID!
● In preparation for next month’s launch, we are
seeking both individual and organizational
endorsements of the OSAID.
● “Endorsement” means your name and
organizational affiliation will be appended to a
press release announcing the OSAID.
● Use OSI’s webform to give your endorsement.
● Email or DM Mer or Nick with any questions.
11

How to Participate :)
● Endorse the OSAID!
○ opensource.org/osaid-endorse
● Public forum: discuss.opensource.org
● Become an OSI member
○ Free or or full
○ SSO with other OSI websites
● Biweekly virtual townhalls… like this one!
12

Q&A

13

Thank you
We realize this is difficult work and we appreciate
your help and openness in improving the deﬁnition.

14


--- Subtitles for 2024-09-20 --- ###
Welcome everyone to our town hall. We're actually going to start having these town halls every week

until the OSAID is launched on October 28th. So we'll be seeing more of you. These are the

community agreements which you're familiar with if you've been here before. One mic, one speaker,

so allow one person to speak at a time, to take space, make space, if you tend to talk more,

pause to let others share, if you tend not to share we invite you to speak up and share your

opinions, to be kind to each other, just not acknowledging that the work is hard, but we can

still be gentle with each other. Obviously hate speech is not permitted in the meeting, that

hopefully is not a surprise, that we're trying to move forward, obviously, that obstacles are marked

to be discussed, but that we try to continue to make progress even when we find those, oh

Nick, I am seeing my whole slide, it's okay, that we seek solutions,

just because there are so many ways that this could not work and finding those ways that this

can work is needed. Does anyone have any other community agreements that they'd like us to

use as we conduct this meeting? You can share it in the chat.

Drinking a bubbly water, okay. Thank you Nick. So we're on version 0.0.9 which was released at

the end of last month, if you use that QR code you can view it online, I believe this is the

HackMD instance with the commenting function, and I'll go through that now. Next. Yeah, so the

OpenSource AI definition has two parts in addition to the preamble, it affirms the four freedoms

as initially enunciated by the Free Software Foundation, but now applied to AI systems, so

grants the freedom to use the system for any purpose without asking permission, to study the

system and inspect its components, to modify the system for any purpose, including to change its

output, and to share the system again with or without modification and for any purpose.

Next. And then the second part of the definition is the preferred form

to make modifications, and again this is for machine learning, OpenSource AI system, right,

so the technology is part of what defines the preferred form, the particular methodology.

So first it requires open weights, so that's model weights and parameters, requires open code,

which means source code used to train and run the system, and it requires data information,

which is the data set or detailed information about the data used to train the system,

and that actually we should change that particular way we're phrasing that,

because the detailed information about the data used to train and run the system is required,

whether or not a data set is also required. Okay, thank you. So what is next, September and

October? We're resolving the comments. We intended to release our RC1 this week. It is still being

edited for reasons some of you may have heard the conversation is having with Gerardo, but there's

still some edits being made to RC1, the release candidate one. Our goal is that we will launch

that next week though, at the Nerdeala conference in Argentina, and then we will have a staple

version launched at All Things Open on October 8th, 28th at the end of next month. Next.

And also just so you know the requirements that we have internally for this launch,

that the board requires that the open source AI definition or OSAID be supported by diverse

stakeholders and specifically for stakeholder types, end users, deployers, developers, and

subjects. So I think in this slide there are not definitions of that, but we can define that if

there's interest, and that that be global representation. Secondly, that there are real

life examples of these AI systems, so it is not, the definition does not result in an empty set.

And finally, that we are able to complete this process by that

deadline that I gave previously of the end of October. Next.

So this is just to let you know where we are. We're in September.

We have done a lot of, we and actually our partners, have done a lot of sharing

the OSAID internationally this month. We had Rahmat, who is a organizational endorser,

which I'll talk about later, and co-designer presented the OSAID in Dakar at the Deep Learning

in Dhaba. We had Taranima Prabhakar, who's a, I'd say a friend, a friend of the OSAID,

and the founder of Taddle, an open source AI system, presented at FOSS India in Bangalore.

I presented in the US at Regen AI, Ashland's in the state of Oregon.

Stefano presented the OSAID in Vienna at Lung's Foundation Europe, and then I will,

inshallah, present in Buenos Aires next week at NERD-ER-LA. And then next week, next month, we

will present at All Things Open, which is in Raleigh, and then we have a data workshop, which

will, which is a data policy paper that deals with, I would say, data questions emerging from the

open source AI definition, but is not specifically working on the definition,

and that will generate a white paper. Okay, yes, get involved. So the big ask,

do you want to do the ask, Nick, the endorse the OSAID ask, because you did, you did this web form.

So do you want to do it, or shall I? Yes, so right now, if you join the website,

and if you look under the drafts, there's a form now for endorsements. So if you'd like to join

that, and I'll paste the link here as well to the form, you can endorse that either as an individual

or as an organization. So let me just drop the link to the form, and it's very simple. You just

add your name, your role, your institution, and if you're endorsing this as an individual or

as an institution, or both, that's an option as well. You can add your comments, and once we

are going to be releasing this, the new release candidates, we'll also showcase some quotes,

and if you add a message there, that should appear as well. Thanks so much. Next slide.

So this is also just sharing with you the definition, and well, you can go back to that

colorful one. Okay, well, they, oh, oh, oh, oh, oh, yeah. So basically, just to say this is a call,

another call for public participation, that anyone who is on the web and would like to endorse the

OSAID is welcome to do so. We do, as Nick said, have the option for organizations to endorse the

OSAID, which is in a more formal process, but also any individual can choose to endorse the OSAID,

and what that means is that when we do have our official launch in October, that your name and

affiliation will be listed on the landing page as an endorser, kind of like the signature at

the end of a document. So, yes, thank you. Next. Hi. So I think that gave, yeah, I think that

gave that information that I was just describing. We can put it up in text still, go back. Some

people like to read as well as to hear information. Could you go back to that previous slide, Nick?

Thank you. Yeah, so this is just affirming that there's individual and organizational,

and it's clarifying what endorsement means, which is that your name is going on, it says

your press release, but it's a public statement that will be on our website, announcing the OSAID,

the web form, and then you can email or DM Nick or I if you have any questions about this,

in addition to the Q&A we're about to have. Now we can go on to the final slide.

Yep, so that's our request. We would love your endorsement of the OSAID,

and to participate in our public forum, which has always been available, and attend weekly town

halls are the ways to currently participate in the process, and that QR code is to the forum,

I believe. So if you go to the next slide.

I will open it up to Q&A, and please, please raise your hand, and I or Nick will call on you,

and allowing everyone to have a comment before we have double up on comments from any one person,

and you can also text in the chat if you would like to do that instead of speaking aloud.

But yeah, I would love to have your comments and questions.

All right.

All right. Hello, or Nick, are there any comments or questions that you feel might be interesting

for us to talk through? Is there anything, anything that I can clarify?

I know that you're going to be talking about the OSAID, and I'm going to be talking about

the OSAID, and I'm going to be talking about the OSAID, and I'm going to be talking about

the OSAID, and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID.

And I'm going to be talking about the OSAID.

### End of last town hall held on 2024-09-20 ###

### Start of next town hall held on 2024-09-27 ###
--- Presentation for 2024-09-27 ---
Open Source Initiative

Deﬁning
Open Source AI
Mer Joyce | September 27, 2024

Supported by:

Why Deﬁne Open Source AI
Now?

Mer Joyce

Frontier of OS

Shaping Regulation

Combat Open-Washing

Deﬁning Open Source AI is
the most signiﬁcant
challenge facing the open
source movement.

Government regulations
have begun in the EU, US,
and elsewhere. We have
the opportunity to share
these new policies and
laws by deﬁning OSAI.

Companies are calling AI
systems “open source”
even though their licenses
contain restrictions that go
against the accepted
principles and freedoms of
open source.

Beneﬁts of Open Source AI
by Lea Gimpel

Mer Joyce

Transparency + Safety

Market Deconcentration +
AI Polyculture

OSAI provides information
essential for auditing
systems and to mitigate
bias, ensures
accountability and
transparency of data
sources, and accelerates AI
safety research

OSAI makes more models
available, spurs innovation
and quality due to
increased competition and
tackles AI monoculture by
providing more
stakeholders access to
foundational technology.

Diverse Applications
OSAI gives developers
access to resources crucial
for developing contextspeciﬁc, localized applications that are representative of cultural and
linguistic diversity and allow
for model aligned with
different value systems.

https://opensource.org/deepdive/we
binars

2022-2023 research
Interviews (Podcast)

Panel discussions

Webinar series

Four panels with 4 experts covering 4
area:
●
Business
●
Society
●
Legal
●
Academia

18 experts of different disciplines
from all over the world dissected
issues from data governance, privacy,
labor laws, software development and
more.

https://deepdive.opensource.org/report/
We’ve known that the availability of training data was THE ISSUE

https://opensource.org/deepdive/webinars

Co-Designing
the OSAID
How we created the Open Source AI
Deﬁnition through global consultation.

Co-Designing the OSAID
A Global Snapshot
Our co-design process included in-person
workshops on five continents – South America,
North America, Africa, Europe, and Asia – and
virtual participants from more than 35 countries.

OSAID Co-Design Question

1
Mer Joyce

Use • Study • Modify • Share
What should these open
source principles mean for
artiﬁcial intelligence?

Open Source
AI Definition
Four
Freedoms
v.0.0.9

1. Use the system for any
purpose and without having to
ask for permission.
2. Study how the system works
and inspect its components.
3. Modify the system for any
purpose, including to change
its output.
4. Share the system for others to
use with or without
modiﬁcations, for any purpose.

OSAID Co-Design Question

2
Mer Joyce

What components must be
open in order for an AI
system to be used, studied,
modiﬁed, and shared?

Virtual
Workgroups
Llama 2 Group
1.
2.
3.
4.
5.
6.
7.
8.

Bastien Guerry
DINUM, French public
administration
Ezequiel Lanza Intel
Roman Shaposhnik
Apache Software
Foundation
Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic Institute of
Paris
Mo Zhou Debian,
Johns Hopkins
University
Victor Lu independent
database consultant

Members agreed to make their names and affiliations public to support the
transparency of the co-design process.

BLOOM Group
1.
2.
3.
4.
5.
6.
7.
8.

George C. G. Barbosa
Fundação Oswaldo Cruz
Daniel Brumund GIZ
FAIR Forward - AI for all
Danish Contractor
BLOOM Model Gov. WG
Abdoulaye Diack
Google
Jaan Li University of
Tartu, Phare Health
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
Ofentse Phuti WiMLDS
Gaborone
Caleb Fianku Quao
Kwame Nkrumah
University of Science and
Technology, Kumasi

Pythia Group
1.
2.

3.
4.

Seo-Young Isabelle
Hwang Samsung
Cailean Osborne
University of Oxford,
Linux Foundation
Stella Biderman
EleutherAI
Justin Colannino
Microsoft

5.

Hailey Schoelkopf
EleutherAI

6.

Aviya Skowron
EleutherAI

Over 50% of participants
are People of Color, 30%
are Black, and 25% are
women, trans, and
nonbinary.

OpenCV Group
1.
2.
3.
4.
5.
6.
7.

8.
9.
10.

Rahmat Akintola
Cubeseed Africa
Ignatius Ezeani
Lancaster University
Kevin Harerimana CMU
Africa
Satya Mallick OpenCV
David Manset ITU
Phil Nelson
OpenCV
Tlamelo Makati
WiMLDS Gaborone,
Technological University
Dublin
Minyechil Alehegn
Tefera Mizan Tepi
University
Akosua Twumasi
Ghana Health Service
Rasim Sen Oasis
Software Technology Ltd.

Selecting the required components described in the

Voting for Requirements checklist and preferred form section
1. Workgroup
Votes

2. Public Vote
Compilation
3. Public Results
Report on Forum

4. Deﬁnition v.0.0.6
+ Checklist

components from
Model Openness
Framework (MOF)

March 1, 2024
March 10, 2024

OSAID Co-Design Question

3
Mer Joyce

Which AI systems
meet the criteria of
the OSAID?

We were interested in reviewing about 10 AI systems self-described as

Validation Reviewers open to validate the definition. Work began May 1, 2024.
1. Arctic
1.

Jesús M.
Gonzalez-Barahona
Universidad Rey Juan
Carlos

2. BLOOM
2.
3.

Danish Contractor
BLOOM Model Gov.
Work Group
Jaan Li University of
Tartu, One Fact
Foundation

3. Falcon
1.
2.

Casey Valk Nutanix
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France

4. Grok
1.
2.

Victor Lu
independent
database consultant
Karsten Wade Open
Community
Architects

5. Llama 2
1.
2.
3.
4.

Davide Testuggine
Meta
Jonathan Torres
Meta
Stefano Zacchiroli
Polytechnic
Institute of Paris
Victor Lu
independent
database consultant

6. LLM360
5.

[Team member
TBD] LLM360

7. Phi-2
6.

Seo-Young Isabelle
Hwang Samsung

8. Mistral
1.
2.
3.

Mark Collier
OpenInfra
Foundation
Jean-Pierre Lorre
LINAGORA,
OpenLLM-France
Cailean Osborne
University of Oxford,
Linux Foundation

9. OLMo
4.
5.

Amanda Casari
Google
Abdoulaye Diack
Google

10. OpenCV
1.

Rasim Sen Oasis
Software
Technology Ltd.

11. Pythia
1.
2.

Seo-Young Isabelle
Hwang Samsung
Stella Biderman
EleutherAI

3.

Hailey Schoelkopf
EleutherAI

4.

Aviya Skowron
EleutherAI

12. T5
5.

Jaan Li University of
Tartu, One Fact
Foundation

13. Viking
6.

Merlijn Sebrechts
Ghent University

Validation Review

Each system is reviewed on a public form, to maximize transparency.

Validation is ongoing. We have found that creator participation is in

Validation Progress most cases necessary to identify all the legal documents needed to
ascertain openness. Last updated in June, 2024.

Current Version: 0.0.9

Open Source AI Deﬁnition
4 Freedoms
● Use
● Study
● Modify
● Share

+

Open Weights

● Model
weights and
parameters

+

Open Code

● Source code
used to train
and run the
system

+

Data Info

● Dataset or
detailed
information
about the
data used to
train the
system

The AI conundrums
“If we assume, for example, that the definition requires full
release of datasets, one thing is certain: in Julia’s words, it
would be “a definition for which few existing systems qualify.”
(OSI note: also less powerful and limited to specific domains
https://redmonk.com/sogrady/2024/07/03/ai-conundrums/

A long history of
exceptions
“The GNU C library uses a special kind of copyleft called the GNU
Library General Public License, which gives permission to link
proprietary software with the library. Why make this exception? [...]
It is not a matter of principle;[...] but strategically it seems that
disallowing them would do more to discourage use of the GNU
system than to encourage development of free applications
Richard Stallman
https://www.gnu.org/philosophy/fsfs/rms-essays.pdf

Board Guidance
The OSI Board requires a deﬁnition that is:

Supported by
diverse stakeholders

Provides real-life
examples

Ready by
October 2024

The deﬁnition
needs to have
approval by end
users, developers,
deployers and
subjects of AI,
globally.

The deﬁnition must
include relevant
examples of AI
systems that comply
with it at the time of
approval, so cannot
have an empty set.

A usable version of
the deﬁnition
needs to be ready
for approval by the
board at the
October board
meeting.

Approved June 21, 2024

Open Source
AI Definition
The general structure of
the document

Basic concepts

The Open Source
AI Definition

The definition of
preferred form to
make modifications
to machine learning

Clarifications

Unlikely to
change in the
future

Most likely to
change in the
future

New FAQ entry (preview)
Open training data: data that can be copied, preserved and reshared. It provides the best way to enable users to study the
system.
Public training data: data that others can inspect as long as it remains available. This also enables users to study the work.
However, this data can degrade as links or references are lost or removed from network availability. To obviate this, different
communities will have to work together to define standards, procedures, tools and governance models to overcome this risk,
and Data Information is required in case the data becomes later unavailable..
Obtainable training data: data that can be obtained, including for a fee. This information provides transparency and is
similar to a purchasable component in an open hardware system. The Data Information provides a means of understanding
this data other than obtaining or purchasing it. This is an area that is likely to change rapidly and will need careful monitoring
to protect Open Source AI developers.
Unshareable non-public training data: data that cannot be shared for explainable reasons, like Personally Identifiable
Information (PII). For this class of data, the ability to study some of the system's biases demands a detailed description of the
data – what it is, how it was collected, its characteristics, and so on – so that users can understand the biases and
categorization underlying the system.

The Board requires that the definition have approval by end users,

Stakeholder Groups developers, deployers and subjects of AI, globally.
Stakeholder

Description

Example

Vols

1. Developer

Makes AI system and/or
component that will be studied,
used, modiﬁed, or shared
through an open source license

ML researcher in academia or
industry

31%

2. Deployer

Seeks to study, use modify, or
share an open source AI system

AI engineer in industry, health
researcher in academia

46%

3. End User

Consumes a system output, but
does not seek to study, use,
modify, or share the system

Student using a chatbot to write
a report, artist creating an image

≈ 90%

4. Subject

Affected upstream or
downstream by a system output
without interacting with it
intentionally + advocates for this
group.

Photographer who ﬁnds their
image in training dataset
(upstream), mortgage applicant
evaluated by a bank’s AI system
(downstream)

≈ 100%
32

32

System testing work stream

2024 Timeline

Stakeholder consultation work stream
Release schedule

February

April

Call For Volunteers
+ Activity
Feedback and
Revision

Virtual System
Review

Bi-Weekly
Virtual
Public
Townhalls

Bi-Weekly
Virtual
Public
Townhalls

Draft 0.0.5

Draft 0.0.8

July

August

September

October

Virtual System
Review

Virtual System
Review

Feedback and
review
Hardening WG

Feedback and
review
Hardening WG

Hola 👋
Townhalls +

Townhalls +

- OSPOs for
Good (NYC)
- OS Community
Africa (virtual)

- AI-dev (Hong
Kong)
- OSC (Beijing)

Draft 0.0.8

Draft 0.0.9

Weekly townhalls
- DL Indaba (Dakar)
- FOSSIndia (Bangalore)
- RegenAI (Ashland)
- LF Europe (Vienna)
- Nerdearla (Buenos
Aires)

RC1

Weekly townhalls
- All Things
Open (Raleigh)
- Data Workshop
(Paris)

Version 1.0

Call for Public Participation

Endorse
the
OSAID!
Mer Joyce

opensource.org/osaid-endorse

Endorse the OSAID!
● In preparation for next month’s launch, we are
seeking both individual and organizational
endorsements of the OSAID.
● “Endorsement” means your name and
organizational aﬃliation will be appended to a press
release announcing the OSAID.
● Use OSI’s webform to give your endorsement.
● Email or DM me on the forum with any questions.
35

How to Participate
● Endorse the OSAID!
○ opensource.org/osaid-endorse
● Public forum: discuss.opensource.org
● Comment on RC1 next week
● Become an OSI Member (free + paid)
● Weekly virtual town halls

Thank You,
Co-Designers!
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

The following individuals volunteered as workgroup members or system reviewers
during the co-design process. This group of 36 volunteers represents 23 countries by
birth and residence. African participants are highlighted.

Rahmat Akintola Cubeseed Africa
George C. G. Barbosa Fundação Oswaldo Cruz
Stella Biderman EleutherAI
Amanda Casari Google
Justin Colannino Microsoft
Mark Collier OpenInfra Foundation
Daniel Brumund GIZ FAIR Forward - AI for All
Danish Contractor BLOOM Model Gov. WG
Abdoulaye Diack Google
Ignatius Ezeani Lancaster University
Jesús M. Gonzalez-Barahona Universidad Rey
Juan Carlos
Bastien Guerry DINUM, French public
administration
Kevin Harerimana CMU Africa
Seo-Young Isabelle Hwang Samsung
Ezequiel Lanza Intel
Jaan Li University of Tartu, One Fact Foundation
Jean-Pierre Lorre LINAGORA, OpenLLM-France
Victor Lu independent database consultant

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

Tlamelo Makati WiMLDS Gaborone, Technological
University Dublin
Satya Mallick OpenCV
David Manset ITU
Phil Nelson OpenCV
Cailean Osborne University of Oxford,
Linux Foundation
Ofentse Phuti WiMLDS Gaborone
Caleb Fianku Quao Kwame Nkrumah University of
Science and Technology, Kumasi
Hailey Schoelkopf EleutherAI
Rasim Sen Oasis Software Technology Ltd.
Roman Shaposhnik Apache Software Foundation
Aviya Skowron EleutherAI
Minyechil Alehegn Tefera Mizan Tepi University
Davide Testuggine Meta
Jonathan Torres Meta
Akosua Twumasi Ghana Health Service
Casey Valk Nutanix
Stefano Zacchiroli Polytechnic Institute of Paris
Mo Zhou Debian, Johns Hopkins University

Q+A

Mer Joyce


--- Subtitles for 2024-09-27 --- ###
All right, thanks everyone for joining this day in the slide access.

I'm Stefano Maffulli, I'm the Executive Director of the Open Source Initiative.

And a reminder, we've been doing this work thanks to a grant from Alfred Sloan Foundation

and a donation from MercatoLibre, which has joined us as sponsors.

Okay, so let's go through quickly a little bit of the history of how we got here

and what we were doing and why we're doing this.

So, why we're defining the Open Source AI now is because

these technologies, since the introduction of chat GPTs or the Open AI launches,

have significantly, significantly impacted how the IT environment in the software spaces

has operated and worked and changed a lot of the fundamentals of our understanding of software

and the Open Source definition.

At the same time, we've seen an incredibly fast reaction from governments around the world,

especially the United States, Europe, but also Japan, China, have started to write laws directly.

And some of these laws, especially the AI Act is very explicit, mentions Open Source AI

and Open Source systems and models without having a specific understanding of what that means.

And the reason for the regulators to do that is to allow for special carve-outs for research and innovation.

Like having seen how the Open Source definition worked for software

and allowed for a thriving ecosystem that is worth apparently 8.8 trillion,

or in any case, it's a huge sum of money, and it's underlying the whole digital infrastructure.

So regulators want to keep everything safe, keep society safe, but at the same time,

they want to make sure that the risks are reduced.

And trying to find that balance revolves around the concept of Open Source AI.

And third is this open washing thing that we've seen a lot of companies,

and especially one abusing of the term Open Source and calling out meta in this space,

for releasing models and releasing artifacts that are not Open Source by any stretch of imagination,

especially their licensing in terms of conditions or not.

But because there is a lack of clarity, they can claim whatever they want,

because there is no easy way to push back and point at a widely agreed upon definition of what Open Source AI actually means.

And so we asked them, I mean, this is just to show the Digital Public Goods Alliance

have given a little, illustrated what they think the benefits of Open Source AI is in general.

So without further ado, let me start from the history.

What we've done is that in late 2021, when I joined the OSI,

we knew it was immediately after Copilot was launched, and it was immediately clear that the word was not going to be the same with that.

So we launched this research that we call Deep Dive AI.

We wanted to understand the space.

So in 2022 and 2023, we ran, if you want, research endeavor.

We interviewed experts. We started to ask them questions.

We published them in a form of deep podcast.

And I recommend you to listen to it because it's really, if you're new to the space,

it gives very good introduction to the legal aspect, the technical aspects, copyright, business and society security.

Also, there's an interview with DARPA program manager for AI security, very eye opening.

Next year, we've done, I mean, in the same year, we also run four panels with four experts covering business, society, legal and academic views.

And we published their report. So if you don't want to listen to the podcast, you don't want to listen to the panel recordings, look at the report.

It summarizes the issue. And together with the webinar series, with interviews and presentations from experts from different parts of the world,

we knew at the beginning or in the middle of 2023, we knew that the issue that we needed to solve was that of the availability of training data.

We knew that that was the problem that we needed to solve in some way, shape or form.

Because it was the most controversial one.

So we thought about using a co-design method to come up with a solution, a plausible solution.

So we went around the world, we asked people questions and we also set up online meetings in order to have more variety.

And we asked them a series of three questions. The first one, what you should be, what should the words or use the verbs,

use, study, modify, share, mean for in the realm, in the domain of artificial intelligence.

And after a few meetings in person and online, it was not too complicated to reproduce the basic principles of the free software definition and port them to the domain of AI.

Then we needed to understand how to implement those freedoms. If you want to use, if you want to study an AI system, what do you need?

So we collected virtual working groups online to analyze four types of systems.

One is Lama, which is completely proprietary. The other one is Bloom, which is very open science, but with a bad license.

PTA is a very open science LLM and OpenCV group analyzed the computer vision neural networks, zoo models, models in the zoo.

So to, to, to find the analysis, to, to look at it from, from also the angle of something that is not an LLM.

And we run some votes, not scientific. I, it was never the intention of being scientific. I've seen conversations on the forum.

The idea was to gather a little bit of feedback that will allow us to move on and check an hypothesis.

The hypothesis here was given the, that known, it showed that the groups were not unanimous in saying that the training data was always necessary to study and modify, especially for modify.

For studying it, it was, that component was a little bit higher.

But we have an hypothesis and the hypothesis to solve the problem of data was to see, okay, if we don't require it, what happens?

So we asked the third questions. Let's go outside, look at the, look at the world, look at existing systems and check which ones would comply if we don't require strictly the training data.

But we require the other components, which is the data processing code and the training code.

So we, we threw, we widened the search to more models to, for this validation phase.

And in fact, we ended up with the expected results. In other words, none of the systems that we knew were bad, like LLAMA or,

or Bloom, for example, we knew that those ones would not pass for different reasons.

So that was that signal. It was just a signal that there might be a way to solve the issue.

And the result was this, right? We, the definition is structured this way.

There is the four freedoms and then the requirements for the preferred form of making modifications to machine learning into these three pieces.

You have to have the weights, the parameters need to be available with freedom respecting licenses and legal terms.

Software needs to be complete for the training, the training and for the data processing.

And then you need a very detailed description of what the data we use for training actually is.

So Redmonk put it quite nicely and he called this the AI conundrums, right?

And he quotes Giulio Ferraioli here. And this is a very interesting quote.

So it says that if we assume that the definition requires full release of datasets, one thing is certain.

It would be a definition for which very few existing systems qualify.

And also those that qualify are less powerful and limited to specific domains.

And then because then the other thing to solve, I mean, the other approach to think about this conundrum is that on the other hand,

we have in the free software and open source movement a long history of making exceptions and finding ways to solve the problems

in order to have more freedom and more open source software.

Now, the other constraints that we have in this whole process is that the board, the OSI board, required three basic pillars, the elements.

We want the definition to be supported by diverse stakeholders.

That means not only end users, not only developers, but all of them.

So end users, developers, deployers of AI, subjects of AI.

And they want to have global representation of diverse interests in the list of endorsers and support.

They also require, the board also requires that the definition must include relevant examples of AI systems.

And this is for a specific tactical reason.

The regulators will not consider the open source AI definition as an interesting one or something to follow and imitate if it is not a general one,

if it doesn't cover general cases and if it doesn't cover and if it excludes clearly anything.

I mean, if it really limited to only small domains.

And it needs to be ready by October. And again, the main reason for this is timing.

The AI Act is already out there and is already law.

And it's already the legislation process, the normative process has already started.

This means that there is a hyperactivity in Brussels, but also in D.C. and in California to convince and educate policymakers that open source just means access to open weights, access to the weights.

And that's all they need to care about. And maybe a little bit of description of transparency in the form, if you're familiar with that data cards or other formats that are pretty lightweight to describe in metadata sense, the data set used for the training.

And which is not sufficient. So there is an urgency to come up with a working definition.

OK, so we're working on Release Candidate 1, which has some clarifications and basic concepts.

This is just a screenshot. It's not really don't don't refer to it too much.

It's going to change between now and when Release Candidate is released.

But I wanted to show here the structure of the document to illustrate a major feature that has been here in its intention from the beginning.

There are probably two main, two macro parts. The top part includes the basic concept, like what is a definition?

What is it that we are defining? Which is it? What is AI? What is an AI system?

And we added here, we may add based on feedback from the forum, the machine learning definition so that we have a list of framework reference of the topics that are covered below.

Then there is the actual open source AI definition, what it is, right? The preamble, why we want it and what is open source AI, which includes the four freedoms.

Now, the four freedoms, as you know, even in the free software world, the free software definition, the freedom to study and the freedom to modify are followed by a sentence that says precondition for this is access to the source code.

And further, the source code is defined as the preferred form of making modification to the program, which is later clarified also in other documents, including the licenses, etc.

Now, we need a frame here to understand what we're talking about, what we need, what is the preferred form of making modifications to an AI system.

And in order to do that, we need to limit the scope. We cannot talk about all of the AI. We need to talk about machine learning in this specific case.

It's the most pressing and urgent matter. Let's finish this part. So the second part, now we enter in the second macro part of the definition.

This part is one that is most likely to change and evolve in future versions of the definition.

So the preferred form of making modifications here lists the three major blocks of an AI system, a machine learning system, which are data piece, the code piece, and the parameters weights and sets conditions for those.

And then we added, which is already in 0.9, space for clarifications. These clarifications serve the purpose of clarifying that whether you call, when you want to call and use the term open source,

refer to anything that spits an output based on an input, whether you call it an open source AI, an open source AI system, open source model, open source weights, open source model or open source weights.

Basically, these are all equivalent terms. You cannot skip the line to some extent and say, well, it's an open source model only.

So, you know, the rest of the definition doesn't apply. No, if you want to call it open source model or open source weights, you have to comply with, we have to provide the preferred form of making modifications to that system.

Now we're also working on a new FAQ and the new FAQ entry will clarify further the four types of training data that are plausible and possible in this world.

And that is clearly, you know, open training data, public training data, obtainable training data and unshareable non-public training data.

And we believe that we believe that all of these four types of data can be part of an open source AI.

We don't want to limit the open source AI only to open training data or open and public training data, because that would limit the capabilities of open source systems and would limit the domain of open source systems.

So open training data typically is something that, you know, you have, you can fairly assume that there is global coverage, global possibility to distribute that data.

And that is a collection of facts like time series of wind speed and ocean temperatures.

And it may seem safe, but I discovered that when trying to immigrate to China, going to China for a business trip,

I noticed that among the reasons for Chinese government to search on entry and exit of the country to search digital devices is for the availability, for the presence of weather information, weather data on the devices.

Meaning this means that even that kind of data is not necessarily easy to circulate around the world, like one can assume.

Public training data is data that others can download, like, you know, the archive of my blog posts, for example.

And this is also this is subject to availability, right? Links go stale and everything like that.

But we can work around that with tools like common crawl or Internet archive and software heritage and places like that where they keep, they can keep the archive.

But that's the public training data. The obtainable training data is data that you can buy or data that you can, you know, they can be obtained if you ask.

Things like the ImageNet data set, for example, and the unshareable non-public training data is private information, that kind of like medical, medical, medical data.

This kind of data can never be asked for, can never be distributed.

And so we need to be careful, but we want to have open source AI medical systems.

So we need to find a way to work around this, this piece.

So I can give a very quick overview of where we're thinking that the release candidate might go to explain things a little bit better.

So in the data information piece, we're trying to make it clear that the requirements are a must.

Like the, we noticed the confusion between the work that we create.

So we're probably going to use, suggesting is to use the word build instead.

Substantially equivalent systems stays together with, but we are adding the fact that the data information needs to work with the code below.

You cannot just say data information alone.

You cannot look at data information alone and think that you can be replicating.

And this is, if you saw online, there was a comment from Professor Perciviere, who highlighted how much the knowing about the data and knowing how it's been processed is the crucial, crucial piece.

And specifies here in particular, if used, so for example, if one uses training data that is publicly available, it needs to be made available.

And for the code specification, there is a clarification that the code must be complete.

You cannot just say, hey, here's the code. No, I need to be able to run it.

I need to be able to run it together with the data information.

I need to know I need to get a working data set in some way or form.

And there is also one line in addition that we're working on.

It's a way to cover all three of these pieces.

So code, data and the issue here is that code weights and data.

The issue here is that could be contractual terms.

And actually, there are like the responsible AI license family has in some of the they show that they played the experiment.

And they have a way of in one contract to say, take this model, take this data and use it under these conditions.

So what we're trying to say here is that we need to have a we need to give away to people like the groups at the OSI who will be reviewing these contracts.

To make sure that we can evaluate the these packages that cover different artifacts,

because if you notice the code individually, the elements code parameters and data,

they have this provision that says code shall be made available on their OSI approved license.

This means that, yes, individually, some elements are covered, you know, they can be covered by this license.

But collectively, we don't have a way in this definition. So it was a missing piece.

And that's what we're working on on this final line.

All right. So these are the groups that we're working with to get endorsements and get different representation and timeline.

We're still aiming to get version one ready for all things open in North Carolina in October, the end of the month.

So for now, you know, we want to hear your voice. So endorse the concepts embedded in the draft.

It's unlikely that they're going to be changing going forward. But the adaptations and clarifications, absolutely.

They're coming because the intention is there.

The intention is to make sure that we have a clear definition that is white, has white support and preserves the principles of open source.

All right. And with that, I think we can go to open the floor for questions.

If you have the mic, you can probably open it yourself or you can type.

Yeah, so I am here. I've obviously shared a lot of my thoughts on on where we're at.

My main concern here is that this is a needs to be a litmus test like the open source definition.

And the open source definition has the benefit of being able to approve a license and then have that license self applied to millions of projects.

Whereas in this case, we really need to look at every single project.

This is getting applied to or somebody needs to look at it, whether it's us or more likely it's going to be the project itself.

And so my my suggestion or my my belief is that this doesn't function as a litmus test and that words like sufficiently detailed and if I can tell you, well, I've got a skilled person here and they're going to say, well, it's not skilled enough.

We've given you enough information. Right. So there's not there's not going to be a way for us to really tell anybody that there is not a source.

I sort of going and trying to implement the thing ourselves based on the information that they've given us.

So let's say that they do achieve the certification.

They get that they get the mark. Does it protect the four freedoms? And I think it's quite clearly I don't think Steven's done a really good job of saying, get these are the kind of proofs that you would need to show like you need to show me that you can make the same modifications to a machine learning system with fine tuning.

Right, we know access to the source data as what you can with access to the source data. I think, you know, as a practitioner, it's clear that that's not the case.

I mean, I feel like we need something that people can self apply, which is like the OSD.

And so it really needs to be something where you say this is the ingredients. This is the manifest. And maybe it's even an electronic manifest, like a JSON file or something that says these are the scripts, the training script, the training data, maybe optionally.

And then with those checkboxes checked, then you get access to the mark, right?

So yeah, I mean, I don't think unless somebody sat down and actually like, tried to size the four freedoms on systems that have been through this, like I maintain that it doesn't function as a litmus test.

Yeah. All right. So it doesn't function as a litmus test. And that's what we tried in the validation phase.

So we said, let's take the, at the time, the definition also had a component called the checklist, which I haven't mentioned.

Basically, the checklist is the list of components of AI systems as described in the model openness framework, which is a paper.

I don't know if you're familiar with it. It's a paper from the Linux Foundation. That paper lists 16, 18 components and classifies the availability of them is used to classify where they stand in three classes.

Open class one is open model class. That's the only way around. Class three is open model class two.

Open models, basically just the weights and model cards, some metadata, model card and data card, technical report, then open tooling.

If they make available also data pre-processing and some other and some other inference code and some other pieces of code.

And then a top class is open science where they provide every everything, every required component, including open training.

I mean, the training code and the training and testing data sets.

So one way that the validation phase work was to say which of these components are required, then one could go and use the model openness framework and see the availability of these marks.

You put zero at this bar, which is between class two and class three and class one, between open tooling and open science.

And that could be one way of having that litmus test.

What we discovered is what you were saying. It requires the finding.

This doesn't work at a glance the same way that open source software and open source license approved open source licenses work.

You cannot look at the repository and see if there is a check the license file could check the open source initiative website and say, hap, this is open source approved or not.

It's not because there are so many different components with different nature.

Some documentation is on a blog post, some code is in GitHub, some or other repositories.

Some of the models are on Agnephase or Kaggle.

Finding all these pieces for a third party of a viewer is almost impossible or very, very complicated without the collaboration of the original developers.

So this is an issue that we are aware of, but it's also an issue that we don't know how to solve today and it could be solved with practice tomorrow.

In other words, there might be a space, a place in time where Agnephase maintains a community of experts or I don't know.

There is a collaboration effort with universities and in fact we started talking with a few of them to see if they want to have, if they want to help us expand in next year the validation phase and fine tune the key indicators of what an open source AI needs.

Because I have a theory in my mind, but it's just a silly theory.

If you're not releasing the data processing code and if you're not releasing the training code, you're not open source.

It's a very, in my mind so far with the samples that I've seen, it's an easy test, but it's not an easy one to solve.

The nature of this animal of AI machine learning is that they are not software, simply.

And even when software, there are examples where understanding if it's open source or not is complicated.

And there are different ways of interpreting what open source means.

In other words, if you look at SQLite, SQLite is an open source database program, but they don't have a community around it.

They don't accept patches. They just release the code at their own will.

And on the other side of the spectrum, you have ginormous projects like OpenStack or Kubernetes, complex governance, multiple contributors, etc.

Different promises to the public.

So there is a range in there.

I go back to the principles that we want to say here.

Do we want to have more open source AI?

Do we want to give groups like Eleuther AI and Allen Institute for AI and maybe TII and other groups,

do we want to give them a chance to build AI systems that are capable of competing with Lama and Gemma and the likes?

Or do we want to stay in a corner where we can only use a limited amount of data and limited amount of kinds of data?

And the OSI has never been about...

Neither has the Free Software Foundation. It's never been about, let's make a limited copy of Unix because the POSIX standards are proprietaried by ISO and we protest the ISO's approach.

Does that make sense, Sam?

Yeah. I mean, SQLI, it's open source. It's in the public domain, right?

It doesn't have all of the things we'd like to see in an open source project, but I can exercise the full freedoms.

And if I have an AI system, which is derived from, and I described like, you know, the kind of toxic dump of data, things like common crawl,

at least I can study it and I can modify it.

And, you know, it's hosted on Amazon. There's a 501(c)(3) the Common Core Foundation that wraps around it.

So you can build a, you know, proposed open source AI on that.

And that's data that exists today and the systems built on it that exist today.

Now, we may be setting too high a bar by saying it's got to be Creative Commons licensed.

And there's a whole lot of reasons about, you know, not just copyrights, but personal rights and other things that prevent you and GDPR and the rest of it.

And they handle the complaints about GDPR. They deal with all of that.

So I think that maybe we are being a bit too purist.

And by being too purist and saying it's got to be CC0 or CC5 or whatever, right, rather than saying, like, it's got to be accessible so that I can enjoy the full freedoms.

That would be already a good start.

If we don't, right, if we don't say we want to see the data, right, we want things like that, the lung cancer data set to be available, then it'll never be.

No one will ever create a data set.

I mean, I've just deleted my data from 23andMe.

It's been sitting there for 20 years or something.

But the reason I put it in was to help advance medical technology, right, and they're good to go private and whatever.

So I deleted it.

But if there was an open source DNA database, you know, I would probably, a lot of people in that community would contribute to it with a view to finding open source drugs and solutions and things.

But if there's no incentive to do that, it's not going to happen.

Okay. No, I see.

I heard that argument also.

And I tend to push back in because I do believe that the open data issue and the incentives to open data are separate and they can run in parallel.

I don't think that there is an inherent capability of the open source definition to say to force behavior.

It has never happened before.

You know, Copyleft has restored what was the Copyleft and Free Software principles have restored what was available before to the research community.

Research community was used to distribute software freely without thinking about copyright.

And then copyright was applied all of a sudden and that created problems.

So it's a free software movement started as a reaction to restore what was happening before.

The open data movement needs, there are so many changes in that, so many challenges in that space that it deserves a separate conversation.

But going back to the common crawl being the tool that is out there, one conversation I've had with Professor Liang and other experts, builders of AI, they told me one interesting thing.

And the common crawl is everything, right? It's the whole web, more or less, we can assume.

And the interesting part, though, is not knowing that common crawl has been used, but having access to the data processing code.

In other words, how common crawl has been filtered, what decisions have been made to split it up into pieces, the duplicated.

And then the other important piece of reproducing or having the freedom to fork meaningfully is to know how the training has been done.

One other theory that I've heard about the importance of data set that is the actual data set that is relatively less important than the code used for producing it,

is that the tendency is to accumulate more and more data. And we may get to the point where there is going to be only one giant pile of data anyway.

But the learning moment and the innovation cycles and the collaboration seems to be most likely to happen on the code front, on the data processing and data training.

But that's for the future. I just want to plant it there to say one thing.

But the other thing that is today that is more relevant to your argument is that common crawl itself is not guaranteed.

You don't have any guarantee that you can distribute it safely around the world.

And in fact, if you look at the history of the pile, and the history of Dolma, the two data sets used by Luther AI and the Allen Institute for AI,

both of them, they're making decisions to distribute data that for which they don't have any rights to redistribute.

And they're also changing the conditions for their distributions. Right?

You were saying common crawl, common zeros, 511c3. There is no guarantee that common crawl can be distributed the way it is legally, safely around the world.

That's what we're trying to dance around. Data is a different space.

We got really lucky that software, there was a decision, a policy decision by IBM and Apple to apply copyright to software and not other different, different exclusive rights.

Because copyright is more or less, uniformly more or less uniformly applied worldwide.

But I'll give you one last example, just to see how complex and how difficult this conversation is.

We say, let's train only on public domain data.

That concept of public domain is different around the world.

Oh, let's talk in only our first, you know, let's, let's use only fair use.

Let's apply the fair use doctrine. That doesn't exist outside of the United States or, and I don't know if there is, I don't know what the situation is in Australia.

It definitely the interpretation of the courts will be different for what fair use is.

So we can't really rely on what we relied on for software.

We just have to change our minds. And this is one of the reasons why we're having a separate conversation and a separate workshop on data.

This coming month to just learn a little bit more about the space.

We're working with Open Future to produce a white paper on this, on this space.

That will serve as a continuation, you know, as a starting point to continue the conversation next year.

Because open data has been around for 15 years and as a movement and all.

And now they're thinking, you know, my sense is that they've been thinking a little bit by surprise.

The because open data has been publishing, you know, release your data, your user data and not much about making it fun, realizing that it was, it would be functional.

And that could be used for to transform the behavior of systems.

Yeah. Look, I mean, I think that the pragmatically the data is only required a training time.

The inference time is 99% of the use cases at inference time.

But but as long as you've got access to it one way or another to be able to, whether that means having a team member in the US or running it in the US or whatever it is to to resolve that.

And then you model you can you can you can run it wherever you want.

My concern is that we have this definition here that that is like, like I said, not like we can't apply it.

Right. And we don't have the manpower to apply this to everybody who wants it.

So you rely on people self applying it, which is like sufficiently detailed, sufficiently skilled.

Anybody can apply it to anything. Right. And so there's not really any way for us to stop that, particularly without trademarks, unless you have a certification trademark and so on.

Right. So I feel like, you know, that we're kind of going to learn that the hard way. Right.

And then to Tom Cataway's point, right, we can't once the cat's out of the bag, you can't bring it back in again.

You can you can start with a high bar and lower the bar.

But if you go out with a low bar, you can't raise it later because the standard is already effectively being said.

I think we need to measure twice and cut once here. But I feel like, you know, no matter no amount of consensus finding or discussion at this point or based on the history, really, at any point.

I mean, we started this conversation, you and I back in March or something.

And I see that it's been running, you know, the whole the whole year. It hasn't really got got anywhere.

But maybe maybe the thing here is we look at those exceptions you mentioned, like the one you've got on the screen now, the library of what used to be the lesser public, lesser GPO and kind of I'm not super like I'm very impressed with the level of detail.

So the cost has got there, but it goes to the intent. Like, you know, when you go and have a dual intent visa, right, what's your intent? You can't really test the intent, not visible.

So it really needs to be a thing. Is the data accessible? And if it's accessible, I can exercise the full freedoms.

I think we agree on that. What? Okay. In that case, it's not like how sorry.

Well, OK, how do you cover the case then for federated learning? The the the the definition tries to be generic.

And I agree with you that there is an issue with certification like that. It needs to be solved.

But let's put that aside. Let's put that aside. We will solve it. We need the principles now.

We need to establish the principles and the principles. I fully agree with all of you. All the requirements for open data, like the building blocks are free code data and weights.

All three of them needs to be made available. It's such a no brainer.

The problem here is to cover for the different cases of the different kinds of data.

That's what we need to we to give a story. We need to have a story for. And the story can only be solved with with this approach.

We can only be solved with this approach. We haven't seen another approach.

We haven't seen another proposal that covers all of these different types of data.

We can go to the politicians. We can go to policymakers and say, look, the the the the right to fork meaningfully for an AI system is

if I have access, if we have access to complete and detailed listing of all these kinds of data with links,

you know, the URLs, the torrent hashes and all of that to download the publicly available, obtainable and open training data.

And in case of nonpublic, very, very detailed description like sample data sets,

you know, sample so that we can build a data set with our own private data, like a hospital can say I can recreate the structure of that data set with my own data.

And the training code and the data processing code.

And the model, right. But I want to have access to I need to be able to the very basic principle that the politician needs to be here.

They want to be here. A very simple thing. And the simple thing could be.

We need to have training code, training, processing, processing data.

And all the instructions to take that and build on top of it, retraining.

Without our own data or a different data.

Is there a way we can address that kind of batteries included versus lesser or D minus or or whatever the.

You know that the minus the block. I mean, that's the approach. I mean, that's what we're striving to get.

That's what we're failing to communicate in this in this.

It when someone says like you, you and others like for simplicity, you know, grouping all training data must be open.

The the conversation stops because there. Yes, in theory, but in practice, there are four kinds of different data.

So how do we account with this diversity is the proposed solution is what it's been in draft since 06 to 09.

And it is to have that data information piece together with the code requirements.

Those two pieces. Need to be made available. Right.

But if I can't get the data itself, then I can't even validate that what you say is I can't even validate that data is actually the data that's gone into the model and it hasn't been supplemented.

So that's that's the problem of reproducibility. Right. Is that what you're talking about?

Reproducing the experience? What I'm saying is anybody can say anything. Anybody can say it's open source and there's nothing I can do to say.

We can say that is also not right. But under this, with this, but there's different rules through any claims. Right.

Yeah, but those are two different problems. The reproducibility is one thing and recognizes whether it is open source or not.

It's a different thing. Reproducibility, even in software, is not a solved problem.

For the most complex systems, you don't have a way to match bit to bit the binary to the source code.

Yeah. And especially not when you're using like CUDA and stuff.

And there's enough randomness in that you're going to get a different binary, but it's going to perform in a substantially similar way.

And if you run the open source system, then you should have something that answers the same question the same way.

You can study that thing. Right. It should be similar.

So we enter into, you know, this is a different space than software. So even in software, we don't have reproducible builds.

Or they're not an unsolved problem. Reproducing and rebuilding from scratch a system to make sure that it behaves completely the same is still an unsolved problem and may never be solved for these machine learning, deep learning systems.

So aiming for that, it's a mistake. That's the open science level, which has always been a separate thing from open source.

Open source is a building block, if you want, for open science. But it's not the same thing.

Here, we're trying to, with open source AI, the open source AI definition has different aims to enable transparency, to enable transportedness, to enable open science, to enable safe and lower risks for society, or not to be an obstacle, rather.

But these are not the goals. The goal here is to preserve the right to fork, if you want to put it very quickly.

Can I fork it? Can I build on top of it? What do I need to do that?

Can I reproduce it? Sure. I should not be stopped. I mean, it's a level on top.

Yeah, it's a bit the open source versus open weights and discussion. In one case, you're getting the weights, but you can fine tune, but you can't fully exercise the freedoms.

But if you have source in the context of preferred form, as in the original training data.

So what are your thoughts then on how we got to this decision and the process? And I guess there was voting done and there was a result that was interpreted, I argue misinterpreted.

Had that decision have come out a different way, had that have been interpreted differently, had those negative votes not gone in, how would that have been handled?

Yeah, no, no, that's a good point. I think Zak raised that issue in the early days as soon as the, Stefano Zacchiroli, as soon as they came out.

But that was so that those results were never meant neither to be scientific, nor representative, nor democratic or anything like that.

There were, we had, we looked at them and we know this display and we knew that requiring trained data at the time, we didn't have this analysis of this four different kinds of data.

We knew that there were cases where data was not distributable. So strictly requiring open data or the full training data set was going to be a limiting factor.

So we tested, we decided to test an hypothesis. It was really like a political decision, if you want, which Stefano Zacchiroli also recently reiterated.

Let's test it. Let's see what happens if we say no training data, but we replace training data with the detailed information about it and the training code and the data processing code.

Let's see what happens and let's test that hypothesis. And that's where we saw the path forward into two following phases, the validation phase.

And with the conversations with the partners, like with the, there is a vocal minority, but I guarantee you there is a much larger supporting group that is not visible on the forums because they're overwhelmed.

And because they are AI builders, they tend not to have a lot of time, the lawyers, etc. professors.

You know, it signaled that experiments gave a signal of a possible solution to the conundrum.

Grant, you know, keeping in mind, we're not AI experts. We were looking at what the AI experts in those working groups were saying.

And we noticed that there was not such an overwhelming majority of requiring training data.

So we test and we knew that requiring it was going to be a problem.

So we tested the hypothesis of what if instead we require information, detailed information and the training code.

Has anybody actually done, like actually done the kind of proven that the freedoms are are exercisable or it's just been a thought.

In what sense? Rebuilt from scratch?

Like a practitioner, somebody gone and actually modified one of these systems or studied one of these systems that without.

Maybe that's a question I can ask you. Like, why are you using Alpaca for your for your system instead of PTI?

PTI is or Olmo.

So using. I'm choosing I was looking at your demo, the personal assistant, which is exactly what I had in mind three years ago.

Like, my God, we need to find a way for the next operating system to be using these systems and they need to be powerful and capable as much as charge.

So how do we do that? And I was watching your demo and I think I saw that you were using Alpaca in it.

Which is the llama.

Jumbo llama beats Jumbo.

So I'm working on the operating system.

And the reason I'm taking a break from that to focus on this is because I would like to have the protection of a strong, meaningful open source AI definition.

I'm working on the operating system and the demos that you're seeing are applications of the top of the operating system.

So like a video chatbot who is standing in for a lecturer and answering questions about quantum physics or assignment deadline or whatever the thing is.

I don't I give you the choice. You can run what you want. Right.

And the reality is that there are these open source models of few and far between.

And my intention would be that there will be more of them.

But if we don't kind of set a bar and say this is the bar you need to meet to be an open source, be part of the open source, the Linux of personal AI, if you like.

Well, all right. So I can tell you I can share I can share with you what the I can share with you that the systems that now comply in my mind for the definition.

I mean, my I mean, based on the results of the analysis are basically four all made by nonprofit organization.

So the Lutheran I Allen Institute for AI, TIA Falcon and LLM 360 are these are the four groups that are releasing all of their science.

None of the others and companies especially are hard pushing back, not about the data they're pushing back on the data processing code and training code.

They don't want to release that. Even the ones who are more generous, like IBM, more generous about their their disclosure of their training, training details and giving the weights and very permissive licenses, etc., etc.

They are not releasing the training code and they're not releasing the data processing code.

And when I mean my conversations also with VC funders, they always tell me the same thing.

That's not going to happen. The companies don't want to release those.

So. It's another sign in my mind that this is a good working solution, it covers it gives PTA, it gives the Lutheran AI, it gives it gives a lean Agora, it gives next cloud.

You know, these are other open source smaller companies who want to release they're working on open source AI and they want to release more of that.

So we want to give them space to create the tools that you can embed in your system and you can ship safely knowing what what we know.

All right, we're getting at the top of the hour. I see Giacomo join, raise the hand.

Let's go with this question and then I need to go.

The question is simple. If the definition does not require the data, neither its distribution nor its availability, which may be a different thing.

So we should remove from the prelude.

It's the claim that the definition want to grant the right, the freedom to study and the freedom to modify and say that such definition will grant the freedom to fine tune the system because that's what is happening.

Also, why I'm pretty sure that the definition that can be used to open wash any black box, we get a lot more traction among several detectors.

It's going to also to have to the nature of the open source solution that may actually distribute or at least show how to obtain the training data.

So we have.

That is all we are here about.

We are to grant with the such definition that are the freedom to use the freedom to distribute and the freedom to fine tune or we try to actually grant the freedom that the open source usually say to want to grant and require in a way or another.

Now, I think you're bringing up, Giacomo, I can't hear you anymore now.

But if I understand you correctly, you're calling for a litmus test, like some saying on the chat that the that litmus test doesn't exist in software either.

So, you know, we may pretend it does, but it doesn't.

I was talking to Sam before explaining the difference between how complicated it is to evaluate if I can really rebuild fully in a trustful, trustworthy way, any more complex program like the reproducible build issue.

So, why is one issue is it or maybe it's a solution.

The problem here is that in general, the definition does not grant the freedom that he pretends to in the preamble.

We are fine. If it's a speech, we say, OK, we can't grant the right to study and we can't grant the right to modify and we grant that we can grant the right to fine tune our system.

So we grant that everybody would happy.

We'll be happy. In particular, Facebook.

I see what your point is. I see what your point is.

I see what your point is. I do think I mean, OK, you have an issue with the fact that it's it's unclear and it's incoherent in that sense.

I some. All right.

Well, I take it. I think that as a as a comment and unfortunately I need to go, but we can continue the conversation online.

One one request for you to just be mindful of the time of others.

If you can make smaller posts and less frequent, if you want, because you made your point.

I think you've been heard. And and let's try to give space to four others also to participate into the conversation, because if we get if they get overwhelmed, it's going to be a dialogue between two or three people.

All right. Thanks very much. Thank you very much.

Gotta go. Bye bye.

Bye.

### End of last town hall held on 2024-09-27 ###

