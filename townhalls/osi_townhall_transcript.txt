All right, here I am.

Let's start the recording and welcome everyone.

Maybe we can wait a couple of minutes and give a little bit of time for others to join.

Okay.

Okay.

All right.

All right.

Let's get it started so we can use most of the time and we can also collect feedback.

So I'll try to get enough time for people to ask me questions and I'm here available.

Let's get started with some very quick community agreements.

Let's make sure that we have give time for people to speak and if you're the kind of

person who usually stays quiet, speak up, feel free to really grab time and write down.

Use the hand button if you want to get attention or write down your comment, but please, we

want to be able to, we want to hear from you.

Be nice and don't have to remind people that this is a safe space and we don't have to

we have to be gentle and we need to keep on moving.

Also if we face obstacles, we move around and we will get back to it and we want to

focus on solutions.

This is a process that is complicated and it's also quite pioneer if you want.

We don't have that history outside the organization of running this co-design process with multiple

stakeholders across the world and there are a lot of things that we know don't work and

can be done better, but we also need to keep on working because time is on us.

Is there anything else that you think we need to cover in this agreement?

All right.

Okay.

So give a recap to the people who have just started following this work.

We started a discussion to define the definition of open source AI and this is a definition

that is coming from a wide conversation with stakeholders from different sides of society

for a very wide different groups and the objective that we have is to talk to multiple experts

in various fields and disciplines around the world.

We will not be able to have some genius coming out of the basement with a definition.

It's unlikely for this to happen, so this needs to be a global conversation and we're

helping.

We hear as the open source initiative as facilitator, convener of conversations for an open source

AI definition to come out of consensus from different stakeholders and the document that

we're trying to draft looks is made of three parts.

My computer is getting really slow.

Okay.

It's made of three parts.

There is a definition of AI system and a preamble at the top and the preamble contains the basic

principles of why we need open source AI.

And there is a section also with issues that are out of scope to clarify what's not covered

in this AI definition.

Then we have the shortest possible answer to the question, what is open source AI?

And they look a lot like the four freedoms for software that many of us have been accustomed

to see.

And then the rest of it is a checklist to evaluate legal documents that are used to

grant the four freedoms above to the AI system.

And we got to the point where we had plenty of conversation in the second half of last

year, 2023, with a variety of people to have the bones, the bare bones of the definition

of AI systems, the preamble, the out of scope and the four freedoms.

And we're missing this checklist of legal documents at the end.

Yes, I will explain the checklist in more details.

So probably it's worth having a very quick overview of how we are proceeding.

We're basically retracing the history of open source, compressing those 25, 30 years of

history in a few months so that we can get to the open source AI definition.

We're tracing the steps following this sequence.

We're going from a software when it came out, there was a legal framework that was applied

to it.

And a community established itself around the principles of the GNU manifesto.

And it started writing new software, the GNU operating system and sharing that was shared

with legal agreements, legal documents that were granting rights rather than removing

them.

So that's the sequence that we're trying to re-trace.

From understanding the new artifacts, these new AI systems, how they're working and which

legal frameworks apply to them, what are the principles that we want to have applied for

granting freedoms, and then we're going to look at legal documents to grant the rights

rather than remove them.

There is one interesting principle that is written inside the GNU manifesto, and that's

the golden rule that is, it's written, we can reuse it easily to apply to the AI system.

So if I like an AI system, I must be free to share it with other people.

That's the basic principle that we want to embed that we're looking for now.

And so far, what we've learned is that we really need to define open source AI in general,

not just focus on machine learning or whatever is new and exciting in this generative AI

space of the past year and a half.

So the other thing that we have learned is we need a definition of AI system.

And we found that the one provided by the Organization for Economic Development is quite

well accepted.

It's embedded in many legislations around the world and so far can be a valid starting

point.

And at least to get the conversation started, we can improve it later.

And this system definition has this concept of it basically, you can read it, it was very

in November, it was updated by the OECD.

And the other thing that is important that we have learned is that we've established

that for AI developers, we want practitioners that academia users of AI, we want them to

have the same benefits of open source, which is the autonomy, the transparency, the fact

that they have an agency, there is agency for the user.

But we also noticed that policymakers and academia and maybe the developers themselves,

developers of AI systems, they seem to be focusing more or concerned about transparency,

explainability and other objectives.

They're not thinking about open as a value.

So we need to work to match the expectations of these two groups and make sure that open

source AI helps ease the concerns of policymakers and academia.

In other words, it does not block for example, transparent or trustworthy.

We cannot have an open source AI that will never be transparent, will never be explainable

or fair, because otherwise, there will never be an open source AI that can be adopted or

that can be even legal if we look at some of the draft legislation that is flying around

the world.

So the next question that we asked ourselves in a small group is, what basic freedoms

do we need in order to share AI systems?

And the next, the sub question is, what is the preferred form to make modifications to

an AI system?

So the basic freedoms we have started by looking at the definition, the free software

definition and tweaked the language during a few meetings in person.

And we took the language to a point where it seems fair that we can have a more public

conversation.

And this is the current draft of the open source AI definition written down and you

can see it's nothing too controversial or too complicated.

We need to be able to use the system for any purpose without having to ask for permission.

And it's quite important because that permissionless is what enabled open source, the open source

world, the open source ecosystem to thrive.

We need to be able to study, we need to be able to modify and give it to others for any

purpose and without having to ask for permission again.

Now the next big question in order to get a complete draft is, what is the preferred

form to make modifications to an AI system?

And that's what we need to do.

This is the next big exercise that we need to do.

We need to get the specification.

So how are we going to be proceeding on this?

We need to start by identifying the technical legal specifications of what is made, what

an AI system is made of.

What are the components that go into it?

And what are these, the components that are, which of these components are necessary to

use, to study, to share, modify such systems?

Once we have that list of components that we need for each of those different four verbs,

for freedoms, then we look at the legal frameworks that are for those.

And from the legal frameworks, we can evaluate the legal elements, the legal documents that

accompany them.

Matching, for example, if one component is under copyright or intellectual property in

general regime, then we can say the license, we can evaluate the license and see if that

grants the freedoms.

So after we repeat this exercise for more groups, then we'll have a better understanding.

We can create that checklist.

So here's the, how we're going to proceed.

And we're going to proceed by evaluating a few examples, very specific elements, very

specific systems like BTR or Lama2 or Bloom, and we'll split into small groups.

And we're going to ask the questions one by one.

What do I need to give input and get an output?

So that's the use or and modify, et cetera.

So for example, if we want to give one by one, let's look at PTA.

What do I need in order to get an output from PTA?

Then probably we'll need weights, inference code, for example, in this one as elements

and components.

Like then why is PTA giving an input gives one output?

This is what we need to know.

We probably need to know the architecture, what went into building the dataset, maybe

access to the dataset itself and calculate the biases, et cetera.

Then moving on, how do we modify and get a different output from PTA?

They're big question.

And finally, what we need in order to share it, you know, what share the original version

or the modified version?

So we'll need to run this exercise for more than one of these systems and write, get those

components in general, analyze the legal frameworks, analyze the legal documents, and write up

a summary.

And that's going to be our-- most likely, it's going to be our basic components of the

checklist that we have at the end of the document draft definition.

In terms of timeline, we need to work-- we need to activate, like, at least-- we need

to move very fast because everyone is-- there is already enough confusion on the market

and many groups that are talking about open source AI without having a big-- without having

a shared understanding of what that means.

And we want to get with version 1 in October of this year.

So towards the end of the year.

And this means that we should be really having a release candidate around the beginning of

the summer.

In order to get to that, we need to have monthly release cadence of drafts and a constant

public review of our work with these town halls that we're going to be running-- that

are going to be running every two weeks at different time zones.

And the important piece here is that-- so we're going to create working groups and we're

going to create working groups to analyze these AI components.

And we're going to be releasing new drafts as we go.

Monthly with a monthly cadence.

Hopefully by the end of May, early June, we'll have an in-presence meeting.

We want to have enough support from different stakeholders.

And I'm going to talk about that.

What do we expect for the release candidate?

Is to have at least a draft that is completed in all its parts.

And support from at least two organizations, two groups for each of the stakeholders in

that we have-- in the groups that we have identified that I will show in a second.

And for version one, it's basically a larger group of support.

So more stakeholders that support and endorse the definition.

And we have identified six categories of stakeholders.

The system creators, the ones who are going to be creating AI systems and they will need

to-- so the ones that will create the AI systems.

And the license creators, the ones who write the legal documents to apply to the AI system

of components.

The regulators, we want to have at least-- going to want to have conversations with regulators

to get their feedback.

If they may not be able to give us endorsements, but at least we want to hear what their thoughts.

We're going to have early exposure to that.

Then we have licensees, the ones who seek to study, modify, share an open source AI

system.

So it's engineers or developers, researchers.

On the last two categories, it's where we probably need most help is end users.

So the ones who, one, need to consume the system output, but are not necessarily interested

in studying or modifying or sharing the system.

And then the final group is the subjects, those who are affected by the effects of the

system outputs, whether they are upstream or downstream.

We use this to indicate, for example, prospective homeowners whose mortgage application is evaluated

by a bank through an AI.

That's a downstream subject.

Or for example, photographers who find their image in a training data set.

That's like content creators.

Those are upstream subjects.

We want to be talking to these organizations, too.

And we want to have their feedback.

And maybe and hopefully also they're endorsing the definition at the end.

One thing also that I want to say is that this doesn't end, this process will probably

not end with version 1, because this is going to be the first definition of open source

that has a version number attached.

So we'll need to have by the end of the year, once we announce version 1, we'll need to

have in place rules for maintenance and review of this definition.

We're probably going to need to maintain and update it, given how quickly the technical

landscape changes, we will have to adapt.

So our immediate next step is we want to have the process make it more public.

Until now, we worked with a private drafting group that has been helping.

And now we got to the point where we feel there is plenty of momentum on one hand and

plenty of shared understanding of where we stand and what are the roadblocks, the biggest

ones.

So we want to have public discussion forums.

We're starting today with this public biweekly town halls.

And this will open up also to more opportunity for more opportunities to volunteer and help

out.

We'll be updating our project landing page, the opensource.org/deepdive.

We need more stakeholders to get involved and we're raising funds.

And we're also setting up the OSI board to review and approve version 1 once it comes

out.

And the drafts are being published.

They're already public and they're already public also the comments.

You can go to deepdive/drafts and you'll find a list of the published drafts and you can

join the conversation in there.

And with that, I want to open up to questions from you.

I see that there is a little bit of a discussion here already.

Do I have domain experts?

Yes.

So some domain experts have already volunteered.

I'm talking to basically friends.

Like there is one of the developer advocates and outreach advocates at Intel.

He's a personal friend.

I'm going to talk to him next week.

The people at Luther AI have made themselves available to help out to analyze Pythia.

And I'm reaching out to developers at Meta to get an explanation of Lama, Lama 2.

And I'm happy to talk to more people.

I have other people who have also volunteered to help.

And we got expertise also inside the board to help out.

To review, to run those reviews.

The topic of content creators and the New York Times with their lawsuit.

Yes, the legal team, the legal experts inside the board are already aware of that.

They're following it.

And I'm pushing the board and the board itself.

People inside the board are getting more expertise and getting ready to even write opinions eventually

on those topics.

It's really interesting to see what's happening in the content on the content creators front

and those legal issues.

Any more curiosities?

Maybe I can spend more time to talk about that checklist idea.

The idea is to get it is to get the completion of that document of the open source AI definition

needs to have something that resembles that can help that can help the license committee

or the AI committee that will be formed.

Some committee inside the open source initiative to evaluate the legal documents that are coming

together with an AI system.

So that an AI system can be judged whether it's open source or not.

Whether it grants the four freedoms that it's supposed to grant.

That is the checklist basically.

Yes.

Daniel.

The question about the getting the discussion people from the global south and not just

the United States and Europe.

Absolutely.

It was one of the eye opening conversations I've had with one of the meetings we had last

year was in Africa, Ethiopia with the digital public goods alliance.

Members meeting, members summit, private event with the DPGA members.

It was really eye opening.

So we are absolutely open to that.

And more than happy.

Like one of the call for actions, one of the things where you can help is to put us in

touch with the people who can participate to these meetings.

And workshops.

So I'm happy to follow up with you, Daniel.

Yes.

Amanda.

Good idea.

Yes.

We'll publish the agenda as we go forward.

Ian or John, I don't know how to pronounce your name.

Probably so.

That's one of the things that we need to understand.

What kind of so access to training data is probably unavoidable.

The question is what kind of access?

What level of access?

The full on training data set?

Or is it sufficient to have a detailed description of what went into it?

Or something else?

That's what we absolutely that's probably one of the most important, most difficult

questions to ask.

And most delicate conversation also.

That's why we need to look at the individual specific.

We try to have this conversation in generic terms.

And having the conversation in generic terms ended up generating a lot of yes, but.

Or yeah, but in this case, maybe if.

You know, lots of uncertainties.

We need to be specific.

Let's look at specifically what's happening individually with PTA, with Lama 2, with FIDO,

with one of these with OpenCV components, like OpenCV algorithms.

Let's have a look at specifically what these need.

And then we generalize.

SBOMS with yeah, of course, like again, with the expert, with someone who has been modifying

Lama 2.

For example, this is one of the questions I asked one of the one of the friend of mine

who's been working with and modifying Lama 2.

Let's have a chat.

What do you what do you actually need in order to modify the behavior of the Lama 2?

For example, that's the exercise we need to do.

Responsible data.

Okay.

Amanda, can you send me?

Yeah, I'll save that.

And I will if you have people who you know who will be I'd be happy to talk to them.

I see other people typing.

Did I answer your question?

Okay.

Thank you.

Yes, links to slides.

I got to publish them.

So the next steps I mentioned, one is to we're going to be creating these these these forums,

public forums where we can we can have conversations more more openly.

And let me pull it back.

And and run the exercise.

I have scheduled meetings next week.

As we as we get more as we run these exercises, analyzing PTA and analyzing Lama 2, building

that list of elements of components and getting through the the the analysis of the legal

frameworks and and and their legal things like let me get back to the slide where it

shows.

Yeah, this is the exercise that we need to do.

This one.

We need to go through this pipeline as quickly as possible.

And once it's completed, we'll have version five, draft five.

And from then on, we'll keep on iterating with with more online meetings and we'll try

to be more more visible, more transparent from now on.

Everything will be public.

And if you follow us on Mastodon and and on LinkedIn, you get the updates.

But as soon as hopefully end of next week, we'll have the public forum, if not the beginning

of the week after.

By the end of the month, for sure, we'll have the public forums that you can sign up and

have discussions and conversations and get updates.

All right.

Are there any more questions or doubts?

Yes, we should.

We should be studying also applications not based on machine learning or deep learning.

Yes, Jean Pierre.

You have any specific suggestions, recommendations for one example that we or two examples that

we we need to look at?

Claire, the best link is open source.org/deepdive.

But that page is in the process of being updated.

Diane, yes, ML Commons is looped in with this initiative and as is the Linux Foundation,

Linux Foundation groups.

That's another thing that we should be we could be doing is to publish all the organizations

that have been participating so far, following the development so far.

I offer.

Okay.

I think we can also do voice.

Voice questions.

If anyone has.

Yeah, we'll share it as a PDF, don't worry about it.

All right, folks, if there are no more questions, I'm gonna close the recording and

we'll make available the recording and a slide deck.

And I'm gonna be available again in two weeks, similar content.

We're gonna alternate the times so that instead of being in the afternoons in

Europe time, we're gonna be in the morning in Europe time.

So we're gonna try to follow to get the Asia Pacific

audience to follow, an opportunity to follow.

So thanks everyone, enjoy your weekend.

All right, and welcome.

Welcome everyone.

This is our second public town hall on the open source AI definition.

The process that the open source initiative has started more than a year ago now.

So a little ground rules before we start, we have these community agreements and I love

to have your comments on these one person at a time.

Meaning make space for others.

If you have the tendency to speak a lot, try yourself.

Think about being quiet and allow others to speak up.

And if you're the kind of person who usually doesn't speak, I highly encourage you to raise

your hand, write down your comments on the chat or take the mic.

We want to hear your voice.

We want to hear your comments.

Everyone is welcome.

Be nice.

I don't think that we need to be talking too much about this.

We expect everyone to go through this hard work without being hard themselves.

And another couple of points, like we need to keep moving.

And this means that if we face an obstacle during our conversations and as we are drafting

the open source AI definition, we may want to face recognize that we have an obstacle

or something hard to deal with.

But during the meetings, we try to keep on moving.

And we'll get back to the hard part later.

So then we go towards the destination.

And focus on solutions.

That means this is pioneer work.

It's a multi-stakeholder process.

And we know that there are a lot of things that don't work that can be done better.

But we need to focus on what works and keep marching towards the end goal.

And the end goal is to have the open source AI definition version 1 by the end of the

year.

By ideally October.

We started more than a year ago.

And we need to have a shared understanding among multiple experts in various disciplines

around the world.

This definition is not coming from a sacred text given by a genius or a saint or some

other form of venerable entity.

It needs to be built by us.

And we need to build an understanding together as we move forward before we can call this

version 1.0.

And I said we started some time ago now.

And this is what we have achieved so far.

We have a document that we're calling this definition.

And it's made of a few parts.

There is a definition of AI system at the beginning which is the same as the definition

used by the organization for economic cooperation and development.

OECD.

And there's a preamble that contains the basic principles of why we need open source AI.

And also mention of what is out of scope.

Meaning the things that we're not covering in the definition.

Then for freedoms which is the shortest possible answer to the question what is open source

AI and followed by a checklist to evaluate legal documents, not just licenses that are

used to grant the four freedoms to the components and elements of an AI system.

So we have done quite a bit of work on the part above the checklist.

And that's what we're missing.

We're missing the checklist.

That's what we're focusing on.

That's what we focused on the last couple of weeks.

Since our last meeting.

So what is open source AI in terms of the four freedoms?

This is the text that we have now in draft four.

And after a few reviews with a few experts, I don't think that this is up for discussion.

But I don't think that there are a lot of controversies or controversial statements

in here.

I think it should be quite fairly understood and fairly well supported.

Now what we need to do in terms of question that we need to find an answer for, the next

big thing is to understand what is the preferred form to make modifications to an AI system.

Because if you those of you who are familiar with the open source definition and the free

software definition, the preferred form to make modification is quite crucial to understand

how you can make how you can exercise your freedom on software.

To exercise your freedoms on software, for example, the freedom to study or the freedom

to modify the software, you need access to the source code of that program.

And we need to find an equivalent of source code of the program for the AI system.

And the proposed path towards getting there is to use this multiple steps.

First start from the concept of AI system.

Now AI system as defined by the OECD means to simplify a system, a digital system that

is capable given an input to generate an output with various degrees of independence from

human interactions.

So input, magic collaboration, output.

Now for the first step that we're working on now is to find the list of components that

are necessary to use, study, modify, share an AI system.

And depending on the component, then from the list of components, we're going to look

at each of these components to see if in which in each legal, which legal framework, legal

regimes they operate under.

So if it's, for example, the inference code or the training code that is software, it's

under the what we already know that is covered by software.

So it's going to be what people refer to as usually intellectual property or things like

that.

If it's data, then we have different regime.

And this is also going to be an exercise where we're going to be identifying potential gaps.

But we already know, for example, that large language models, the weights, for example,

are not clearly, are not yet clearly labeled either as data or software, and they may fall

into some other regime.

So there's going to be conversations around there.

And then we're going to look at existing frameworks.

I mean, for each component, we're going to look at the legal documents that go with them

and see if there is any gaps.

And reading them and analyzing them, identify common traits.

And finally, we should have, after repeating this exercise for many different AI systems,

we're going to have something that looks like a valuable checklist that we can use for many

years probably, hopefully.

So last week I said the past weeks we have started working to analyze Lama 2 as an AI

system as an example.

And this is what we discovered in the meetings and online conversations that we had last

week.

We assembled a working group made of these people from different organizations, different

expertise, all of them participating in the personal capacity.

This is one of the -- none of them is authorized to speak for the company, but they are working

-- they're collaborating with us.

And the -- so the purpose of the meeting is -- I mean, we show the purpose of the meeting.

It's part of the -- part of a track of work that is testing the system to discover the

components that are available, like the -- and so make that list and identify which ones

of them are absolutely necessary for -- to exercise each of the individual freedoms.

Like the study -- use, study, modify, and share.

And so we have reviewed the table of components that we have -- that we have borrowed.

We've been following the work of the Linux Foundation, AI and data foundation, and data

group, they've been working on a document on their own.

And that contains a pretty long, pretty detailed list of components.

And we've used that as a conversation starter for our exercise.

We have -- so this is what we've done.

We have separated the list of components into four main blocks.

Well, three main blocks and one smaller block.

One for things that we call code.

That is software.

And we have, for example, looking at the code, list of components that we call code.

And apply to the exercise -- I mean, the function of using an AI system.

So getting an output from an AI system.

Asked the group to write down if that component was necessary, strictly necessary or not.

For running or using the system.

And this is the first result for the code.

And then the next question is looking at the data.

Separated into many -- you see many different types of datasets in here.

And we asked what is necessary to use Llama2 in terms of data.

And as you can see, most of the answers are in the not necessary.

And we also captured in the document the comments on nuanced approaches.

It's not necessarily it would be nice to have.

And this is something that we want to debate further.

I'm gonna ask a question to you afterwards.

And finally, on the model itself, so the model weights, parameters, architecture, model card,

et cetera, we asked people here to describe what is needed to use.

I gotta say there was a little bit of a lot of actually a lot of conversations during

the meeting around the meaning of these words.

And there was a major misunderstanding on the word model parameters.

Because in the intention of the paper from the LFAI data, which is a very early draft,

so it's not really meant to be quoted yet, model parameters contains both model weights

and model biases and parameters, hyperparameters and other elements.

So there was a little bit of confusion.

But there was -- you know, the group seemed to agree that, of course, you need the model

weights to run, to use Llama2.

And other components like model card, some people interpreted the definition of model

card as something that is necessary for use.

And then finally, the last group of elements or components is on the documentation, the

supporting documentation.

Like, the availability of a thorough research paper for the execution, you know, for running

Llama2 is nice to have.

I guess, you know, you can understand a lot of things.

But it's actually not strictly -- what is strictly or much more necessary is have documentation

on the usage.

And this is the current status.

We didn't get through -- we didn't get through the first meeting, during the first meeting

through the other freedoms, Modify and others.

But we're gonna keep on iterating with the others.

So yeah.

This is what we need to do next.

It's to ask these questions on what you need to study.

So understand how the Llama2 was built, fine-tuned, how it can be fine-tuned, what biases are

in the dataset.

And things like that.

Explain its performance.

And on the Modify questions are more on the -- what are the tools, techniques that we

can use to fine-tune, optimize, get a different output from -- or faster outputs from the

model or more accurate.

And finally, in order to share it, what are we gonna do?

You know, what is necessary, what is needed?

So for us, the next steps are continuing on this process of running these meetings and

starting new AI systems.

We've already -- I've already asked a few people who volunteered to analyze Pythia.

But we need to start parallel the process for Bloom and Mistral.

And also we want to look at AI systems that are not generative AI, that are not large

language models.

And like inside OpenCV, the Open Computer Vision Project, there are a lot of neural

networks and other kind of AI that are not generative AI.

So they pose a slightly different -- slightly different questions if we want to look into

those.

So if you know anyone in those areas, point them our way.

And I'll give you also more information about how to engage later.

And we also need to validate this list of components.

As I mentioned, we worked with the AI and data from Linux Foundation.

But we know that the -- that their paper is not peer-reviewed.

And their working paper, they're still working on it.

So we need to provide feedback to them.

But also we need to see whether that list of components is enough or if we need to keep

on improving it.

So to reiterate our timeline, it still looks like this.

We want to have a new draft of the definition in February.

And then a regular cadence every month.

Have a new draft of the definition.

Refining at every step.

And most importantly, the most important part is as we refine this step, we also have more

publicity to it, more people supporting it, endorsing it.

And we need it to -- we want to get to a point in between the end of May, early June, where

we have enough support and enough endorsements collected from a variety of different stakeholders

to be able to call the definition feature complete and issue a release candidate, first

release candidate.

Then between June and October, we want to get into a series of conferences, a series

of meetings around the world with me and other volunteers who have participated in the drafting

process.

Maybe some of the original endorsers that participated to release candidate work.

And push it through a big exposure and a round of larger feedback.

And by October, gain like double the amount of endorsers and be able to call it version

1.0.

And because version 1.0 will be basically feature complete license that enough organizations

from a variety of interests will be supporting it and be able to endorse it.

And say we're going to be using it.

But then after version 1, we know that there's going to be more work to be done.

So in terms of stakeholders that we want to have in the rooms to work with us on the definition,

we need to find a way to engage with policymakers.

That is we have some contacts and we need to have a little bit more of conversations

with people who are working in the government space, in the policymaking space.

Even though of course regulators will not be giving comments to us.

People who write the legislation.

And we will not engage with people who write legislation directly because we cannot as

an American.

But we want to hear from the people who are in this space.

Because we notice that there is legislators are concerned about abuse of AI.

And there is already starting to emerge a vision that open source AI or open AI widely

available models and AI are capable of influencing elections or creating havoc in the society

in general.

So we need to make sure that whatever definition comes out of this process is not seen as a

threat to society by regulators.

That's something we need to be very careful about.

And we need to explain this as we go.

Understanding the problematics and solve them as soon as possible.

And we need also to engage a lot with end users.

So people who are like interacting with a bot at a bank.

Or subjects.

These are people who don't know that they're talking to an AI and they are affected by

the automatic decisions, for example.

We need to engage with them.

So how a reminder, this is doesn't end with 1.0.

We already started to define to think about what's going to be the future of 1.0.

Like the open source initiative and its board has set up is setting up a new committee to

brainstorm to think about the maintenance of this definition that is coming very quickly

in a space that is evolving even faster, even more rapidly.

So we need to prepare to catch up and to have a process to maintain the definition to keep

it valid over time.

And so what we're launching today is a new forum.

We'll keep on doing these biweekly town halls and we'll keep on adding opportunities to

volunteer to help out.

We're working on a new version of the landing page to have the information all about this

process all in one place.

And we've done that.

We're working on this.

And as I said, setting up the board for managing the future.

So as a big announcement for you is to the opening of the forums to have this conversation

publicly online in order to join the forum.

The forum uses the single sign on with other OSIs website.

So you can you need to become a member of OSI.

That is a free member.

We have three tiers.

There is a free membership.

So you don't have to worry about having to pay.

Or if this is an opportunity for you to support this work, which is very important, you can

become a full member and donate to us from $50 a year and up.

And on the forums you will find the links to the latest drafts.

We will keep on asking questions on the forums.

We'll keep on having the conversations we're having here constantly on the forums.

And with that, I will I see that there are some questions on the chat.

If you prefer, I can unmute all of you.

You can also take the mic and speak.

So I'll answer the question from Dirk.

What licenses are required for the data and software components in the AI system?

So we'll be talking about it.

From the software components, it's I think that the answer is going to be quite easy.

Anything that is recognizably software, we need to use licenses that have been approved

by the open source definition.

For the data component, it's we'll have to have conversations around that.

I think we are working with organizations like Creative Commons and I mentioned the

Linux Foundation AI Data.

They have their licenses.

There are different licenses that qualify as open data.

The open data world has a different culture than the open source movement and the open

source world.

The data people, I mean, the people who have been dealing with open data that I met, I'm

not sure how much they have been thinking about the fact that their data is actionable.

We need to understand with them, we need to work with them to understand exactly what

they think of their space once the space of open data, once it becomes actionable just

like software.

In other words, to make a pretty simple example, not many data sets out there are maintained

in a way that they can be modified and fixed.

One of the latest examples that I noticed is that in an open data set that has been

used to train a lot of the large language models had reported, I mean, someone analyzed

it years ago and found that it contained a lot of images that were illegal in many parts

of the world and absolutely abhorrent, including child porn and atrocious material.

Now the project that the people, the group that maintains this data set, which is open,

never received a public issue.

This is on GitHub, this data set.

It's a GitHub project and there was no issue filed, but there was a paper, a research paper

filed that described the bad material in the data set.

So I think that there is work that needs to be done into this community because they're

completely different and they're probably inside a similar conundrum that we as open

source groups are when it comes to AI.

Our world is being disrupted, let's say, modified.

I don't know if that explains it.

Any other questions?

Curiosities?

Thanks, Kellen.

Yeah, glad to see you.

And I hope that we can, yeah, we can work together soon.

Any other concerns, questions?

I'll give you time to start playing with the forums and maybe if you have any technical

issues, you can, we can do, play with it.

All right.

No more questions.

I'm going to stop the recording.

Thanks.

Bye.

All right.

Thanks for joining this panel meeting again.

Sorry for my voice.

This is the result of a week of conversations in Brussels in very loud environments.

I think I stressed out my vocal cords a little bit too much.

And I caught the false debug, which is not COVID.

Just a little cold.

So the purpose of these meetings is to keep the tempo and get live conversations and live

updates on the most important things that have happened in the past couple of weeks.

And let's remind everyone our principles under which we operate.

We try to have -- make sure that one person speaks at a time.

There's no crowds around Mike.

Try to make space for others.

If you tend to be quiet, speak up.

You can use the buttons to raise your hands in this meeting, but you can also type if

you prefer not to speak up.

But please give feedback.

This is the best place to have quick interactions.

Let's use them.

And I don't think we need to be stressing the fact that we want everyone to be nice.

And keep in mind, we need to keep moving.

We need to finish this process.

And if we face an obstacle, we move around it and we should be getting back to it later

rather than stop it and admiring how big and insurmountable it is.

And we need to focus on solutions.

It's a multi-stakeholder, co-design process.

It's basically pioneer work for us.

And we know there are a lot of things that don't work that can be done better.

But we need to focus on what actually works and keep on moving.

Are there anything else that we need to take care of?

All right.

Reminder.

I was wondering whether to keep this slide or not.

But I think I want to remind everyone that our objective is to have an open source AI

definition that is workable, that is good enough by the end of the year.

It's really important.

And everyone is asking, not only is asking for one, but I think that we really have this

responsibility to create, to come to an agreement, to agree on something.

And notice the version number 1.0.

It's not necessarily going to be the most perfect one.

We will always be able to fix it.

And a reminder for what we have so far.

We have a definition of AI systems in a document, version 5.05.

And we have basic preambles for the basic principles of why we need an open source AI.

And we may want to have this wording also reviewed and straight up as quickly as possible.

Because that's another question that I get asked often.

Why do we need open source AI?

Why is it important?

I refer to this preamble, but I want to make sure that we are quoting that.

The other piece is the what's Atascope?

And there has been a little bit of discussion around what is Atascope.

I encourage you to give feedback on this text, too.

Because I don't want to, you know, I want to have it finalized as quickly as possible.

I don't think that it's bad, necessarily.

But we want to have a conclusion very quickly.

Then we have the four freedoms.

There isn't much debate around this right now.

Although there are a couple of questions that I will highlight later.

And what we're working on right now that is missing is this checklist of legal documents.

And I give you an update now on this, on the work that we've been doing.

So the four freedoms as described here are at the core of the open source definition

of AI.

And we're at the stage where we need to identify what are the preferred forms to make modifications

to an AI system.

And in the process, understand what we're going to be is highlighted here.

And we're at the stage two.

We have a list of components that we have identified thanks to the work done by Linux

Foundation AI and Data Commons, Generative AI Commons Working Group.

They have provided a list of components for machine learning systems.

And we have been using that list of components to identify which of those components are

required, they are a must have, in order to be able to use a system, to study a system,

modify and share it.

And then once we have this list with these matching points, we're going to be progressing

on this, on this, on this line, on this timeline, where we're going to be checking whether the

components have or fall under which legal frameworks, whether that's exclusive rights,

exclusive rights like intellectual property, broad term, copyright, patents, secrets, or

what have you.

Or if they don't, what kind of legal frameworks they fall under.

And then we're going to be looking at the licenses as a next step.

And the licenses are legal documents, legal terms, with which they are distributed.

We're going to be identifying gaps.

And from those gaps, and from the list of legal documents, we're going to make a checklist

to evaluate the freedoms in these legal documents.

Now we started working with two groups, analyzing specifically Lama 2 and PTI as examples, two

examples of generative AI machine learning systems.

And the members of these groups are in this list, me and Mer, are almost basically observers

and facilitators of the meeting.

And we have experts of different, different capabilities.

All of these people are working for a company, one way, shape, or form.

But they're participating, not representing their company's views.

They're representing us, experts.

But of course, for transparency, we list their affiliation.

So this is the Lama Working Group and PTI Working Group.

It's a little bit smaller, but it includes people here from different parts of the world

also.

So with them, we have gone through, the process has been, we're at the point where we are

at this working group report.

They need to go through these documents.

They're going through these documents.

Let me share with you what's happening, what's happening in here.

So for, we built this table, you may have seen it in draft five that I published at

the beginning of last week.

The draft five of the definition of open source CI has this table at the bottom, in which

you can see the list of components, and then on each, on the first column.

And then there are other four columns.

Those four columns have, basically, they're going to be X marks, whether the component

on the row is required, so it's mandatory.

It must be available to use the system, to use LamaTo, or to study LamaTo, or to modify

and share it, LamaTo, so individually.

And the components are split into four categories.

There is code, and this is what happens, what are the analysis done by the experts in the

working group for LamaTo.

And it looks like, in order to, the kind of code that we need to, there is pretty much

consensus on the kind of code that needs to be available for using LamaTo is the inference

code and the libraries, such as the tokenizer and hyperparameter search code, et cetera.

So those are required to use, seem to be.

In order to study, there is a little bit less participation of this group, like only one

person so far has filled in the table.

And it looks like training code and data pre-processing code and the other libraries are required

to study and to modify.

Similarly, there is little participation, but there are some boxes in here.

Moving forward on the data front, doesn't look like any of the data is required to use

the system, but SC is the initials of StackFano Zacchiroli.

He's looked at the, he's left these comments that training data set and other data documentation

is required to study.

And similarly, testing and validation data set is required to modify the system, but

not to use and share.

And finally, on the use front, looks like there is pretty much consensus that model

parameters is necessary to use it and study, modify, and share.

And maybe usage documentation, according to StackFano Zacchiroli, is required to modify.

And moving forward, Pithia, this one working group has done a little bit more work and

it's a little more comprehensive.

You can see that in order to study the data, it looks like there is a lot of boxes checked

here, which is very interesting to see.

Some data is even necessary, according to Sarah Young, in order to run, to use the system.

It's going to be interesting to see, to have for her, the rationale behind this decision.

And on the data front, sorry, that was the code front, yeah, okay, so on the code piece.

On the data front, some data required to use, but there is a unanimity that, again, a lot

of data is required to study, which is also very interesting and needs to be investigated

further.

And when we build a model for execution and model architecture and parameters seem to

be necessary, but also modify and share.

So this work is making progress.

We are, we have scheduled two more meetings with each of these groups next week, and we're

going to drive for completing these cards by Friday, so that we can have two complete

analyses and publish them for a wider conversation on the forums.

This is going to be a very major milestone for us, and a very good, important result.

Now, the forums that we launched, we launched them, was it last week?

They already contain a lot of interesting conversations, but I wanted to highlight three

of them that I think are very crucial to have some sort of, to have a, to drive towards

a conclusion so we can release a T in three weeks, four weeks, we can release a new draft

of the definition.

And I think that the top and most important one is the conversation around data, and you

will see it on the forum.

This is one of the ones with the highest amount of comments on it, I think.

It's worth keeping an eye out in there, because I think we need to come close to a conclusion

very soon, or at least to try to understand what the consensus is, or if there is no consensus,

we need to highlight why, and what are the reasons, the main reasons for that lack of

consensus, the controversial part.

It's very crucial in there.

And the other thing, the other conversation we have ongoing is that I think is important,

it is the one on the definition of AI system, that right now we've been using the one provided

by the organization for economic cooperation and development, the OECD.

There are a couple of comments, one by Richard Fontana, but also others, that, arguing that

the definition by the OECD is too wide, and too, that covers pretty much everything.

Everything digital.

And we may want to revise it.

So I don't have a strong attachment to that definition, or any other definition, but we

need to have a definition of AI system, because the open source AI needs to refer to a system,

and not to individual components, or pieces.

We need to have a framework of reference that we can tie to.

I go back to explaining that the open source definition for software refers to programs.

And programs, even though they're not defined either, but pretty much everyone knows what

they are, the discipline, and the software, the computer science is old enough that we

know a program when we see it.

For AI, I don't think we have that luxury yet, and we need to be able, we need to be

a little bit more specific.

So if anyone knows of different, better, well understood definitions of AI systems that

we can use and reuse, so please go and make suggestions on that thread.

There is another one that is very interesting to me, at least, and there's a conversation

around the meaning of the verb share, because there is an argument being made that the sharing

needs to be clarified, that we can share the systems with the same conditions under which

we have, under the same legal conditions for which we have received it.

I, you know, it's a very quite legally type of question.

I'm not exactly sure I understand where that conversation, that question is coming from,

but I see people involved in it, and I would recommend someone looks at it and tries to

explain or tries to find a converging solution.

So what are the next steps?

And maybe, let me see, I see a question in here.

Nick, the result for Lama2 and PTA, should they be similar?

Eventually, yeah, I mean, probably they will not, because they're different people making

different evaluations.

They should be similar, because they're similar systems, similar architecture, similar things.

They should be similar, but if they don't, then that's what the process is going to be

like.

We're going to have to have a conversation once we have also Bloom, for example, the

three of them, we will have to find a way to identify the diversity and why, explain

why things are different, and drive towards a conclusion.

I think a lot of the work is going to be around explaining exactly what access means.

I'm sensing from conversations I've had with multiple people that the concept of access

to the data, access to the architecture, access to the documentation is different.

Sorry.

Sorry for that.

All right, so what are we doing next?

We started recruiting people, but we need to review this list of components and the

checklists that the two working groups on PTA and Lama2 have started, and also we started

recruiting people to analyze Bloom OpenCV, and we may even need probably will recruit

for more other systems if necessary.

But at least we want to look at OpenCV as a curiosity mostly because it's a non-generative

AI just to validate that list of components down the line.

That's for the next couple of weeks' work.

And just reminding everyone, the timeline is here.

We have draft five released in February as scheduled.

We're going to be releasing 06.

We keep on going with these virtual meetings, town halls, and work group activities, trying

to speed up things so that we can get in end of May, early June with an in-person meeting

that will eventually resolve the last controversies and issue a release candidate.

This is a very aggressive timeline.

I keep on stressing this out.

We need to keep the tempo, and that's why I'm putting so much energy into this.

Once we have the release candidate, the idea is to take it in a roadshow around the world.

We have found already three partner conferences in different ways in different parts of the

world where we can host a presentation and a review of the release candidate.

And so we get to number version one in October.

The criteria for respectively release candidate and version one is to have representatives

from each of the stakeholders to support it, and all of this information is public now

on our website.

And these are the categories of stakeholders where we would be putting logos in here as

we go.

And that's the other reminder that I want everyone to keep in mind.

It's not going to be perfect.

And the board of the OSI is already working on setting up a committee that will be looking

into the review and approval of version one when it comes out, because it's going to be

the board's purview to review and finally approve the work of the community and take

over the maintenance of this definition, because this is going to be the first version, the

first definition maintained by the OSI with a version number in it.

And yeah, we're working very hard to make sure that we have the funding to support all

of this.

So but I'm crossing fingers.

I think we're going to be okay.

And if I run out of funds, I'm going to let you know in advance.

And we got the forums.

I'm pretty excited about this.

So they're easy to sign in.

If you have already a member, log in for any of the open source initiatives, websites,

and opensource.net, it's going to work seamlessly.

If not, you can register, become a free member, or now is also a good time to sign up and

become a full member so that you can vote also at the next election that are coming

up for the board.

And we're also draft 05.

Since last time we spoke at this time, it's a new thing.

So go and look at the latest draft also.

And leave your comments on the you can leave comments directly on the draft, or you can

leave comments on the forums if they're more generic.

If it's specific for, you know, I want to change this word, I would recommend leave

the conversation on the draft.

But if it's more generic about and requires larger, more text and stuff like that, like

leave it on the forum.

And with that, I'm happy to take questions.

Victor, public link to LamaTubePT session.

No, well, actually not yet.

Not yet, because we want to leave the groups to work a little bit more, you know, in peace

and without having to be, you know, like under, what is it called?

Under, you know, like a aquarium type of thing.

We're going to make public everything as soon as the work is done.

Matt is that correct as an answer?

I cannot hear you.

Sorry.

I need to enable you.

You should be able now to unblock your mic.

And now you're muted.

You need to unmute yourself.

Thank you.

It's only been three months, three years of pandemic.

Yeah, so the groups themselves, they meet as small groups, but the membership is transparent.

And then we report out all the documentation that's being created, which is the summary

and also the tables that Stefano shared.

And that really is the report.

I think we're also planning to make the slides that the groups are working from public, which

is effectively the agenda.

So that's how we're balancing transparency and also people being able to have a meeting,

which I think also has value.

So yeah, open to any feedback.

Thank you.

you

you

you

you

you

you

you

Welcome to the fourth Town Hall. The scope of this Town Hall is to get people the chance

to interact live with the process, ask questions, and get regular updates on what's happening

and what's hot. So for the live meeting, just a few ground rules. We want to be giving space

and being nice, listening to questions, but also make sure that people can ask questions

and feel empowered to do so. But we also want to make sure that we're moving forward. We're

not getting stuck debating forever. We need to make decisions and keep on going. And let's

remind everyone that the objective for 2024 is to have a working open source AI definition.

And by working, I mean it must be something that has endorsements from different groups

and can be put in practice and allows for open source AI systems and components to exist.

It's not something that is theoretical pie in the sky. We love it, but nobody can use

it in practice. What we're working on is to have a definition that is made up of a few

pieces. We have pretty decent understanding of all the pieces in here, minus some wordsmithing

and clarifications, but the basic piece that we're still working on is the license or legal

documents checklist at the bottom. So what happens, we have clarified that what is open

source AI is basically something, it's referred to AI system. And the reason for it is that

it gives us an anchor. It gives us a way to clarify what we're talking about, what freedoms

we want to use. And it helps us run, drive the conversation around what do I need in

order to use an AI system? What am I actually using? What is it that I want to study? What

is it that I want to modify? What is it that I want to share? What kind of practical outputs

or practical elements, examples I want to get out of this freedom, out of this verb?

And so we've been running this exercise with four groups that have been split into analyzing

four systems, Lama2, Bloom, BFIA, and OpenCV. Three of them, the first three are generative

AI systems and OpenCV is non-generative. It's a computer vision program, computer vision

framework, set of libraries with different algorithms. And some of the algorithms that

OpenCV uses are neural networks and so machine learning based systems. And we wanted to see

with a little bit of differentiation, if the requirements are different for non-generative

AI systems so far. So you see the people who have volunteered to analyze the systems and

there is a lot of diversity here, geographic representation from all over the place, from

all places in the continent. There is academia represented, there are industry players, there

is civil society interest in here too, and government organizations like the ITU. You

can see a lot of diversity here. I'm really happy to see the involvement of the very wide

breadth of people volunteering their time to contribute to this effort. I kept saying

this from the beginning, this is not the effort defining something new like open source AI,

having a new definition. The Open Source Initiative is not the work of a genius in a basement

that comes out with a secret text. This is the work of a community that puts their brilliant

minds together and drives towards consensus, drives towards a shared understanding of what

open source AI means. That's what's going to make this valuable.

So the summary, so these groups have been looking at the list of components that have

been produced by a list of components, generically described in a working paper that is almost

ready for publication by the Linux Foundation AI and Data Generative AI Commons Working

Group or initiative inside the Linux Foundation AI and Data Foundation. They have produced

a list of components that they want to use as a reference for judging the projects that

are going to be hosted by the Linux Foundation. We've taken that same list of components,

we passed it to the working groups, and each of them have been looking at the list of working

groups and have been answering the question, what do I need in order to, which component

is necessary, which component is required to train, to study, or to run a system or

modify and share it? And a summary, very quick high-level view,

is what are required are the training and evaluation and testing code, there is a requirement

for inference code, model architecture, model parameters, and supporting libraries and tools.

That looks like there's pretty good consensus. And then a few other things are on the likely

required, maybe required, are data pre-processing code, data sets, and usage documentation.

And then on the right-hand side, you see what's likely not to be required.

We have asked the group to vote for each component. We compiled the votes into one document that

I will show, and we split the results. This is an example of the table that the working

group has been using as a reference. They've been filling in their initials in the cells.

For each row, there is the component, and on the column side, there is yes or no. Is

it required for using? Is it required to study, et cetera?

Then we compiled, we're compiling the exercises. It's going to be done today, completed today.

We're compiling this spreadsheet with the sum of the votes for each of the components,

and we're going to grade it with a very simple algorithm. Basically, a yes if the median

is higher than two votes, et cetera. I mean, yes, is the median higher? It's a yes. It's

lower? It's a no. Pretty simple. This is what it's going to look like, and we're going to

share this as the exercise completes today. I'm going to summarize and make it public

next week on the forums.

So, code, we can see what's required. As I mentioned, inference code is mostly likely

on the data front. This is the interesting part. A lot of the groups are leaning on the

maybe or maybe not. Maybe not. This is an important result and something that we'll

have to spend a little bit of time debating as soon as the exercise finishes. My sense

is that this is the crucial. We knew from the beginning that the conversations around

data are crucial. Some of the live interactions that I've had with people in the working group

have been along. I've been sort of describing what the highlighting, I've been highlighting

to me the fact that definitely data is often, if not always, necessary, but the level of

access is different in the mind of the practitioners. In other words, for example, during one of

the conversations with one of the working groups, one of the questions from a volunteer

was what level of depth do we want to organize or do we want to understand the verb study?

So how deep do I want to be able to study a system? Because there is a very radical

difference between studying a system because I need to write a PhD dissertation or if I

need to study and understand it enough so that I can evaluate, for example, its transparency

according to the regulation from the AI Act or a slightly different level of understanding.

What level do I need to have if I want to only understand enough so that I can modify,

retrain, improve, fine-tune a system? That, in my mind, means diving deeper with other

conversations with some of these working groups has been highlighting how the level of access

to the original dataset is also something that we need to clarify and we have an opportunity

to clarify. How much do we need the dataset in full, like all the terabytes or petabytes

of the original dataset or in some cases, some people have argued that it's enough to

have a very good detailed description of what went into the dataset, maybe a randomized

sample of the data inside the dataset. It could be sufficient to study, to modify, etc.

This is a conversation that we'll have to dive deeper in the next iteration.

The last thing that I want to say around the data issue is that a lot of the debates are

also on the availability of data in general. Many of the practitioners that I talked to

highlighted how not having access to data in general is a problem. The uncertainties

around the regulations for text and data mining and the privacy laws and the very different

implications of the copyright issues that have been raised in the United States and

other places, they're all putting obstacles and this lack of clarity is blocking a lot

of the freedoms that we want to unblock instead.

I've been discussing with the people of the Open Future in Europe and we're starting to

think about opening another separate conversation around data governance. This is something

that might happen in the very near future where the data conversation will probably

be spun off or another parallel conversation will start to talk about the availability

of data.

Moving on for the model recommendation, no surprise here, we know that we need to have

the model architecture and the model parameters and unsure about the model metadata and model

card. This is probably because there is not a lot of clarity over what those components

actually mean because the paper from the Linux Foundation is fairly new still. The communities

need more time to digest and understand what each individual component is.

The other interesting thing is the groups have many, many people have voted yes on the

supporting libraries and tools. That's because depending on how the supporting tools are

described and the Linux Foundation has described them quite well in detail, they include in

here things like hyperparameters, search code and tokenizers that most people consider necessary

in order to interact, for example, with the system.

This is the summary. This is where we are. It's interesting to see how we got very close

to the framework from the research paper on openness in AI from this group and the group

Liesenfeld and Dingelman. This is it. We're going to be ending the vote on the working

group today. We're going to wrap it up and summarize the exercise.

One thing that is quite becoming clear is that we're really focusing on machine learning

right now. This is something that we expected when we started at the very beginning of the

process that we were actually, this definition of open source AI is very close to, I mean

very close. Right now, it's being driven by machine learning. We're going to be talking

mostly about this. I'm not sure exactly how we're going to be dealing with this slight

change, but it may be necessary to clarify this in the definitional documents. I still

don't know exactly how to deal with this. Because there was a conversation months ago

and so many people have argued that what we want to have is a definition for AI in general

and not machine learning specifically. This is something that will be brought up again

and we'll have that conversation. Then there is one highlight that there is an interesting

question from the forum, very thought provoking from Richard Fontana. He's been driving the

conversation around whether we need a definition that refers to open source, I mean to AI systems

and not to its individual components. He makes a very compelling argument and I encourage

you all to check on the forum and see the debate because one of my highlighting here

is only one of the questions that Fontana raises. It is one of his latest messages.

He's talking about whether the terminology may have the effect of narrowing or interacting

in weird ways with the open source definition, the one that refers to software. My current

line of thinking is that the definition of AI system is something that we have to introduce

at the beginning because the conversation that we were having was going around in circles

because we were talking about things like, "Oh, but what do I need to exercise the freedom

to use a model?" People were thinking about data, were thinking about our components.

It was really not clear. There was no clarity in there. As soon as we introduced the concept

of AI system, then everything started to drive and to be more aligned. Now that we got into

the deeper parts of the debate, we're starting to get a much clearer understanding of what

is necessary to use and to study and run and what kind of components we're talking about.

This is being formalized by the industry groups inside the Linux Foundation. There are other

groups that are working in a similar fashion on listed components for machine learning

systems. It's becoming more clear, that whole aspect. I'm not too married to any of these

ideas. I do want to clarify and answer the question to Fontana.

I believe that every single component  now that we have identified every single component,

each of the components will have its own terms of use and terms of services. Some are going

to be software code and those will be distributed and will be available with licenses like any

other piece of software that we are very used to. Other components like model parameters,

etc., they will be covered by other law and other legal frameworks. I don't think that

there is going to be much of an interaction between the open source AI definition and

the open source software definition. There's going to be interaction, but there's going

to be a clear separation between one and the other. I don't think that there's going to

be any complication in here. We'll have the list of components and we'll have the legal

frameworks understood for each of the components. We will have a way to read and interpret each

of the individual components' legal documents that go with them. We'll be able to generally

understand the freedoms that we must have for each of the components.

One thing that is interesting, though, is that we also are going to generate  we

will need to have some sort of dependency graph. For example, a component that is like

the model parameters. The model parameters will have a dependency on maybe on the tokenizer

because otherwise you're not going to need it. So, model component, model parameter,

and tokenizer will have to come and be shipped together in order to be used. That's why we

need a definition for a system, in my mind. You cannot say the component itself is free

or an open source like the model itself because the model itself is not going to be usable

without this tokenizer, for example. That's where I think we're going to be heading

towards, this dependency graph and the bundles that are necessary in order to have an open

source AI. That's why we need a definition of a system because we need to have some way

of anchoring that conversation. But we may not need it and just reference to the graph.

We'll see where we end up with.

That's for the next step. Today, the final vote. Then, next week, early March, we're

going to be releasing a new version. We're still on time, in my mind, to get to June

with a release candidate. The criteria, to repeat, the release candidate will need to

have the support of at least two representatives for each of these stakeholder groups that

we have invited to the conversation. Version 1 will have to be supported and endorsed by

at least double as such or at least five representatives for each stakeholder group. We will be announcing

it in late October. That's the deadline.

Between the release candidate and version 1, we're planning a worldwide tour to show

the release candidate and host small workshops to iterate with other stakeholders around

the world. We're fundraising for this. Stay tuned and we'll show details probably next

week or the week after.

I think we're getting much closer to have a full list of stakeholders yet. It's always

good if you have friends or contacts that you think should be involved and should be

following this. Mostly, we're looking for end users and subject category and in some

ways also regulators, although not necessarily government employees or policy makers because

they're not going to be able to freely give feedback. But organizations that work very

closely like lobbying organizations that work very closely with policy makers, they'd be

very useful to have a read into the definition as it's being drafted so that they can help

us understand what the regulators are concerned about.

We create a definition or we come up with a definition that is not illegal out of the

gate. Let's put it that way. Either illegal or impossible to implement in many parts of

the world because it clashes with regulation.

And a reminder that we'll probably have to keep an eye on the evolution of the world

and keep an eye on the definition that we come up with so that we can adapt it in case

there are changes in the technological landscape that will force us to create either another

checklist separate. Like if we're now focusing on machine learning, maybe there's going to

be some new technology or some variation of machine learning that we require to review

the list of components. And at that point, we will have to adjust or add a new checklist

to the bottom of our definition of AI. So we will need to keep on working.

And with that, my encouragement for you is to join the conversation in the forum. We're

making an effort to start publishing weekly also a summary of the forums on our blog to

make sure that everyone has an opportunity to stay on top even though their inboxes get

full. And a reminder to everyone that on opensource.org/deepdive, you will find a link to the drafts and the

drafts themselves are  you can comment on them directly.

So with that, I'm open to opening the floor for questions and answers from you. I can

bring up your mic so you can speak up or you can type it however you want to talk.

I believe Isabel is writing a question. Let's wait for that.

In the meantime, it's very good that we're seeing these types of discussions. And I find

it particularly interesting that we're actually discussing what's the meaning of each one

of those verbs, right? What's use, what's study, what's modify, and what's share? I

see a lot of discussions there in the forum around those verbs. And in particular for

study, it really does depend on how deep it's study, what's the meaning of study. And I

was looking back here at the free software definition and I'm just going to read through

this, the freedom, what, right? So the freedom to study how the problem works and change

it so it does not  it does your computing as you wish.

So it's clear here that the idea behind this is just study how the problem works and to

modify. If you really want something deep, like to study to really understand that, it

becomes clear that you need more than just access to the code. You have to have a lot

of documentation to understand the idea behind that. And the same applies to data. You have

to have not just the data should be open, but also how the data was created. How was

it filtered? So in a way, it becomes impractical. And the open source definition and open source

software has always been pragmatic, right? That's one of the key ideas behind open source

definition. And so having a study so deep like that, perhaps it might become impractical

to actually apply that. So that's what I wanted to share here.

Yeah, that's a good point. I've been rereading the classic documents myself and realizing

that that's the spirit. It's very, very practical. The freedom to study, all the descriptions

inside the Kino Manifesto, the benefits are for scientific progress. And it talks about

the schools will not have to waste too much in order to acquire software and for teaching

and let the students understand what's happening. So there are multiple facets that are useful

to go back and read.

All right. So if there are no more questions...

Isabel.

Okay, go ahead.

Yeah, so Isabel doesn't have a question, but she actually shared exactly those discussions

around the verbs use and share. And thank you, Isabel, for sharing that.

Wonderful. Yes, thank you. So today we're going to start with publishing a forum wrap-up

on our blog. And we're going to be publishing the recording as usual and the slide deck

for this town hall. All right, everyone, thank you for joining. And we'll see you in two weeks

at a later time. So that is compatible, more compatible with the United States and West

Coast in general. And we'll keep on hammering on this. We'll have a new definition, new draft

at the next meeting. Thank you.

Yeah, let's go with it.

All right.

Okay, welcome everyone.

So you are attending the online public town hall for the open source AI definition on

March 8th, 2024.

My name is Mare Joyce.

My pronouns are she and her, and I'm the process facilitator for creating this definition as

a multi-stakeholder co-design process.

Okay, so these are community agreements.

Some of you have already seen them.

I'll go over them briefly.

So one mic, one speaker, allowing one person to speak at a time, no interrupting.

Take space, make space if you tend to speak up.

Allow space for others to speak.

If you tend not to speak, we do invite you to share.

Kindness, just remembering that the work is hard, but we don't have to be, and to just

be gentle with each other and curious.

And of course, hate speech and insults are not permitted in the spaces that we host.

Forward motion just means that we focus on what's possible and that we note obstacles

and then we route around them and move forward and come back when needed, but that we don't

let complexity stop our project from moving forward.

Solution seeking is connected to that.

So we just, we know that suggesting new ideas and options is vulnerable, but it is crucial.

And this is how we resolve those complexities that we just mentioned.

And are there any other norms that you would like to see in this meeting?

If you have any, you can type them in the chat.

I also realized that there's a transparency norm that we should add here, just to say

that this will be posted publicly, this video will be posted publicly.

Okay.

Looks like we don't have any other comments.

I will continue.

So yes, our objective for 2024 is to release version 1.0 of the open source AI definition.

And this is what the definition looks like.

We define AI system.

There is a preamble that basically makes an argument for why this definition is necessary.

There are certain out of scope issues.

The URL is up at the top.

If you'd like to see the document.

And there are the four freedoms, which I will go into in greater detail.

And then there's this license checklist, which is looking at specifically which components

of an AI system must be open in order for the system to be called open according to

this definition.

These are the freedoms.

These were coming from earlier documents in the open source movement, but were verified

and drafted specifically for this purpose by co-design workshops at the end of 2023.

So using the system for any purpose without having to ask for permission, studying how

the system works and inspecting its components, modifying the system to change its recommendations

and predictions and to adapt it to your needs and sharing the system with or without modification

for any purpose are the overarching requirements of an open source AI system.

And now what we're going to talk about is the most recent work we've been doing, which

is recommendations of working groups that have been looking at AI systems to develop

this list of required components.

So this is what we're up to with systems review, which is also called track one of our project.

We're not going too deeply into different tracks, but for those of you who have that

context, this is track one of three.

So what we have completed is that we analyzed a sample of AI systems to identify precisely

required components for study, use, modification and sharing.

And what we are going to do next is for each component of these systems, check their availability

and the conditions for use and distribution.

So legal documents and licenses, because that is the mechanism by which OSI verifies a piece

of technology is open source or not is through licenses and legal documents.

Then we will generalize the findings and complete a checklist for OSI license committee, get

endorsement from major stakeholders.

And that will be called that's release candidate one, which will proceed version 1.0, which

of course we will refine and rough dates are RC1 is June and then version 1.0 is October.

And anything to add to the slide, Stefano?

No, this to me looks complete.

It's more about if anyone has any comments so far, I mean, you can use the chat and keep

on adding comments.

Yeah.

Okay.

Sounds good.

Okay.

So these are the four systems that we developed work groups around and this is why we chose

them.

We wanted to have a diversity of approaches.

So we looked at Pythia, an open science project with a permissive license, Bloom, another

open science project with lots of details with release, but with a restrictive license.

And I'm sure all these descriptions could be, might be different for different people,

but this is how we were looking at the systems.

Lama2, obviously a commercial project with a restrictive license, OpenCV, an open source

project with ML components, but let's have generative AI.

And so these were the work group members having public membership as part of the transparency

commitment we have just so that you know, who are the people that are making these recommendations?

Cause these are particularly empowered stakeholders in determining what the components of the

definition will be.

And we did additional outreach to have a better, particularly racial and geographic representation.

So you can take a look at that later, I guess.

We do have posted on the forum, all these, this information as well.

And what the, what the members of the working groups did, this might be information that

some of you have already heard, but I'll go through it for those who are new, is that

they voted on, we took a list of components from a forthcoming paper.

Can we, can we name the paper yet Stefano?

Cause it is forthcoming.

We can name it.

Yes.

Okay.

Excellent.

Okay.

So it's called the Model Openness Framework.

It's being, it was written primarily by researchers connected to the Linux Foundation, although

with other collaborators as well, it's going to be released on ArchiveX, I think imminently,

maybe even today or tomorrow.

Anyway, they came up with this really nice generalized list of AI system components.

And so we use their list and then we created this voting system.

Do you think this component is necessary to use, study, modify, share, and then members

of the working groups with their initials.

So again, there's transparency who's saying that what is required voted.

And this is just a screenshot of a slide from the LAMA working group.

And yeah, if you have any questions, just put them in the chat.

And if I don't see them, Stefano will see them.

And then we compiled all the votes across all the working groups.

And I developed a rubric for basically picking a vote total and turning it into a recommendation

for a requirement.

And I think, do I have a zoom in on that?

I do not have a zoom in on that.

So if you look at the upper, I don't know which corner it is, upper left or right, but

you see this part of the slide, for me, it's the upper right, which says legend.

And it's basically based on the mean number of votes, something that was more than two

times the mean was an automatic yes, this is required on down to likely yes, maybe lean

no and then no for less than, okay, between I think 0.5 and zero or zero less than 0.5

and zero.

Yeah.

So you can kind of see through this color coding how each component ranked, you can

see there's a few here that are yeses, like training validation and testing code and inference

code.

And then many lean no's, for example, data set.

And then we looked at multiple different data sets.

So that was different from the model openness framework.

They just had data set, but we thought that's such an important part of the system that

we broke it out into multiple different types of data set to really get as much input as

possible on whether that should be required.

And then this is the result of the voting of that applying the rubric to the votes was

that the required elements were and are training validation and testing code, inference code,

model architecture, model parameters, which includes weights, supporting libraries and

tools which includes things like tokenizers and hyperparameter search if used.

And then down through a likely required data processing code, maybe the data sets as you

saw not likely elements like the model card, not required data card, sample model, technical

report.

And then what is new from I think some of you have been in previous meetings is that

we have for version 6.0 made this distinction.

So the required components, we took everything that was required plus likely required.

So the data pre-processing code and those are the required components.

And then everything else is optional.

So there's nothing that we're saying don't include this, but everything else is listed

as appreciated, but not required.

And I think let's see what's next.

I feel like this might be a good place to pause.

Maybe we do this.

Do you want to pause here for questions, Stefano, or do you want to go into this greater detail

about version 6.0 and then pause?

Yeah, let's wait and see if anyone has any questions so far.

We can definitely take a break.

Yeah.

So any kind of questions or thoughts on how we got here and where we are?

Okay.

Thank you.

I'm muted basically, everyone.

If anyone wants to jump, they can use voice or if you feel more comfortable, you can type.

Yeah.

And there's a raise hand function at the bottom like in Zoom as well.

Yep.

I don't see many questions.

Maybe we can just...

Obastium has a question.

Go ahead.

Yeah.

Hi.

Thanks for the summary.

I was just wondering if you had any priority in each column, like is data processing code

more important than training validation?

I guess on the left, everything is at the same level, but maybe on the right, some things

are more optional than others or is it something that has not been discussed?

Hasn't been discussed, frankly.

And yes, they're all required.

It's a yes or no.

Yeah, it's a yes or no.

Yeah, we can have a conversation about that.

Yeah.

Because...

Oh, let me just before those double questions, let me get another question from the next

person, Bastien, and come back to you.

Unless...

Is that okay?

Sure.

No problem.

Yes.

Okay.

Thanks.

All right.

Jacob?

Yeah.

You guys can hear me, right?

Correct.

Yep.

Okay, cool.

Yeah, sure.

So I guess one question I had is if some of the reasoning around decisions that were made

within these groups is available.

I'd just be curious, particularly on the datasets portion.

I guess my intuition is that if something is open source, we should be able to verify

its legality completely.

And without access to the datasets or in some way, then that may be a lot more difficult.

I'm not saying complete access to the datasets.

But some access may be worthwhile.

Go ahead, Stef.

Yeah.

I can give an argument.

So the question of legality may not be appropriate for the open source definition.

It's a separate conversation.

But I do believe, and there were conversations inside the group about that understanding

of the datasets.

And in fact, one of the reasons why you see there the required components, the data pre-processing

code is that many of the groups had debated about which of the -- what's necessary, what

level of understanding do you need to have in order to be able to feel safe about using

a model or have enough information, the transparency requirements that look like they're going

to be mandated by law anyway, at least in Europe, and other information about provenance

and assessing risk in deployments, bias calculation, and all of those things.

So the conversation went -- this is the -- it's the torn issue, access to the datasets, what

is necessary, what is required, what level of depth do you need to have access to it.

And it's something that we're probably going to keep continuing debating.

What seemed clear to me is that the original dataset, having access to it completely and

fully in a way that you can download it, et cetera, and retrain with the purpose of retraining

or rebuilding from scratch a model that you have received, it's a requirement that is

not strictly necessary.

At least there was pretty much -- pretty good agreement on that front.

>> Thank you.

And I see you have a raised hand again, Jacob.

I'm just going to go to another question, and we can come back to you.

So Shala asks -- yeah, exactly.

No, thank you.

So Shala asks, did any of the systems reviewed meet the required components?

So let me go back to the -- yeah.

So it wasn't that we were trying to evaluate whether any system had all of its components

required.

It was more of a comparison.

And no, there was no system where all the components were considered to be required.

But the ones that are required are simply the ones on this list under the lime green

required title.

And those are the ones that then we moved into this binary distinction of required and

not, which will appear in definition 0.0.6.

And feel free to raise your hand or ask a follow-up question in case I didn't ask.

Okay.

Bastien needs to go.

Okay.

Thank you for coming, Bastien.

I see -- Jacob, did you want to ask another question?

>> I want to complete the answer.

I want to add something else for Shala.

This analysis, this -- you know, the response also will come after the next phase.

We're going to be reviewing the systems and see if they have available the required components

and what conditions they're available.

What can we do with those components?

>> Okay.

Yeah, I see what you're asking, Shala.

Thank you for clarifying that, Stefano.

I see Justin is typing.

But Jacob already has his hand up.

So yes, ask your question, Jacob.

>> I should have written it down.

I apologize.

I had a thought.

It's gone now.

I'll bring it up if I remember it.

>> No problem.

No problem.

I'm going to -- let's move on to the next slide.

Because that one adds this extra information about requirements around the training method.

And then we can continue to take questions.

What do you think, Stefano?

So I think this is where you will start presenting, I think.

>> I was looking at the -- we can answer Justin.

>> Okay.

Let's do that.

>> He admitted -- no, no.

He admitted that it's outside of this.

>> Okay.

Great.

>> So this is the text that is now in the draft of -- in the draft version 6.

006.

Which is going to go live on Monday.

So it's basically completed.

And the narrative in here is to have a piece of text inside the definition of that section

of what is open source AI.

Where we describe what we actually need in order to exercise those four freedoms.

To use study, share, modify.

And that's where the text that I was talking about before, the sufficiently detailed information

of how the system was trained, and the components basically that the groups have said that they

require.

Here they are described in a more verbose way, more of a narrative rather than bullet

points talking about quoting, mentioning specifically components that are referenced in a separate

paper by -- or maintained by another organization.

So this is more about describing in a more -- in a fairly precise fashion the list of

components that require components that came out of the working group.

And here you can see, like, you need to have detailed information of how the system was

trained.

Providence of the data, the scope and characteristics.

Some of these wording also comes from the EU AI Act in terms of requirements of transparency.

So I tried to use the words included in that legislation so that thinking that it's sufficiently

-- it's been reviewed.

It's been debated.

It's been agreed upon by the -- at least by the European regulators.

And negotiated heavily.

So I'm assuming it's quite fine-tuned to represent transparency requirements in a fairly

detailed way.

So at least it's a good way to start the conversation for us.

And then in terms of code, pieces that are about the preprocessing data, the code used

for the training validation, and the supporting libraries.

And the model parameters, the weights, which should also include the checkpoints for the

intermediate stages of the training.

As well as the finalized one.

So this is what's in -- you will see on Monday on draft six as it gets published.

You want to go on to the next one?

Because this is the other thing that will be clear.

Spelled out.

Like the precondition that we need to focus on, like a very, very high-level necessary

thing, necessary feature that needs to be made available is to have the preferred form

to make modifications to the system.

And that, for machine learning, the examples that we have studied, they give us the list

of components.

This sentence here is a form to make the open source AI definition a little bit more flexible

and adaptable to other technologies should they change next year or two years from now.

At least in the short term.

Give us a little bit more flexibility.

And that's what we're going to do.

So the next step is -- the very immediate next step is to finalize the -- hit the release

button and go live with version six of the draft on Monday.

And then we're going to start the second step in track one, which is to review each of the

systems that we have already analyzed.

Maybe add some more.

I'm not against adding more at this stage.

Because we need to look at the required components that we think are necessary.

The working groups have identified as necessary.

Make a list.

And for each of the components, put the URLs, you know, where can I get them?

Where can I get it?

If it's not available, then mark it as unavailable.

And if we can get them, under what conditions?

So we're going to find out -- I can already say we know.

For Lama 2, we know that in order to download the model weights, you will have to -- you

will have to sign up on a website.

You need to give in your details.

You need to ask for permission.

And you need to sign an agreement by doing so.

And that agreement has specifications of what you can and cannot do.

And we'll log all of that information in a place.

And we'll analyze them in step three.

PTR will have different things, et cetera, et cetera.

Oh, in fact, yes.

I put together -- there is a slide with -- go ahead.

Go to the next one.

Yes.

That's the -- that's what the next table, the next working groups will do.

It's basically go through the list of required components, put the URL, and match the legal

framework.

Now, you will see that here we're talking mostly about code.

And there is one line.

So for the code parts, it's going to be easy to say that all the code made available needs

to be formally using an OSI-approved license.

And I don't think it's going to be that complicated, that part.

The model parameters instead.

That part is most likely going to raise a conversation around what legal frameworks

go around the parameters.

Those are -- there is still some, from what I hear from the legal communities, the lawyers

have diverging opinions whether parameters are copyrightable.

And if they're not copyrightable, what kind of other -- if there is any other exclusive

in property regimes or not.

And therefore, what kind of contracts -- the validity of the contracts or terms of use

and other legal tools.

Whether -- you know, which ones are better or valid, et cetera.

So it's going to spin off an interesting legal conversation.

>> Sorry.

I clicked early.

I didn't want to raise my hand before you were done.

>> No, you're good.

Go.

>> Okay.

So the first question I have, which is what I meant to ask earlier, was what constitutes

data preprocessing versus a new dataset?

Like is it -- if it's done internally to the company that is making the model, that's when

it's data preprocessing?

Or -- yeah, I guess basically how are we differentiating between those?

>> No, let me look at the paper.

The paper, it will go live later today.

And definitely on Monday.

But my memory serves me right.

The data preprocessing is the tooling that is used to do things like cleaning up, formatting

the data, and tokenizing, you know, doing the -- all the preparation work that goes

into prepare the data to be fed into -- for data ingestion, for example.

>> Right.

>> Feature engineering, you know, data, yeah, all of that code.

>> Right.

Oh, I guess there's a follow-up.

But I'll pause if you want to go to someone else.

>> What do you mean?

There's overlap?

>> Sorry, Mer, I couldn't hear you.

>> Yeah, you can -- yeah, let's -- yeah, good facilitation practice.

Let me go to Mo and then we can come back to this.

Mo says model architecture is defined in the code.

It overlaps with the training and validation and testing code.

Is model architecture really an independent component that can be analyzed individually?

Do you want to -- >> Once we can -- yeah, I think that once

we can point at the paper that so far we've been using generously through pre-preview,

we can have a better understanding of these technical overlaps, et cetera.

>> Yeah, the delineation between different components.

So yeah, part of this paper is that there's often multi-paragraph definitions of each

of these components.

So yeah, I think that's the best place to go for that.

Jacob, did you want to ask a follow-up?

>> Yeah.

So I guess then at least how I'm thinking about this data pre-processing and I will

be like be open -- I'm coming at this from an adversarial perspective intentionally because

I feel like that will be done, I guess.

And so basically my thought is if we don't have to know -- like if a third party can

do the pre-processing, not in terms of tokenization necessarily, but more of like sifting the

data and can create a new dataset that is proprietary and then you use that, that's

a way to obfuscate your data usage.

And so maybe that's not relevant here.

Maybe that goes too much into legality, but that's just sort of how I'm thinking about

it and I'm curious to hear what your response is.

>> It seems like it's covered by the first bullet.

Isn't a lot of that concern covered by the first bullet?

There's just so much documentation about data that's required?

Or what do you think, Stefano?

>> If I understand correctly, the question or the concern, it's about replicating the

dataset with different setups, different things in it.

Or different way of reorganizing, reshuffling the same -- using the pre-processing code

means that you have a way to rebuild -- it doesn't mean that you have access to the original

data.

You can -- you have a way to extrapolate, you have those transparency requirements that

make you -- that give you some sort of better understanding for how you would have to build

your own dataset for your own training if you want to do -- if you want to rebuild from

scratch or if you want to build from -- not rebuild from scratch, build from scratch something

else that looks or behaves similar to what you have received.

In other words, I don't think that the scenario that you're describing is a scenario that

necessarily is part of this conversation.

>> Gotcha.

Okay.

Let's go on and see what else comes up.

>> Yeah, because I think some of these questions can be -- yeah, can be described also in what

we're doing.

Another thing -- another of the things that we're doing next and partially I can talk

about here the roadshow that now it's not detailed here, but you can see on the timeline

we have these three tracks, the green, the white, and the light blue that we're following

in parallel.

And in June we're going to have the release candidate.

Once that release candidate happens, we'll have meetings in different parts of the world

and we're organizing them to show the release candidate to gain more visibility across different

communities and different practitioners, different stakeholders in order to get to release candidate

to version 1 in October.

During these meetings, we're going to spin off a conversation about data because there

is a strong requirement for good quality data sets and an increased amount of awareness

in the practice of building data sets that are valid, respectful, trustworthy, you know,

they are clean, they're transparent, they're fair in how -- what they represent, et cetera.

And there is very few of these.

There are very few data sets that are large enough, that are good enough -- that are good

in that term.

And what's becoming more clear to me also is that the data community hasn't been -- needs

to also -- to have these conversations.

So we're going to be partnering with organizations that are more into that data space and we're

going to be helping supporting conversations around data in parallel or, you know, as a

spin off of this project.

>> Jacob, go ahead.

>> Yeah, sorry.

Last one.

You touched on this just now, but I guess one thing that I've been thinking about a

lot is how do we -- or I guess OSI maybe -- take back the term?

Because I feel like it's been falsely attributed to systems that are pretty clearly not open

source by this definition.

And like you said, you're going to go and, you know, talk with more people and have those

meetings.

But, yeah, just curious what your thoughts are about that.

>> Yeah, this is a known issue, unfortunately.

Yes, exactly.

Having a definition helps to take back the term.

And having people, enough people who support it and are willing to say we're going to use

it.

This is what we mean when we say open source AI.

And they're going to be multiplying the idea.

You know, they're going to go -- so I'll tell you an anecdote.

I was in -- I was at a meeting last week with a lot of friends of open in general.

And there was a lot of pushback.

Common shared pushback against Meta's use of the open source AI name to identify, to

talk about Lama.

Lama2 specifically.

So it's -- many others will be joining in our effort to clarify the public what that

means.

And it's a little bit the same work that -- the same way that it happens with the open source

software.

Like lots of -- there is people -- some people still complain and say, well, but I mean something

else.

But there is always a very large pushback of supporters of the open source definition who

say, no, it's -- you may have all the opinions you want, but open source is defined by the

open source initiative.

And it's maintained by the open source initiative.

And that brings the cloud up.

Yeah, so that's a big thing.

This doesn't end with version 1.

We know that we will have -- most likely it's going to be -- it's going to have to be maintained

and improved and reviewed.

So the board of the OSI is already at work to think about the -- how we're going to be

maintaining -- we're going to be maintaining this definition.

Which is very different from what the open source definition for software is.

Right?

We're trying to have -- so someone was asking before I saw the meetings and -- oh, it was

Justin.

Yeah, we're talking about meetings, et cetera.

And how to participate.

So we're trying to have everything public.

So that no one gets surprised when at the end we come up with the definition.

We're having this sequence of town halls every two weeks at different times so that we can

accommodate multiple time zones.

We have discussions on the forums.

We do publish on the blog every week a summary of what's happening on the forums.

So there are multiple ways to get involved.

To stay aware and to give comments during this process.

We'll publish the roadshow.

Also the roadshow meetings are going to be in different parts of the world.

We have partnered with existing conferences.

In order to gather people who are already being at a place.

Already going to that place.

So we're going to be in -- at the -- well, we'll publish it next week.

Or the week after.

But I can say that we're going to touch every continent starting from June.

Starting from June until October.

So we're going to be in Africa in June.

We're going to be in September.

We're going to be in Hong Kong.

Europe, Paris, North America, Mexico.

I don't remember when.

So there's many, many opportunities to meet in person.

And we're raising also funds and disclosing this.

By the hope is that we're going to have also travel grants for people who want to participate.

And they can apply and get to some of these meetings.

So hopefully we'll be able to have a very good roadshow.

And gather a lot of support.

And if not, we're going to keep on going next year also.

Multiple opportunities.

>> Thank you, Sam, for offering to host us in Toronto.

Okay.

Yes.

And thank you for your comment, Jacob.

Okay.

Let's see what else we have in the deck.

Oh!

Q&A.

>> I haven't really started.

So yeah.

That's the end of our deck.

So we do have more time in the meeting.

If anyone else has a question.

And this would be a great time if you're someone who often doesn't ask a question in a meeting.

Please do.

We really invite you to.

And if you prefer to put it in the chat rather than to speak publicly, then that is also

most available to you.

>> All right.

Jacob, thank you for sharing the information.

You're welcome to join the forums if you're not already.

They're easy to use.

And should be smooth.

And once you're a you can become a free member of the OSI to join the forums.

It's very easy.

>> Yes.

I joined earlier this week.

I had some troubles with logging in.

But I got that fixed.

So...

>> Cheers.

>> Thank you, guys.

>> Thank you.

>> Bye.

>> See.

Just in typing.

But I'll wait.

But I can stop the recording at this point.

I think.

Okay.

So...

I'm going to stop the recording.

All right, everyone, welcome to this, I don't know how many we've done of this already,

public town hall to get an update on the process to define open source AI.

As you all know, this is a long and hard process.

The agreements that we have in here, I like to remind everyone, and especially I'm fond

of the fact that we're moving forward.

We must be keep going and we must reach a conclusion.

And if we find something that is blocking the conversation, we take notes, we try to

move on, we'll get back to it later.

And we want to find a solution which is really relevant for delivering something on time

and reaching agreements.

This is what we set for our objective, and I'd like to remind this.

We want to get to a workable, usable, agreed upon definition of open source AI.

This is absolutely the goal and objective.

And I got to say that I'm getting more comfortable that we're reaching a conclusion.

And in fact, in...

Okay, got a wrong slide here.

Okay.

And my system is really slow.

Okay.

So here's the status on the structure of the definition, which many of you have already

seen.

It's made of a definition of AI system at the beginning, the preamble where we set the

rules, we set the principles, actually, the principles that we want and why we want to

have a definition, what value and what advantages we think that's going to bring to the world

or to the ecosystem in general.

We also set clear out of scope, and so the boundaries of what's in scope for a definition,

what's left out.

And finally, the four freedoms, which are the basic understanding, the most succinct

way of communicating what is an open source AI.

And below that, we're going to be...

We're working on defining the legal terms, and we'll talk about the draft six, which

was released at the beginning of the month.

And I think it is going to give us a clear understanding.

So what I want to say here is that it looks like very few comments are coming in on the

top parts of the document, like the draft, preamble, out of scope, AI system definition,

and for freedom seem to be fairly set, especially the first three.

The fourth, maybe some small details, but it looks like these parts of the document

look done.

I really encourage you all to reread also the top part.

Don't get fixated on what's working on.

The more...

I'd love to get a sense of what's happening, and if really we can consider the top parts

complete, and if they're going to be...

So that we avoid having surprises at the last minute.

Now on the legal check terms, I mean, legal terms, the checklist, let's talk about what's

in draft six, which is very, very new.

The four freedoms haven't been changed at all.

What's added in draft zero six is the statement of the precondition.

What is that you need to exercise the freedom?

What is the fact, the statement that you need access to the preferred form to make modifications

to the system?

This is a sentence that is quite well understood in the realm of software.

We know because of practice, because it's been defined in various licenses, that access

to the preferred form to make modifications to a program, software program, you need to

have access not only to the source code, but also documentation on how to rebuild it, and

the tools and scripts to build.

So you need to have the compilation, for example, the make files and other pieces.

The GPLD3, for example, has a very detailed list of what's necessary to make modifications

to the program.

Now for machine learning systems, and we focus on machine learning here because as an example

of what an AI system needs in order to have the preferred form to make modifications,

you need three things.

Well, three sets of things, three categories of things.

Let's start from the bottom.

On the model front, we need model parameters, including the weights.

And maybe in some cases, we may need checkpoints for the stages of training.

And that's for the model requirement.

Then there is software that we need.

And the software that we need is software used for pre-processing the data, the software

used for training, validation, testing, and supporting libraries for the execution, like

the tokenizers, the search code, if there are the hyperparameter search code, if there

is one.

Then we need to know how to run inference on it.

And we need to have the model architecture, which is also a piece of code, usually.

Now at the top, data, and I have highlighted it, is the sufficient detailed information

of how the system was trained.

So this is not access, being able to download the full dataset as it was used for training.

But it's enough information to understand what went, from the transparency perspective,

what went into building that dataset, how it's been trained, how it's been collected,

who collected it, the procedures for labeling, if there was any reinforcement training, human

feedback, non-human feedback, rags, what have you, all of the methodologies that went into

building that dataset.

So this is something that many people have highlighted as still an area of contention.

And I'm fully aware of the fact that data is the most controversial part of the open

source of AI in general, and open source AI specifically, even more, because there are

so many open questions.

Now this is one of the boulders that I have highlighted at the beginning.

We know that this is an issue, but we've been going around for over a year, and we can't

figure it out.

So let's move on.

Let's finish this investigation phase.

Let's get to a complete draft using these assumptions, that we don't need access to

the full dataset, and see what happens.

See what we end up with.

Once we go back, we can revisit this decision, if it really looks like we have reached a

wrong or counterintuitive or counterproductive, or maybe it's decent and good enough that

we can work with it.

Now the data transparency requirements, this is something that we will need to elaborate

on in this new phase.

But let's see, because the wording that I've used in this draft are mostly taken from the

draft of the EU, European Union's AI Act, which, and these requirements have been already

criticized for not being clear enough, or not being extensive enough.

So I'm going to be on the data front.

We are going to be working closely with Creative Commons and Open Future, rather, to elaborate

a little bit more, to understand more the issue of data, and the issue of data governance,

as this is a sophisticated and complicated topic.

And all right, so phase two, which has started, is to look at the AI systems that we have

investigated in the phase one, which are Bloom, Lama2, Pythia, OpenCV.

And I'm open to add more, but the reason for this phase is to go through the list of required

components, the ones that in the draft 06 are required to exercise the four freedoms,

find them, find the preprocessing code for Lama2, preprocessing code for Pythia, training

and validation code for OpenCV, inference code, what do we use for inference on Bloom,

and find it, check the conditions under which they're made available, which I am not calling

them licenses, because in some cases, these are not copyright, especially model parameters.

It's not clear whether they're copyrighted or not.

So licenses for everything that is code, licenses for everything that there is documentation,

but we need to find all these resources and see how they are distributed, under which

legal frameworks and legal documentation, legal contracts or terms of use, what have

you.

We need to find them, we need to document them, because once we've completed this for

at least the four systems that I have highlighted, then we're going to go into looking at the

legal documents and write analysis, legal analysis on these.

So we're going to look at the Lama license, or the Lama terms of use, the Bloom rail frameworks

for distribution, use, etc. of Bloom, etc.

We're going to look at the Apache 2 license that is used by OpenCV, if I remember correctly,

in some of the pieces of OpenCV, and see how the language of the Apache license matches

the intention and how compatible it is with the digital artifact, the model weights, the

model parameters, etc.

That will give us the...

Once we finish this, and I'm hoping, aiming to finish this towards the end of May, we

should have the complete, we should reach a complete, feature complete list of elements

for a knowledge, have enough knowledge to be able to say, "Okay, this is what we think

open source AI looks like."

It needs to come with these components, the components need to be made available with

these, need to give out these freedoms, they need to allow these things.

And most likely, it's going to be a checklist, very similar.

Well, we'll see what...

The principles are going to be very similar to what we have in the open source definition

now, most likely.

So those are the steps that we have in mind.

And in terms of timeline, I think that we are still on time.

I still think that we're going to be able to have a meeting in June.

We're still discussing at this point, we're getting a little bit too close to June to

have an in-person meeting, but I have started to think that we might have, in order to...

We might have a virtual meeting, but hold on, we're still...

There are a lot of opportunities, a lot of trips that we can take.

We may have, instead of a one big meeting, we may have multiple ones at different times

around the time of June, because there are so many events where we're really committed

to go to, and we're going to be meeting many of the stakeholders at these events in Paris,

at PyCon in Pittsburgh.

And there's a meeting in Africa also at the beginning of June.

So we might be able to distribute this stakeholder meeting and the issue of a release candidate

around the month of June, rather than one big event.

But in any case, October is still the release of version one, stable version, whatever we're

going to call it.

And we'll add all things open.

So keep that in mind.

And yeah, these are the dates that I mentioned we already have in mind, committed.

So we're thinking about this roadshow, once we have a release candidate feature complete

definition.

The idea is to go through to these events and show the other meetings in this, but these

are the main ones, the top ones with the organizers.

We're partnering with the organizers so that we can have maximum exposure and we can use

the feedback between June, late May to October.

And of course, you're more than welcome to continue to come online, like we're being

super transparent.

We have these working that are set up to do the analysis, the early drafts of the analysis,

and then publish them on the forums where we are hoping to get more comments and feed

into the machine.

So no one is really surprised at the end when the definition is announced.

Easy to use as forums powered by open source discourse.

So fun and also mobile friendly.

All right.

With that, I'm happy to get any questions if there is any.

And if not, we can continue the conversation online.

All right.

I almost forgot.

All right.

Welcome, everyone.

This is our public town hall where we explain the status, where we are, and highlight the -- what happened in the past two weeks, and we talk about what's coming in the next near future.

So today Mer is going to lead the presentation.

So Mer, it's up to you.

>> Okay.

Thank you.

So I think you all know me.

I'm the process facilitator for co-designing the open source AI definition.

And I think you all have seen this, just that we have some community agreements that we use at all meetings.

One mic, one speaker is about not interrupting.

Take space, make space just says if you tend to be more quiet, we invite you to speak up.

And if you tend to speak up more easily, to give space for others to speak as well.

Kindness just reminding us to be gentle with each other because this is quite hard, but we don't have to be.

Forward motion is acknowledging that there's so many challenges and obstacles to this work.

And just that we can choose for those to stop the process.

But rather instead that if we hit a boulder, we note it and we walk around it and come back in the future as needed.

And solution seeking is similar.

It's just that it's easier to say, oh, this doesn't work, that won't work.

And it's more challenging and vulnerable to say, hey, how about this?

Could we do it this way?

But that we need that kind of, I guess, intellectual energy to make this definition a good one.

So, yeah, so this is a slide probably anyone who's been to one of these has seen before.

We're creating the version 1.0 of the open source AI definition this year.

And this is where we are now.

And these are the parts of the definition.

Defining an AI system, a preamble about the need for the definition, issues that are out of scope, definitions of the four freedoms, studies, modify and share.

And that was the first part of our co-design process at the end of last year was co-designing the specific words that we're using to define those concepts.

And that will be shared later in the presentation in case you need a refresher.

And what we're doing now is we're working on a draft of the checklist.

So what are the required components for an AI system to be considered open by according to OSI?

And that summarizes what I've just told you.

We're pretty much finished with the rest of it.

And we're working on a draft of the checklist.

I guess also if you have questions, you can share them in the chat.

And I may or may not see them, but Stefano and Nick are there to do so.

So, yeah, so this is version 0.0.6, which is the current version of the definition.

And you can see at the top the terms, use, study, modify, share, and how we're defining those.

That's not new for this version, but it's important content.

And the thing that was new with this version is that there was a lot of question, as you can all imagine,

about requiring data and what has come out.

And this version, and I'll talk about our process, is that we have transparency requirements only.

So data sets themselves are not required, but we have transparency requirements in the form of documentation requirements.

And I'll go into that.

So this is going into our process, how we've been co-designing the definition.

We've been doing it through these system review workgroups primarily.

And right now the workgroups are still active, and they're creating content for version 7 of 0.0.7,

which will be released next Friday.

And then this is a reminder of what the workgroups, the focus of them.

They're focusing on different AI systems that have varying approaches to openness, to the concept of openness.

So we have Pythia, Bloom, Lama2, and OpenCV.

And these are the members of those groups.

Part of being a member of the group is that you agree to have your name and affiliation shared publicly for the sake of the transparency of the process.

And just to also note that these groups reflected also some outreach that we did to have better global representation,

particularly of Black, Indigenous, and other people of color, women, and individuals from the global south,

because this is going to be a global standard.

So this is what we did in phase one at the beginning of the year.

In each working group, we had component voting.

So we took a list of components from the model openness framework, which is based on a paper by the Linux Foundation and others,

and we thought it was a great list of components, generalized components across multiple systems.

So we used that as our components list.

And we had members of the work groups vote with their initials as to whether they thought that each component was necessary for the system to be studied, used, modified, and shared.

So building on that foundation of the principles, which we'd already established, we used that to develop work group recommendations on whether each component should be required.

Then, in the example that was from the Lama II group, I then compiled the votes and developed a rubric that made a recommendation on the components based on the number of votes.

So we obviously could have had a system where any component that got even one vote, that would mean it was required.

We didn't do it that way.

We said, let's have a set of minimum requirements for openness.

And then the results of that, which ended up being a Likert scale, basically.

So there were components that had the most votes and would definitely be required, that might be required, then I think possibly required, unlikely to be required, not required.

And then we posted that list in the forum, that recommendations report, and then that list became version 0.0.6.

Yeah, and now this is what we're doing now. We're doing phase two, fine tuning the component list.

So we have this checklist in 0.0.6, which then I put into a slightly different format, basically adding documentation.

So documentation was listed in 0.1.6 textually.

But it wasn't in the checklist table. So I put the documentation requirements into a checklist format.

And right now the work groups are...

I hope you can't hear the pinging in the background.

My computer. Hopefully that's just me.

So now all the work groups, they have another spreadsheet they're filling out, lucky them. This is the example from Bloom.

But they're identifying what is the documentation for each of these required components.

And then is it those drop downs, those gray drop downs, I think it's allowed or

allowed, not allowed effectively.

You know, is use allowed, not allowed, studied, not allowed, not allowed, modification, sharing for each component.

And then for 0.0.7, we're also seeking to fill in these blanks, which are in red.

So what would be the legal framework for model parameters, including weights, and what would be the legal framework for all these forms of documentation.

Stefano, do you want to jump in at any, add anything?

No, you're covering all of it.

Okay, sounds good. I'll continue then.

So, yeah, so these are the document reviewers.

Again, we said if you want to be a document reviewer, you need to share your name and affiliation.

And here we wanted to be sure that there was at least one unaffiliated reviewer.

People that are affiliated are creators or advisors of the systems under review.

And they have the most technical knowledge.

And yet also have obviously their own set of preferences around how a system might be reviewed.

So we also have unaffiliated reviewers.

And we are looking good for Lama 2 Bloom and Pythia.

We don't have anyone for OpenCV. So it's possible that OpenCV simply won't be reviewed in this phase, which would be sad.

But we would love for someone to do it.

We've asked on the forum, don't have any takers yet.

But so this is a formal call.

If you would like to volunteer, chat or message me on the forum, or we would love for this review to happen.

But so far we don't have anyone to do it.

And yes, talking about representation.

So we have two ways of looking at representation.

The first way is the way that I was talking about of around identity, not specifically related to open AI.

But then the second way we have of looking at representation is relation to open source AI.

And so we have six stakeholder groups, system creator, license creator, regulator, licensee, end user and subject.

And you can see those descriptions and examples.

And right now, the people most involved in this phase are system and license creators and licensees who tend to have that ability to analyze license documents.

Other individuals are welcome.

And of course, everyone falls into six subjects.

So if you're thinking, oh, I don't fit into any other group, trust me, you fall into six subjects of AI.

So, yes, we welcome everyone to join.

And there will be as we get out of the more technical aspects of the review, it will be easier for people without that technical knowledge to participate.

Although they are invited at any point to be involved.

And then this is just, again, the way that we're ensuring global inclusion and equity with phrases like this.

You know, black, indigenous, Latina and other people of color, women, queer, transgender, non-binary people, people with disabilities, poor and working class backgrounds are encouraged to respond.

So just whenever we're sharing about our project, just saying we want you to be involved, even if you're not seeing people like yourself involved yet.

And I think that's the end of the slides.

Next steps.

Ah, yes.

So here we are in April.

We are going to be releasing Open 0.7 by next Friday.

Also next month there is a live workshop at PyCon in Pittsburgh, probably will be the 17th.

And that will be the review of -- I guess we'll be turning that into 0.0.8.

But it's basically going to be a live opportunity for people to be involved in the next version of the -- yeah.

The -- creating the definition.

And then we also have these meetings that we have planned.

And this purple line is the one that's been confirmed that we will be there.

But we are planning and hoping to be at these other events around the world this summer.

Do you want to say anything about that, Stefano?

>> Yeah.

If you go back to the previous slide, there is one thing that we want to highlight also.

That we're still targeting reaching release candidate in June.

Which means that the workshop at PyCon is going to be very crucial to -- because it's going to be probably the last draft before we go to release candidate.

It's going to be very close.

Or we're hoping to be -- to have it in shape to be close to a future complete, actually.

It should be future complete by May.

And cleaned up at a meeting in June.

We've been hoping to hold one in person.

But we're thinking at the moment, because of opportunities and because of time crunch, it might be an online meeting of a couple of hours.

So we're going to be reaching out to the crucial stakeholders that we want invited.

And you're welcome to also candidate yourself if you think you may want to join this in June.

Just reach out to both me and Mer.

We'll be looping you in.

>> Okay.

Sounds good.

So this is just a reminder that we do have this forum.

I think everyone here knows that because they probably joined this meeting based on the forum post.

But this is our main mechanism of public transparency is the forum.

Obviously not everyone can attend these town halls.

So please do join.

And that's at discuss.opensource.org.

And now we have Q&A.

So thank you.

>> Yeah, thanks, Mer.

Does anyone have any curiosity or question or ideas?

Have you reviewed the draft?

You left the comments on the draft already.

>> Yes.

Can you share the link to the draft just because I'm sharing my screen?

>> Of course.

You can comment directly on the HackMD website.

Or there are dedicated -- there is a dedicated topic on the forum that I just linked.

It's pinned at the top.

You can comment generally on the proposal, see what others have been saying already in general on the draft.

>> Yeah.

And feel free to chat or raise your hands.

Whatever you prefer.

>> There is -- so on the call for volunteers to review OpenCV, I also want to say that this is a pretty simple task.

It doesn't require specific knowledge of AI in general.

Of all the systems, I think OpenCV should have pretty much everything available under free and open source license.

It should be fairly easy to go through the list of components.

There are only eight or ten.

And try to find them basically in the OpenCV repository.

So it should be fairly easy.

And in time, it's a great way to get familiar with the process and what we're doing.

And be listed as a contributor, of course.

Because we'll be giving recognition.

>> So I may be able to jump in on this one.

I will talk to Mary next week and see if this is an option.

>> I will give you the time and the knowledge to do that.

>> That would be great.

Yeah, thanks, Ofer.

And Ricardo is just commenting, this is great.

And saying that he learned about the model openness framework recently.

Yeah, it was only just published on ArchiveX.

The model openness framework.

>> It's pretty new.

>> We only work on this for a few months.

A couple of months, maybe.

>> All right.

If there are no more questions, then I think we can close it here.

Thanks, everyone, for joining and listening in.

We'll be here back again in two weeks at a different time.

More compatible with the eastern side of the world.

But, you know, keep track of the process and keep leaving your comments.

We're going to see you soon.

>> Yeah, thanks, everyone.

Good.

Let's get started.

Thanks everyone for joining this public town hall.

I don't even remember the fifth in the series,

but there's been a while we've tried to be transparent

about the process and what's happening

and give a very quick overview

of what's been happening in the past few months

and look at the latest draft

and have a quick glance at what's coming next

because we're really approaching the last months,

actually the last weeks of the drafting process.

We really are getting close to something that is workable.

Let's start with our community agreements

to remind everyone that we are welcoming a place,

we're also trying to balance with moving forward

and finding converging towards a solution,

leaving the largest building blocking paths,

elements for something that can be fixed in the future.

And we are aiming quickly towards having a definition

for open source AI by the end of the year.

So where do we stand now?

Remember, this is a reminder of what we've been working on.

We have a preamble that sets the objective

of why we're doing this, what are the objectives,

what are the reasons why we want to have a clear definition

of open source AI, why that's necessary.

And we want to also clarify what we think needs to be fixed

and we need to be addressed the issues that AI creates

are to be resolved at a different level,

at the government level, governance level,

deployment levels, and not inside the documents

that are used to distribute and make AI systems available.

Then we have worked quite heavily to define the freedoms,

to define exactly what is open source AI in practice,

what are the identifying elements of when we see it,

we will know that that system is an open source AI.

This top part, before what we call the legal checklist,

this top part is the most important piece

and the most urgent piece that we need to get right

and we need to get it right quickly.

What follows below is the space,

is what we are reviewing and revising at this stage.

The top part looks fairly stable

and I really urge everyone to look at it,

to give it a very solid, deep read,

to see, to highlight possible mistakes,

possible areas of improvement,

because we really need to put this to bed

as quickly as possible.

And since no one has been giving a lot of comments to this

in the past couple of iterations,

I'd love to tell everyone, to remind everyone

that this is very important that we complete the process

and this top part is really, really, really the top,

the most important one.

What comes below is the,

what comes below the legal checklist is,

basically, an operation manual,

or at least recommendations and the initial recommendations

for operators of the,

for the people who would be reviewing AI systems

and evaluate whether they satisfy the definition

about what is open source AI.

And because these are strongly targeting,

this checklist is strongly targeting

machine learning systems,

because those are the systems that introduce new elements

and pose more challenges at the moment.

In the future, it may be different,

but at the moment, machine learning is what is creating

this uncertainties around what is open source,

rather than other systems.

And the main reason is because the AI systems require data

and they produce, machine learning systems require data

and they produce model weights.

And these two elements are fairly new in the software world.

And we haven't really been thinking about how they interact

with the open source definition.

This whole exercise of finding the open source AI definition

revolves around these disruption, if you want,

this disturbance in the understanding

of what open source means.

And that's what we are analyzing.

This checklist is the piece that we are using

to evaluate whether a system is open source or not,

the response to the open source definition for AI or not.

So what we've been doing, we started in the fall

and we found these principles with co-design workshops

that we run in multiple parts of the world,

like in October in Raleigh, North Carolina,

then we went to Monterey.

We went to Alisabeba with the United Nations

Digital Public Goods Alliance to run another workshop.

And the result of these conversations,

also we had conversations online,

came out, produced this Four Freedoms for AI,

which is basically the four freedom for free software,

adapted and reviewed and purposed for AI systems,

thinking about the definition of AI system.

Then we focused on understanding the required components

that one needs to have for a machine learning system

in order to exercise those freedoms.

So what do you actually need in order to have access

to these systems?

So we had, again, more workshops in person in San Jose,

and then we run virtual work groups online

to analyze four specific systems,

Lama2, Bloom, PTI, and OpenCV.

And you will see a variety of elements in here.

You see Lama2, it's a commercial project

and distributed with legal terms

that include restrictions,

and the Open Source Initiative has already called Lama2

not an open source system.

But it's relevant to have the analysis.

We looked at Bloom because it's an open science project.

It's very open in terms of it distributes

a lot of its components,

and it's very complete from the science perspective.

Also, we know that it's been shared with our license

and with legal terms that prevent some uses.

PTI is another open science project,

and it's very permissive.

And OpenCV is similarly an open source project

with lots of openness and lots of open components

made available, but it's non-generative.

So it's a computer vision, machine learning,

machine learning system.

So adding a little bit of variety.

We asked for volunteers and we reached out to volunteers

to have the most, the widest possible diversity

in different levels and different stages.

We invited experts from like the developers

and technical experts of each of these groups.

And we included others.

Like we invited Davide Testugine and Jonathan Torres

from Meta into the LAMA working group explicitly

because they are experts.

And if someone couldn't find a component,

we could ask the experts to go look for them

and to tell us whether those were available or not.

And that's the reason why they're here together with,

for example, Stella Biderman from PTI.

And we worked also, we aligned our work.

We started with the model openness framework

that is produced by Matt White, Ibrahim, Adad

and others from the Linux Foundation and other researchers

who they have analyzed machine learning

and they grouped the required, the components

that go into producing, distributing a system.

And we based on that list of components,

we asked the volunteers in the working groups

to go look and see which of these components

you think is required to study,

which one is required to use the system,

which one is required to share and modify.

And they voted for each of these components.

Then we composed and weighted all those results,

all those votes.

And we came up with a recommendation summary

of what is required and what is less necessary

or gathered less votes from the working groups.

And that has produced the latest,

no, that has produced a list of components

for which we needed to go look at the legal documents.

So we had the required components,

we grouped them into three main areas for code,

for what we call model, and then for data

because the votes didn't reach a very high threshold

for the votes of the working groups

didn't reach a very high threshold

to require the original training dataset.

And because of other practical considerations,

we substituted the information,

we built a proxy for the access,

having access to the original training dataset.

We replaced it with requirements for data transparency.

Like we wanna have the maximum amount

of transparency on the data.

And we wanna have also the tools

instead of the actual dataset,

the tools to build compatible data datasets.

So we want to have the code

that went into building that dataset as an alternative.

And now with that list of the required components,

we went and looked at the legal frameworks

for each of these components.

And we ended up with having basically everything

we discovered basically that everything,

all the required components,

they fall under copyright quite clearly

except one of the components.

So everything that is code,

so in this slide, you can see everything

that is in the pre-training, I mean, the code section,

in the data transparency section,

that's documentation basically.

And in model architecture,

those are all distributed as code

that is written by a human,

falls squarely under copyright

and maybe patent law eventually.

But it's something that we are very familiar with.

It's an environment that we understand very well.

It's an environment where we have, it's a legal framework.

These are legal frameworks for which we have licenses

and clear understanding of what those means.

But for the model parameters,

and these include, for example,

the weights and the biases.

For model parameters, we don't have a universal understanding

around the world of what these fall under,

what kind of laws they fall under.

So we have to be a bit more careful evaluating

what are the terms that we want to apply here

and how we want to have,

evaluate the legal terms

under which model parameters are distributed.

So I mentioned that we worked a lot

to get global representation in this process,

because ultimately we want,

we have engaged with,

we have identified these groups of stakeholders,

like system creator, license creators, regulators,

licensees, end users, and subject.

And we have tried to engage with as many as possible.

With the most involved ones in the current phase

have been the licensees and system creators

and license creators,

so lawyers and integrators and developers.

And we are expanding our reach now at this stage

to end users, subjects, and regulators.

And as a proxy for regulators,

we're gonna be engaging with civil society

who talks to regulators, lawmakers around the world.

And so we have closed that phase,

so we have now the next steps,

what's happening in the next steps.

We're getting ready to release the next draft, draft 08.

I'm actually at a conference this week

where I gathered a lot of feedback

and may be able to release at 08 before May,

and maybe go into Pittsburgh at the PyCon

with an even higher version number,

even more clearly towards a release candidate with a 0.1.

So skipping that level

and going into minor release numbering.

And like a feature complete,

but with close to be a release candidate in June.

Between in June, we'll hold in-person or online.

This is getting into a territory

where we'd love to have it in person,

but we also would love to have different people

from different parts of the world.

And so it's probably most likely gonna be online

instead of in-person, but we'll see what happens.

In any case, in June, we wanna have a group

of important relevant stakeholders

who have been involved into the drafting process

to meet and release the release candidate number one.

And during the summer months between July

and the end of October,

we have a plan to go through a worldwide roadshow

to demonstrate, to illustrate, to advocate for,

and gather in different parts of the world

and gather more sustained to support

and endorsement from different groups and organizations

so that at the end of the October in Raleigh

at All Things Open,

the OSI board can review the draft with the comments

and release the stable version at the end of the month.

And this is our plan.

I think we're getting very close to the finish line

and it's really exciting.

If you haven't been involved until now,

I really, really, really, really encourage you

to go to the online forums

where we have healthy, deep conversations.

Keep coming to these down-home meetings,

ask questions, and stay engaged

because we are making history right now.

We are writing a definition that we hope will remove,

that we want people to use to remove uncertainties

and doubts from the market.

People are releasing more models.

They're using the open source moniker.

They are confusing regulators

and legislators around the world.

And we need to provide certainties.

We need to provide a stable view

of what open source AI means

so that regulation can come in

and encourage innovation without causing harm,

without spreading more disinformation

and providing a positive environment.

So with that, I'm gonna take a pause.

And if you have any questions, I'm happy to respond.

Any curiosities?

- Yeah, I just have a question.

So again, you may have touched based on it,

but I was not sure it was clear.

You do not touch at all on the data used for training

except getting some form of transparency.

Do I get it right?

- Yes, that is correct.

This is a, it's really,

we started to work on a frequently asked question document

because it's becoming recurrent now

as more people are becoming aware of the process.

The data issue has been,

we have debated it at the very beginning

and it's been really confusing.

It's been really, it's been going around in circles.

Like the very big issue with data

is that if we require the original dataset

to be distributed together with the model weights

and parameters and the rest of the code,

we will automatically exclude from the pool

of possible AI systems.

We will exclude systems that don't have data

where the data is not available, right?

Like federated learning,

federated learning or privacy preserving,

training mechanisms, all of those, for example,

will not be part of the open source AI ecosystem

because there is no data.

The other reason is that many times

you have the right to download, for example,

information from a website

in order to do data mining on it,

but you don't have the right to redistribute it further.

So also in these cases,

you got a model parameters

that you can definitely use.

You have instructions to rebuild that dataset,

but you cannot really have the original dataset

because it's illegal to distribute it.

And so to obviate for these issues,

it's much easier and probably also more relevant

to have access instead as a proxy to the tooling,

to the filtering and to the instructions

on how the dataset was built as a minimum.

Again, these are default requirement.

Nothing really prevents from something like

Starcoder or other systems

that have been built with open science in mind

and have been very careful.

Like Luther AI is working on the pile

to a new dataset that is more,

since they became more concerned

about the copyright status of the input,

the training datasets,

they're rebuilding the pile,

excluding all the possible sources of lawsuits

and DMCA takedowns.

So nothing excludes from building datasets

that are relevant and important

and can be distributed further,

but that would make the open source AI,

would put the, having that as a harder requirement,

would put the open source AI at a disadvantage

compared to the commercial proprietary systems

where they basically don't even disclose

the list of the data.

Yeah.

- That makes sense.

Thanks a lot.

So that's indeed very clear.

- Absolutely.

- Thank you.

- Absolutely.

All right.

If there are no more questions,

then I will close it here.

And again, please go to the forums

and there is a long thread about data

where you can see the past conversation

on this very hot topic.

And yeah, we can continue there,

or we can also move on to the other big issue,

which is defining and understanding a little bit better,

gathering more comments on the legal status

of the model parameters and understand,

get more suggestions on how we should treat them.

Thanks everyone for joining and talk to you soon.

In two weeks, we'll redo this.

Bye.

>> Hello, everyone.

>> Hi, welcome.

>> Do you want to take it now?

>> I will.

>> It's becoming a tradition that we tag team on this one.

>> Yeah.

Teamwork.

>> So, yes, welcome to the online public town hall for the

open source AI definition for May 3rd.

We always go through our community agreements.

Those who have been here before are familiar, but just to

remember one mic, one speaker, take space, make space.

So if you ask a question, wait for others to ask before you

ask another one.

If you don't want to ask a question, pause and let others

take a chance to speak.

And if you don't usually speak in a public venue, we invite

you to say what's on your mind.

Kindness, just that we -- the work is hard, but that we be

gentle with each other.

And obviously hate speech is not permitted in this space.

Forward motion.

We start by focusing on what's possible.

And we note obstacles and come back to them, but we reroute

around them and do what is possible in the moment.

We seek solutions.

And we know that that is vulnerable, but it is crucial and

that we are all needed in this work.

And are there any other -- any other community agreements that

we have for this meeting today?

Okay.

So -- playing with my windows one moment.

Okay.

There we go.

Okay.

So, yes, as you all know, our objective for 2024 is to have a

stable version of the open source AI definition and that is

still scheduled for October.

Where are we now?

We have a couple slides that are similar to our last meeting,

but the last meeting was in a different time zone, so I'm

hoping this won't be redundant for anyone.

We are on version 0.0.8, which is feature complete.

It's our feature complete version.

So we have the preamble, the four freedoms, which have been

here for a while.

And then we now have a checklist, legal checklist for

required and optional components that has the required legal

checklist for every single component.

So that has been the new content for this version.

And very briefly, how did we get here?

I see there's chat, and I will trust Stefano and Nick to pause

me if I need to attend to that.

So we started with the four freedoms in the fall of 2023.

I know some of you are actually part of this process.

And this was study, use, modify, and share.

What should these open source principles mean for AI?

And so we had in-person co-design workshops.

We had one at All Things Open.

We had one at Linux Foundation Member Summit.

We had one at the Digital Public Goods Alliance member meeting

in Addis Ababa.

And from that, we came up with the definitions of the four

freedoms for AI.

So these are in 0.0.8.

And they should not surprise anyone, but we've now formalized

them for this technological context.

So we have use the system for any purpose without asking permission,

study the system and inspect its components, modify for any purpose,

and then also to use with or without modification, again,

for any purpose.

I actually will pause for comments at this point.

Let's see.

Yep.

Oh, I see.

Great.

So in the winter, we asked this very big question.

What components must be open in order for an AI system to be used,

studied, modified, and shared, of which there are many,

many different opinions and many, many valid opinions?

And we started doing this, again, by having in-person workshops.

We were at AI Dev in December in San Jose.

And then we got some really good feedback,

which is that working in person only is exclusionary because not

everyone can be in the room.

And so we shifted into virtual work groups in January of this year.

And we also decided to have our work groups focus on specific AI

systems self-described as open so that we could get specific in all

these different questions and debates around open-source AI.

And we're basically looking for systems that represent a diversity of

approaches to AI openness.

And we chose Wama2, Bloom, Pythia, and OpenCV.

And then we recruited members for these groups.

And we were very concerned about having global representation.

So we conducted specific outreach to Black, Indigenous,

and other people of color, particularly women and individuals

from the global South.

And part of being a member of the work group is to have your name and

affiliation shared publicly for the sake of transparency.

And over 50% of work group participants are people of color.

And you can see them here.

And, again, the deck will be available on the website.

So the first thing that the work groups did is they selected the required

components.

So we started with the model openness framework,

which was created by Matt White and colleagues at Linux Foundation.

And you can see those components from that paper on the left,

things like data pre-processing code, training code, evaluation code.

And then there's also model and data components as well that aren't shown.

And then we had work group members vote, initialed vote.

So that's a public vote of is this component required to use or study or

modify or share the system as a whole.

And then I, and this is also public,

created a Likert scale based on the number of votes per component.

And we came up with certain components that were, yes,

this definitely should be required down to no,

there really aren't many votes saying that this should be required.

And then that, that results of that Likert scale, the required, likely,

maybe, probably not, not required,

but into a public forum post for further feedback.

And that became version 0.0.6 of the definition.

So that is the first version of the definition where we actually said,

these are the components that we think should be required for something to be

open source.

And what we just finished early spring was a second activity of the work

groups,

which is to look at the legal documents for these required components and see

are the,

are there legal documents in these systems that are associated with these

components as described?

So we had the required components, which are, there's code components.

As you can see a couple of model components and then a number of data

information or in this earlier version,

data documentation components.

And then we asked volunteers to find links to the documents or licenses that

reference the rights to access and use those components.

And then to evaluate, to look through the document and say,

is use restricted or allowed is modification restricted or allowed is sharing

restricted or allowed for all these different components.

And these are the, so, and this is just a zoom in on the result,

which is 0.0.8. As you saw in the beginning, we have,

we are calling it data information now.

And so data sets are not required,

but information about training and methodologies, scope,

and characteristics provenance labeling procedures,

if used and cleaning methodology is required.

And then we have code components, data, pre-processing code,

training, validation, and testing inference and supporting libraries and

tools. And then two model components, architecture and parameters.

And you can see on the right,

the legal frameworks that we're using for each and then a longer list of

optional components.

This is basically the remainder of the model openness framework components

because obviously we want as many components as possible to be open,

but these are not required. So then, so basically all these data sets,

we say we would love if they're available,

but they are not required to for the system to be called open according to

our definition, additional code elements model.

I see for some reason, I didn't put a highlight on model,

but you can see it in there and other, which is for example,

a research paper or a technical report.

And then just again,

that it's very important that we have a representative process.

It's a global definition. And so this requires global consultation and we

have various stakeholder groups that we're,

that as part of our outreach,

particularly as we move into the next phases of the project and I can go back

to this if people are interested in it,

most involved in the current phase are system creators and licensed creators

and licensees. So people seeking to study, use, modify, and share the system.

And then to increase, I guess, identity-based diversity.

We, I'm using phrases like this one that are specifically inviting,

for example, Black, Indigenous, Latina, other people of color, women,

you can read that paragraph.

And then we also do outreach,

specific outreach to bring underrepresented groups into the process.

So next steps, spring through fall.

So now through October, basically. Right now we're doing definition validation.

So we are seeking volunteers to review. It says one to three.

This is not accurate anymore because now we've decided that we want to do about

10 systems total. So it's actually about six additional systems.

Using that same procedure as of the spreadsheet.

So finding the legal document and doing the analysis of each component,

according to these definitions of study, use, modify, and share.

And we're hoping to have that complete by the 20th.

So in about two and a half weeks.

And these are the systems that we're currently looking for to review.

And we have at least one volunteer for everything except Arctic,

Snowflake Arctic, which is a new addition.

But additional volunteers are welcome on all systems. It's a big task.

So I'm sure that Casey and Mark and Victor and Jan and Racine would love to

have a pal to share that review task with.

And you can email me if you're interested in that,

being a volunteer on any of those systems.

Again, to test the definition against the documentation available for these

systems, the legal documents and licenses.

And our timeline for the rest of the year, we did just release 0.0.8.

We may do a 0.0.9, depending on if there are changes that come back,

major changes that come back from this definition validation activity we're

currently engaged in.

We will have a virtual launch event associated with the release of RC1 in

June, and that date will be TBD.

We had been thinking of doing something in person, and then we thought

inclusion, this is a very important event.

We want as many people to be able to participate as possible.

So we decided to do virtual.

And then we will have a stable version released in October,

and that will be in person.

That will be at All Things Open in North Carolina.

And we have additional virtual and in-person meetings where we'll be

sharing and seeking feedback on, I guess, RC1, release candidate 1.

You can see where we'll be.

And some events, you can see we have the month but not the date.

So we're still working on certain details of this road show.

So, yes, we would love for you to be on the public forum discussed at

opensource.org, and I think that's the QR code.

We'll take you to that site, which you can join for free or become a

paid member.

And we have these biweekly town halls, which you're at right now, so you

know about those.

And then if you're interested in volunteering for definition validation,

you can email me or you can direct message me on the -- on that discussed

platform.

So thank you.

And, yes, Stefano, do you have anything to say before we do the Q&A?

>> I don't know.

Maybe we can share the news.

Shall we?

>> Oh, yes, Stefano.

>> Well, you know, we got -- we have received a grant from the Sloan

Foundation.

So we'll be doing a lot of the -- we're well positioned to have a lot of

participation, a lot of those travel, a lot of those trips to those events

will be supported by this program.

Maybe you can go back.

I had something also I wanted to mention.

Go to slide 28.

I don't know why I remembered this in my head.

I said -- mental note that I wanted to say something here.

Oh, yes.

So here you can see how the legal frameworks in the column legal

frameworks, we have the legal frameworks, the legal frameworks, the

legal frameworks, we have -- we talk about data information available

under OSD compliant license.

And when you look at the code, like inference or data preprocessing, you

see that the legal framework is available under OSI approved license.

And then if you look at the model -- oh, no, yes.

Parameters -- oh, it's cut.

Available under OSD -- parameter says OSD conformant terms.

I think it's interesting here because code, we know that is licensed -- I

mean, we know the licenses, we know the legal frameworks, we know it's

copyright mostly, there is some patent issue, but we've been using OSI

approved license for a long time.

So straightforward, we don't have any problem.

Judging whether the code component are suitable, are available under the

open source principles.

For data information, which is mostly documentation, it's a little bit

fuzzy, but still we can debate -- we know we can identify -- there is no

definition of open documentation.

But I think we can easily identify licenses that give us the possibility

to read the documentation, modify, and redistribute to others.

So that's why we're using the term OSD compliant license.

Although there is a question whether we should use OSD compliant or OSD

compatible.

So compatible with the open source definition or compliant with the open

source definition.

So it's a little bit of a debate and it's ongoing on the forum.

I encourage you to go find the thread and vote.

There is actually a little poll in there.

But the model parameters is interesting because model parameters don't seem

to fall under copyright law.

And there is discussion whether any other exclusive rights apply in

different jurisdictions.

So it's different between like Europe, United States, China, UK.

There is still a little bit of a debate.

So that's why we're using a more generic term that says OSD conformant.

So we want to have -- leave the flexibility to interpret how the

principles or how these parameters are distributed.

Until the dust settles on the legal point of view.

These are the questions -- these are the points that I think will have

to be clarified in the next few weeks during the validation process

among other things.

So if you have opinions, if you know someone who might have opinions,

now is the time to go and check the document.

Because the definition, the draft 08, 008 is feature complete.

It has all the elements that we want.

And if no one really objects or if there are no strong pushback, I think

it's going to be -- the release candidate is going to look very similar

to what we have now.

So any questions, I'm happy to -- me and Mer here are happy to answer.

>> A question on the GDPR.

I can read it.

Shall I read it for the recording or Jan, do you want to come off mute?

>> Yeah, go ahead.

>> I can unmute.

So there's been questions about like when it's -- a model is generating

results that someone is saying, oh, this isn't -- I want to remove this

from this.

From your results according to GDPR.

Wouldn't it be very nice to also have a possibility to do it?

Because if you just have the model, you cannot really remove it.

Because you have to remove it from the training data and then retrain to

get a new thing.

>> Yeah.

I -- yes.

But that is such a big question in fact.

And I'm really curious to see what the results of the lawsuit that just

happened against open AI.

Granted that is a closed, opaque, we don't know what's happening inside

there.

The fact that the source data is not required is because it's exactly for

this reason.

So if there is private information in the source data sets, those -- that

data set cannot be distributed legally.

So that's why we want to know what's going in there.

You know, we went into the training data set.

We want to know exactly how it was filtered.

You know, the duplication, all that thing.

That's why there is a requirement on data preprocessing in the code

section.

Because that's what it means.

You should -- you know, sometimes it's very valuable also to know exactly

how to have the exact same instruments that went into the training.

Building the data set for the training so that one can retrain the model

and/or readjust the parameters with their own data.

Or similar data.

In fact, the exact spelling of the data information requirement is -- says

it needs to be sufficiently detailed information about the data used to

train the system so that a skilled person can recreate a substantially

equivalent system using the same or similar data.

We hope that this solves the problem.

And if -- honestly, yes, if there is GDPR data inside the data set and the

model itself has it, then you should be able to rebuild the -- with your own

data without it.

And maybe that model itself is illegal, right?

In some legislation.

So there is a higher standard that applies here.

>> Thanks.

Any other questions?

You can chat or take yourself off mute.

If anyone has any other questions or thoughts.

>> I can come back on and just ask a little bit of a background question

here because I missed a couple of town halls.

So what is the idea of not requiring the training data in full and just have

the opaque model?

Because that sort of seems to me to be counterintuitive to the spirit of the

open source definition.

And I understand for the legality, but one can also say, well, all open

source models should be legal.

Is that the only thing or is there something more as well?

>> No, I think there is something more.

So many -- the fact that data set did not make it into the draft 06, was it?

Is because the working group as they were evaluating the various systems,

not enough of them put the requirement of the original data set as strictly

required to modify, study, use, and share.

So they ranked higher other -- like the training information.

Like the training code, the documentation on the data used were ranked

higher.

And so because there are so many machine learning systems that don't have

the original data set, like it just doesn't exist because it's not created.

Like for anything that is used with -- learning and other ways that are

privacy preserving.

Then there is that question of private data.

Where it might go -- I mean, it may be part -- I mean, technically part of

the -- good part of the originating data set.

But can be obfuscated or hidden from the model itself.

Like we were concerned -- we are concerned.

I mean, all of us are concerned about generating -- putting the bar so high

that there is no incentive.

Not only there is no incentive into releasing open source, but there is

actually a very strong disincentive into the open source AI.

And in fact, if you look at the amount of lawsuits that any of the more

open foundation models that have been released, they're receiving just

because they've been transparently saying, hey, we have scour the web and

incorporated pretty much anything that we could find.

That, you know, give us -- while on the other side of the spectrum, we

have things like Lama 3 or open AI, they don't say what's inside the

data sets, what went into their training sets, because they don't want to

be sued.

So we're trying to see if there is a balance to be found.

And let's -- the validation is also for this.

Like do we have a set of models out there that already exist that can

fit into the open source AI definition and we can actually work with

them?

Yeah, we want to be pragmatic, but we also want to maintain the

principles right.

The principles that we want to give users freedom, agency, control

over the technical choices doesn't necessarily mean that we want to

have the full spectrum of everything always open all the time.

Because it may be that there is enough elements even without having

the complete spectrum.

If you have looked at the model openness framework paper, it's an

interesting read because it has -- lists all of those components and

then gives a sliding scale of what's required for the -- to be included

in the Linux foundation projects.

And it scales from basically just give us the model parameters all the

way to give us everything.

And they call it open models, open tooling, when some more extra

pieces are available.

In open science where there is everything.

So we're trying to find a balance in there where there is a bar where

we can say, okay, this is open source AI, but -- and then everything

else goes on top.

Yeah.

All right.

So the transparency is a feature of open source.

>> I just want to pause.

I just want to pause.

Because we can continue this conversation for a long time.

I just want to pause.

Is there anyone else on the call who has a different kind of question?

And if not, we can continue this conversation for a bit of time.

Okay.

No.

All right.

So, yeah.

So we can continue, I don't know, to the half hour maybe talking about

this topic?

>> Yeah.

I just want to also announce the fact that we're going to be talking

about data in a separate talk.

Like there is absolutely a need to better understand the space also

as data becomes functional.

Which is a new thing.

Fairly new thing.

And we want to understand it a little bit better.

One of the stops in September is in France.

And we're working on a workshop specifically to start the

conversation that I'm quite sure is going to take a little bit longer.

Because transparency is the feature.

I want to highlight that.

That's why we're insisting on having data information, provenance

and all of that.

And the code for the training.

The code used for the creation of that data set.

I think it's going to be -- it's a good compromise.

But let's see what else exists in there.

>> I see Claire, you have a comment.

Do you want to come off mute, Claire?

>> Sure.

Thank you.

So this is just a question to see if there is any current effort

going into keeping track of any other definitions of open source

AI.

And specifically thinking about anything that might be referenced

in any emerging regulation or policies that might be coming at a

government level.

Knowing that I think it was referenced in the AI act, but I'm

not sure how it was referenced or what they defined it as in that

act.

>> Yeah.

So thanks for the question.

Because the AI act mentions multiple times, a couple of times

that it's a free and open source AI system without providing any

explanation of what that means.

So it was one of the triggers to push for this project to start

two years ago when we saw -- when I saw the first draft of the

AI act, I was like, oh, we need to have -- we need to help

regulators understand this space.

And we're having fairly good, intense conversations also with

the American agencies which are now under pressure to come up

with regulations inside to -- right.

To control a little bit this market.

As it comes out, there are so many foundation models that it

talks about risks and they all want to know what open source

means, what open means in this space and what the implications

are for public in general, for public interest.

>> Thank you.

>> Maybe one final thought or comment and then we'll close the

session.

I saw you typing.

If you want to have a last thought, you're more than welcome

to share it.

>> Maybe I see types.

I can say watch the space, watch our blog, too, because we're

going to be continuing the conversations around data.

I think it's a really important space where we don't have a lot

of practice.

There are new legal questions that are being raised like what

is exactly right, acceptable when it comes to text and data

mining.

New regulation around text and data mining specifically

appearing around the world like Japan has an approach that is

very -- Europe has introduced it as a new right and it's still

having -- there are some limitations to it, though.

So policies are going to be written and all the lawsuits in

the United States which are very interesting and we're waiting

for them to be clarified.

Yes, so Claire, the outreach plan is vast.

Like we've scrolled through with Mayor, but yes, we are reaching

out to a lot of the AI communities, startups, developers,

conferences like new rips and others.

Yeah.

Granted, it's going to -- remember what I like to remind

everyone, that the open source definition came out after at

least 15 years of experience in the free software world and when

the developers were few, computers were not as ubiquitous as

they are now, and it took a while to become so well-known and

widely respected, so we'll have to be doing this work of open

source AI.

We're defining it in a few months.

So we're going to have to do a lot of work after -- continue to

do a lot of this outreach work in the next years.

Yes, if you're coming to PyCon, you'll find us there.

That's our next stop.

All right.

Thanks, everyone.

We host this every two weeks.

I think that next week I'll be at PyCon, so we will not be able

to have this.

But we'll meet again in two weeks and the forums are still

going to be active and available.

Thanks, everyone.

So, thank you.

So hi everyone.

My name is Mare and I'm leading the code of design process for the open source AI definition

and Stefano is with me and this is the public town hall for May 31st.

And those of you who have been here before will recognize our community agreements.

I'll go through them very quickly.

Basically one person speaks at a time.

And we ask that you obviously mute yourself unless we're in the Q&A session.

Take space, make space just means that if you tend to speak up, take a moment to pause

to let others speak and if you do tend to be quiet, we also invite you to share your

thoughts.

And then also once we do get into Q&A, we can have whoever asks a question, there will

be a response and then we'll say wait for another person to ask a question so we don't

just have a back and forth with one speaker.

Kindness this work is hard, but let's be gentle with each other.

Forward motion, focus on what is possible in doing it because this is hard work.

So we note obstacles and we come back to them, but we do what is possible in the moment.

Likewise solution seeking.

So saying something is not possible, yes, and it's very vulnerable to say, hey, how

about this, but that is what we need to have as a mindset to get this work done.

And are there any other community agreements that people would like to propose that are

not here and you can just put them in the chat.

Oh, hi, Anna.

Hi, Anna.

Okay.

I'll just continue.

So yes, so we are creating the open source AI definition.

That's our project for this year.

And where are we now?

We're on version 0.0.8, which was released in April and the parts should be familiar.

We have a preamble.

We have the four freedoms, which we're not going to go into today, but they're used,

we modify and share.

And then we have the legal checklist, which is basically operationalizing the four freedoms

by identifying which components are required, which was voted on by our community co-design

process.

And then what is the license or legal framework for each component.

And Stefano, step in if you have any additions.

What we're working on now is to review, is the review process for determining if an AI

system meets the definition requirements.

And yeah, we would like to review about 10 systems before we release, do release candidate

one in June, which is coming up soon.

A little bit of how did we get here?

This is the recent past, not the story of the whole project as some previous town halls

have shared.

So these are the people who've been working on this.

At this point, we have 11 systems that we're looking at, and this is listing the reviewers.

We started with the asterisked systems, Bloom, Lama2, Pythia and OpenCV.

And then we added on seven more.

So you can see.

And we had this spreadsheet-based validation process where component listed on the far

left, then the legal framework from the definition, then the individual reviewers asked to find

on the internet, which I'll get to later, the legal document as provided by the system

creators, and then to look at that document and determine, does this document give the

ability to study, use, modify, share that particular required component?

And it was hard.

It was in most cases not possible for volunteer reviewers to find the required documents necessary

to do the review.

And as a result, the analysis was also not possible.

So let me just see what my next slide is.

So what this means is that -- oh, there's a new slide here.

I see.

So what that means is that we are still needing to work on the validation, and we're needing

to work with system creators.

We need from system creators their identification of this is the document that you need, this

is the license on this component of our system.

We've just realized that that's -- it's a required component of even being able to test

our own definition.

And okay, we're going to complete this validation phase by the 10th and resolve comments and

release a version 0.0.9 after the validation and cut a release candidate with sufficient

endorsement.

Stefano, did you want to say anything else on the slide?

>> Well, maybe just add a little bit about the validation phase and how it's going.

We realize that basically that checklist is complicated to -- for people, even for experts,

computer experts, to find these components without the expertise of the actual -- the

people who have created the systems is really complicated.

So we really -- at this point, we really have to engage with system creators, the original

creators of PHY, and LLAMA, LLAMA 2 and 3, and GROK, and Mestral, and PTI, et cetera,

Falco, and ask them to provide the list of components.

Or we need to find another way of validating.

Because we had conversations with the Linux Foundation also, and they have a similar concern

for the model openness framework, which we have -- we are reusing for the list of components.

So it is complicated.

But the intention here needs to be -- you know, I'd like to clarify.

The intention here is to provide a definition that is general purpose, that we can apply

to different technology, that can to some extent resist the test of time.

This components piece is really targeted at the latest generation of transformers and

large language models.

The architectures that -- of the systems that we have here, neural networks, et cetera.

So we're really trying to strike a balance between setting principles that are high level

and valid for a longer term.

And provide a checklist for the evaluation of the openness of these systems.

So yeah.

That's it.

We're a little bit -- and I just posted a few minutes ago, probably an hour ago, on

the forum, like a comment along the same lines.

Of what I just said.

There is one curiosity here that probably some people have been -- that I've heard people

asking.

Go back one slide, Nat, please.

Where it says -- the column that says legal document.

And why not call it license?

And that's because the licenses are -- is a term that is really tied to the concept

of copyright.

So it works really for documentation and code.

But for model parameters, the copyright is most likely not applicable.

And the same also for data.

Copyright is not necessarily applicable.

So those are usually referred to as agreements in legal terms.

So that's why we're not calling them -- legal document is more of a generic term that covers

both licenses and agreements in terms of service and other names.

>> So I'll just comment a little on Nick.

And then Dan, I'm going to leave your question to the Q&A.

So just to clarify, because this is a concern that people have of the idea that would system

creators be evaluating their own systems as part of a formal process?

No.

I think it would be that system creators are providing documentation and then there are

independent reviewers looking at that documentation and confirming, yes, this describes the component

as required.

I don't know, Stefano, if you have anything to add on that.

But just this idea of independent review is still part of the process.

Okay.

All right.

So yeah, this is just basically saying what Stefano was talking about.

Reaching out to system creators, I would add that, yeah, we are also looking into collaborating

with the Linux Foundation on this because we are using their component list.

And they do have -- I guess I can't -- I'm not sure what I can announce.

I know they have a launch.

But they're also working on a solution to this documentation challenge.

And so we're looking at how can we collaborate with them.

So that we're not both going to system creators and both asking them for documents, but where

we can be asking the system creators to funnel their documentation into the same location.

This volunteers, I'm not sure that's going to work.

But if volunteers do have this knowledge and can help us fill in the blanks, that's great.

Yes, and we're learning from reviewers, which is basically what Stefano has talked about.

This idea of needing the collaboration of creators, system creators is what we found

from talking to reviewers.

Yeah.

So this is -- yes, there is a report that Stefano referenced, which is just basically

in text talking through what I'm sharing with you now.

And that's a QR code to the forum.

And yeah, we've been thinking through what are ways to simplify the validation process.

At this point, it seems like making the documentation for each component easy to find and review

is probably the number one blocker.

There may also be blockers related to format.

And we're looking at the idea -- Stefano created this design, the idea of an evaluation card.

Maybe that format would be easier to work with than a spreadsheet.

But in any case, having the document to review is probably the number one need that we have

right now.

And Josh, I see your hand.

And I will answer during the Q&A.

And then just to have our timeline.

So we are still looking to release RC1 next month.

And then the stable version in October.

Yeah.

And also a virtual launch event, I guess, is still something we're planning for next

month.

RC1.

We'll see how that goes.

And then we have some in-person meetings.

We were at PyCon.

And Nick created a forum post about that, summaring what we're up to at PyCon.

And yeah, throughout the summer, we have a roadshow going.

And we'll have a data event in October.

That's an issue that's come up throughout the process, is what the definition should

be saying with regards to particularly training data.

So yes, speaking of which.

So yeah, so this is a huge issue.

It's a very important issue in the definition.

And the AWS, Amazon Web Services, open source team posted a range of different concerns

with our current version on the forum.

And the Linux team, primarily the issue of wanting data to be included as a requirement.

And then also the Linux Foundation has recommended adding a data card and removing data processing

code.

So there are various institutional actors and individuals that have made requests about

changing the definition.

And I also just want to affirm to everyone on the call that no changes will be made without

a very clear, structured public process.

So you're not going to wake up one morning and a new requirement is in there, or a requirement

has been removed.

We're sharing with you the requests for transparency.

But we will have a public decision-making process about any changes to the definition.

Let's see how much.

Yes.

So this was helpful and useful.

So the LLM 360 team voluntarily ran their system through version 8 review process.

So again, self-review wouldn't be something that would happen in a formal review process,

but this was very, very helpful just that they were able to look through the component

list and the description of the components and said, yes, we understand what each one

says.

Yes, we have documentation associated with each of these components.

Yes, we think it's fair and well-structured.

And they have their post.

Again, that QR code will take you to the forum, which includes all these different posts I'm

describing.

And then, yes, Stefano also posted about certification.

So what is the process for determining that an AI system meets or does not meet the open

source AI definition?

Is that a certification process that lives at OSI?

Does it live somewhere else?

That's something we're also considering.

And Stefano has a post on that.

If you have thoughts, please comment on that.

Yeah.

And this was also prompted by--

Go ahead.

Yeah.

That request was also prompted by the AWS team, which is something that we were already,

you know, back of our mind.

It's definitely for the future.

It's not an immediate urgency now to decide whether we want to have more certifications

and how that would look like.

But I think it's an interesting question to pose.

And if you have any thoughts, please join the forum and contribute to that conversation.

The question is if OSI should engage in the certification and how.

If yes, how?

It's not necessary.

I don't think it's mandatory for OSI to necessarily engage into this process of certification.

Yeah.

And that was also something that came out of the PyCon workshop that we did.

The number one question from participants was how do I know if an open source-- a system

is open source according to a definition?

You know, what's the process?

How do I know as a system creator even?

So that's also something that directed us in that-- toward that question.

Okay.

Yes.

So just ways to participate have been shared already.

But just the link to the forum is discussed at opensource.org.

You need to create an account, which is free if you want.

Or you can become a member and give us a little donation.

OSI is a nonprofit.

We have the biweekly town halls, which you obviously know about.

And then, yeah, if you would like to volunteer, you can DM myself or Stefano.

But primarily me, since it's my role to manage that.

And now we will get to the Q&A.

So I'll start with Dan, and then I'll call on Josh.

So Dan, I'll just read your question.

Are we looking all the way down to the library level for SBOMs?

And I don't know, Stefano, if you need additional information on that or--

I was wondering, I'm not sure what you mean, Dan.

I can give you voice if you want to speak out loud or if you want to elaborate a little

bit more, because I'm not sure which library level or which SBOMs you're referring to.

Okay.

Dan's typing.

Yeah, there you go.

Is that clarifying?

Yeah.

I'm thinking GitHub repositories.

So for AI systems, there are three type of components that are required.

Then they're grouped into data information, which is mainly made of documentation.

There is model parameters, which is basically a set of one and zero organized in tables.

And then there is code components that include the architecture of the system, the code used

for assembling and creating the data set, the code for running the training, and the

code for inference.

So are we looking at the library level?

I mean, for the code piece, SBOMs, I'm assuming you're talking about the code.

I don't understand the question.

Right.

Yeah.

Code, we're looking at is the code open source or not?

And it's usually pretty easy to understand if it's open source or not.

If it carries an open source license and source code is available, you should be able to figure

it out.

SBOMs are -- no.

So if you're asking how deep we are investigating it, you know, someone was asking yesterday

in a conversation, like, if you -- for inference, you need to run a proprietary system or you

need to run on a proprietary platform.

You can only do inference on G Cloud or something else.

We'll have to think specifically.

We'll have to look at specific examples.

Because we want to -- because there is a thing called the system library exception or there

is an experience that we have from the old days when we didn't have the Linux kernel.

And there was a lot of open source software running on proprietary hardware, on very proprietary

operating systems.

And that was okay.

That was fine.

Because we were working towards having more open source code.

So it didn't matter if you were running an open source photo editor on Windows or, you

know, a kernel, a known free kernel with a GNU user space.

It was still open source software.

So we will have to look at specific examples in these cases to see how deep we want to

go into -- it needs to be open all the way down to the last turtle.

>> Thank you.

Okay.

Josh.

>> I hope that explains.

If you have more questions -- okay.

Good.

Josh.

>> First off, thanks for bringing up the system library extension.

That's the first thing I thought of when I've been thinking about these things.

And the reason why that came about.

Just as you explained so succinctly.

And OSI came out of -- the open source definition came out of all of that.

Having criteria for determining, you know, what's going to be part of this operating

system and whatnot.

Where I feel this -- what I feel this is most analogous to, this process that I've experienced,

is actually the free software foundation's respect to your freedom hardware certification.

Because it had nothing to do with hardware in a sense.

Because they didn't -- they weren't looking at hardware design and things.

That was a nice thing.

If anybody wanted to share their hardware designs, that would be great.

But in designing that program, which is -- I led the launch of that.

And the initial certifications.

It really was about thinking about an ecosystem in a context.

Right?

And having to come up with the set of criteria.

How you go about -- okay.

Here's a person selling a product.

And we want to certify that it's, you know, respects your freedom in these ways.

Right?

But it wasn't just looking at that product.

And what code it shipped with.

That was what we would do to give them certification or not.

But what we did as a community and in working with them, is really encourage them to think

about how they're shipping that.

How they're treating the entire ecosystem.

Not just to support this product, but the idea of product lines and the ability for

a person to take this and make their own potential products or adapt the existing products.

And it feels very similar to that.

That you're going to have a lot of different kinds of hardware.

Or in this case, open AI systems or laboratories, as I kind of think of them.

Or open AI ecosystems.

And it feels like it's a little bit broader than, say, a definition.

But more like, you know, a tree of conditions.

Like, well, for these kinds of systems, there are levels of what a person can do.

You know?

If you ship all of this, it gives them this starting point.

And they can then adapt on top of it.

If you give them, you know, you can give them all of this, but it's not going to be any

of the data.

They're going to have to go out and find all of that to just get started.

To have day one.

It's going to be maybe a year out for them.

Or if they're going to need a certain amount of money.

But we had to do the same kinds of things in the open -- in the hardware certification.

And partly why I bring that up is because we didn't do actual certification.

You know?

Now that I'm in the world of standards development with IEEE, I understand what certification

is much better than I did when I was with the FSF.

But really, it was this criteria.

You could use a trademark.

The FSF's trademark.

You could self-certify was one of the ideas that we were pursuing.

And say, I'm delivering what I believe meets all of these criteria of some version of this

criteria.

And I just want to put that out there.

Because I think there are some amazing historical examples that would be -- that we could run

through this without feeling like we're having a moving target.

Things like Cafe.

And then Facebook's creation of Cafe 2 is, to me, one of the greatest case studies that

we can look at.

A lot of people aren't familiar with it.

And I don't do my civic duty of writing about it.

But to me, it's literally one of the best available sort of things that has gone through

a whole -- its whole life cycle from kind of beginning to end.

Because it's now moved on to other things.

But it's -- I'll leave it -- well, I'll leave everything there.

And then if another time I can come back and I can discuss why I think it's a great learning

example for what is happening here and how it could apply.

But my main kind of point -- and it's kind of a question, I guess -- is, do you feel

this is more like this multi -- like, OSI definition is kind of binary.

Your license is either -- when applied to code, is either meeting this definition or

not.

But I feel the open AI definition really is, it's more like a set of criteria for kinds

of systems or laboratories or like a lab of the box or something that is evaluated and

then potentially given kinds of -- not scores, but, you know, meet certain types of criteria.

And is that where you feel this might be going?

Or are you looking to try to get it to be simpler?

I can't really tell.

>> No, thanks, Josh.

What's your comment?

>> No, I get it.

So it's a frequently asked question, I guess.

Only recently there was another one request on the forum about this.

So I believe that strictly the open source AI definition must be binary.

And it must be binary because if it's not binary, then people will -- people, the public,

politicians, regulators, business managers, and business owners, venture capitals, et

cetera, will expect that also the open source definition will imply a range of openness.

Which is already there.

If you want, like if you look very carefully, you will see that some software is open source.

And then on top of that open source layer, there is a proprietary piece that renders

the whole stack less useful.

But still it's better than nothing.

So there is in practice, there are -- I can see that some people might interpret them

as ranges of open.

But for the definition itself is binary.

And that's where we're -- what we're aiming at.

We have an open source AI definition that is binary.

Meaning you provide these data information, code, and required data information, required

code components, and required model components, and you're done.

You pass the bar.

Then if you provide more, you are more open.

If you provide less, you're not open source AI.

That's it.

It's crystal clear.

Now there is something, though, that keeps coming into my mind.

The concept of what you can do, and there was someone posting recently on the forum

again.

What you can do with a full open source AI, in other words, or with some of the artifacts

of the machine learning, without having access to some of the components, is immensely more

useful and more powerful and more -- you can do more than you can do with a binary piece

of software without having the source code.

In other words, if I don't give you -- so the open source AI definition requires very

detailed information about the data set, so that -- and the code that you use to build

it so that you can retrain the -- or you can train a new model that has similar capabilities,

similar scoring, for example, in benchmarks, et cetera.

That's the intention of the Draft008.

That capability of retraining a model, especially if it's a large one, is not something that

will happen very often.

It's not like rebuilding a binary, even if it's a large one.

It's still within reach, and it makes a lot of sense for security, for research, for a

lot of other things.

The retraining of models is -- I don't think it's going to be very, very popular as an

activity.

But at the same time, fine tuning and splitting models, re-architecting and things like that

is the most, in my mind, in my -- you know, I'm not an expert, but from what I've already

-- we've already started to see those activities being a lot more exciting and popular.

So in the future, there might be some other -- I mean, in practice, as we go into practice,

we may see some -- something else pop up.

Yeah.

>> Thank you.

>> Yeah.

Custom models are time-consuming, expensive, et cetera.

Yeah.

So more questions.

>> Yeah.

Does anyone who hasn't asked a question have a question?

And you can raise your hand or write in the chat.

And any follow-up questions?

Someone who's already asked a question and wanted to ask a follow-up.

Okay.

Josh.

>> Yeah.

So part of where I'm still struggling here, right, is that -- for good reasons, I should

say, I'll start there.

So that I don't -- I don't want to offend anybody.

I think people have made a lot of good choices and has tried to do good things.

But in general, our community has tried to, except for some, avoided talking about the

fact that when we say an operating system is open source, we don't really mean that.

Right?

We don't really mean that you go and if I pick a piece of code at random, it is going

to be open source.

When we're talking about the operating system.

We mean for the most part, practically speaking, with some exceptions here and there.

And that's important to note.

Those are the exceptions that make -- those are the only parts that are the non-open source

parts at times.

And they're there to enable -- to practically allow people to run on different hardware

systems to allow for things that in life are important.

Right?

Whether they were browser add-ons or they were kernel modules or what have you.

Right?

And so I think it's kind of maybe important to note that if the level of things we're

judging are these multifaceted systems, our definition might not need to be when applied

in normally might not need to be perfect.

Because we've never really done that.

People don't want to take the free software foundation stance of, you know, Debian is

not a free software operating system.

Right?

Like, that's just been brutal.

I lived that for ten years when I worked there.

It was terrible.

I hated it.

But I understood why they took that line.

Because they felt somebody needed to.

Even if it -- but everybody else, and I'm very happy everybody else made the good choice

of being practical and saying Debian is a free and open source operating system and

Red Hat is and whatnot.

Right?

But I wonder if we could do something similar with this.

Where we say, look, here's the pristine version of it.

If there are just things that are kind of added on to enable this to happen in various

contexts, then we don't throw -- we don't just label the whole thing as not open source

AI.

Right?

I think that we -- I think that maybe we should say, when we apply this definition, we can

do it in a way that says, is the bulk sort of kernel of this?

Is there a single way in which you could take all of the -- take a subset, a majority subset

of this and apply it in a circumstance where it is 100% AI and these other things are just

for practical compromises to allow it to run in more systems, use certain data sources,

or what have you.

They're not necessarily necessary for what we're evaluating when we say open source AI,

but they're practically needed to allow people to actually use these.

And that's how we apply it.

It still gets us to binary, it's still criteria, but I mean -- sorry, I'm just trying to really

think about real world.

>> Great question.

Yeah.

>> Josh, I hear you.

And in fact, you know, probably as veterans of the open source and free software, I think

you recognize that there is a piece above the checklist.

The checklist is very specific.

And let's say it's a sort of experiment.

That's why it's going through the validation phase.

But what really, in my mind, what really counts is what's above that.

And above that, there is the definition that looks pretty much like the free software foundation,

the free software definition, not just the four freedoms, but also what's written below

as the preferred form to make modifications to a machine learning system.

Those pieces are the ones that in my mind count a lot more.

Because in those pieces, we can have that flexibility to judge and evaluate.

From a distance, we're going to be able to see, hey, do I know enough about the prominence

of this data so that I can say how you've trained your system and therefore I can say

I can replicate it and that will tell me that it's really an open source AI.

And if not, like, dude, I don't even need to go through the checklist.

Like, you know, it's very quick and clear.

But if I have plenty of information, then if it's skipping one of the elements of those

checklists, I can probably say confidently, like, yeah, this is open source enough.

I can live with it.

Because I know that I can do this, this, and that.

I can modify, I can study, share with confidence.

So a lot of it, remember that this is it took 20 plus years to go from the free software

definition to the open source definition.

Like, that required that generate I mean, those 20 years generated a huge amount of

code licenses, there was plenty to draw from to write those 10 points for the Debian free

software guidelines.

We don't have that luxury.

We're really flying and building the plane at the same time.

But yeah, the experience is really valuable.

And if you share with me that cafe that you mentioned that via email, I'm really curious

to see what that is.

Yeah, I'll do that.

I've written it up for sharing to a co worker somewhat recently.

And I'll adapt that.

Just a quick little follow up.

Oh, sorry.

I didn't capitalize.

Yep, yep.

Look, Peter, I need to just absolutely.

Sorry.

So what I'm going to do is I'm going to go to Dan's question.

And then I'll do a last call for questions.

And I think it might make sense, Josh to take the any continuing, continuing conversation

into email.

Just so that we can can wrap up the meeting.

But yeah, so I'll take Dan's question, then we'll do the last call.

So Dan is asking, how will OSI partnerships work, particularly a OS, OSI AI partnerships.

So I think we might need more clarification, but Stefano, do you have enough to respond

to that?

Yeah, I it's not clear to me the concept of partnership, because we don't have partners

now we have the OSI has affiliate organizations, which are other nonprofits that support the

mission of the OSI.

We have individual members who donate to us and decide donate or not, but decide to support

the mission of OSI with money or just by following our activities.

And we have individual sponsors, sorry, corporate sponsors and and but we don't have partners.

So I'm not sure.

We don't envision to have AI partnerships.

So if you want to type in there, Dan, what you're clarifying follow up, then we are happy

to respond to your questions.

And then I think I will just do one last call for comments, actually for questions.

Yes, and then and then yeah, we can take the conversation Josh, the quick conversation

offline to continue if you'd like.

So as I scroll to the last, thank you, slide.

I'm not seeing any.

Okay, cool.

All right.

So then thank you so much.

Anna.

I see I see a raised hand from Anna.

I think it might be a clapping hand from Anna.

Oh, I see.

Okay.

Thank you, Anna.

We appreciate it.

Yeah, we met on at PyCon.

Oh, just clapping.

Okay.

All right.

We appreciate it.

Okay, bye.

Thank you, everyone.

And hang out in the forum.

That's where we share all our updates and opportunities for interaction and feedback.

Thank you.

Thanks.

Bye.

Bye.

Bye.

Thanks.

All right, folks, thanks for joining this town hall.

We meet every two weeks, try to keep up to date the community about the evolution of

the draft and summarizing the conversations that we've been having on the forums and in

conferences like the conference that I just presented at here in Paris, in Cologne, Paris,

in a hotel.

So hopefully the network gods support us to go through this recording.

Just the community agreement, remember that we're trying, the one that I'm really focused

on and love the most is the forward motion, the fact that we are trying to understand

where the problems are and if we don't find an immediate solution, still we've marked

the spot, we move around, we'll get back to it because we do have to find a solution.

We do have a tremendous amount of pressure from all over the place, from politicians,

policymakers and from the industry, from academia, from the nonprofit and civil society to provide

some sort of guidance of what open source AI really means since everyone is using this

term.

And reminding that this is our objective to have by the end of the year a workable definition,

something that is acceptable even though it may not be the most perfect test thing that

we can imagine because the world is moving very rapidly and things might change in the

future.

So we need to find ways to provide solid principles that maybe will not change but allow for some

parts to be adapted.

We'll talk about some of the topics that emerged last week.

So the current version of the definition is still draft 008 and this was released a little

bit over a month ago at this point and it's made of some parts and parts that have received

very little comments in the past months are the preamble which is the place where we define

what we're talking about which is we decided to adopt the definition of an AI system provided

by the Organization for Economic Collaboration and Development or ECD.

It seems to be a widely accepted definition so we're going to use that as a reference.

Maybe it's worth going back and remind people at this stage that the reason why we have

a definition of an AI system is because we needed to have an anchor for the conversation.

In the free software definition, the free software definition refers to the program

and everyone understands what the program is or at least there is a very small margin

for error or misinterpretations.

But when it comes to AI there are misinterpretations and that's why there is a definition and these

definitions are also stated in law like the AI Act mentions, defines an AI system in a

very similar way to the OECD text.

So that's what we have.

And then we have in the preamble the reason why we are working on and the reason why we

want the definition of open source AI which is a very short summary of the intention to

give users the same rights that they have in software, the same independence, control

of the technology to enable permissionless innovation and collaboration.

Now the concept of user is also not defined in the free software space and this is an

area that has received some comments.

We want to be explicit and I think I'm working on a draft 0.9 and that will specify, will

contain a suggestion for what the recipients of the rights should be.

And draft 0.09 will probably mention the fact that we want end users, so anyone who is interacting

with the system, putting input and receiving outputs and also developers and deployers

of AI systems needs to be able to enjoy those freedoms.

Now below this part have not received a lot of comments so they seem to be fairly stable

to me.

The one part that is new in draft 0.08 is the concept of preferred form to make modifications.

That is something that is described in the free software definition as access to the

source code that is necessary for the actions of study the software and modify the software.

Now to study an AI system and to modify an AI system it's necessary to define what the

preferred form to make modification is and that's where there is a new section in 0.08

that says what the preferred form to make modification is.

I'll go into the details later.

And finally the bottom part is a legal checklist.

This is what I refer to as it's based on a paper from the Linux Foundation called the

Model Openness Framework.

You will see often referred to with the acronym MOF.

And this lists components of machine learning systems and in generic terms but they're defined

in the paper.

We use this as an ideal checklist that a future certifier or reviewer of AI systems might

use as a reference to say if this component is available under licenses or terms or legal

terms that allow the same grant, the same freedoms of the open source definition, the

original one, then if the required components are available under those acceptable conditions

then the AI system is an open source AI.

If not, most likely it's not.

Okay, so let's go a little bit into the details.

The key feedback that we have received is around what is required and what is optional.

So the pieces of optional components, I mean required

components are the biggest conversation is about data.

The original datasets are seen, some people have seen the training dataset into the optional

components and I believe they may have jumped to conclusions because the, well I'll talk

about it, but these are replaced with data information.

So let's skip through.

The other required components that I want to draw your attention on is the fact that

the data processing and like one of the components is actually required and data processing and

labeling techniques and all the disclosures about how the dataset has been built are part

of the draft.

And I'll go into more details later.

So there is a very lots of confusion around this part of the definition and we need to

spend a little bit more time to discuss.

Other minor requests are comments that we have received that are around the fact that

the legal requirements are described as available with terms like available under OSD, the original

open source definition, OSD compliant terms or OSD conformant terms.

Quick explanation of what this means.

The data information, I mean the concept here in data information like training methodologies,

et cetera, training, training scope, the data, the scope of the data, where the sources,

et cetera, are in documentation are probably going to be in the form of documentation.

The documentation uses different licenses and different agreements for sharing and distributing

for distribution.

However, the OSI has reviewed licenses that are not specifically targeting software.

So we don't have a way to say right now, we don't have a list of OSI approved licenses

for documentation.

So we know what they look like and they conform, they comply with the open source definition.

In other words, they allow for no discrimination of use, no discrimination of people, no field

of use, strict restrictions, ability of preferred form to make modification to the text, like

the source code of the documentation, et cetera.

So like you don't distribute a PDF encrypted as documentation.

That's not acceptable.

So that's what these words say.

And for the model parameters, we do talk about the OSD conformant.

So we use a different term because most likely model parameters don't fall.

Actually it's quite clear at this point, they don't fall into copyright law.

So using the word licenses and license approved, OSI approved, OSI compliant terms is not really

useful.

We need to be using a different framework and it's probably going to be more in the

contract law, at least that's what many of the lawyers that I talk to seem to think.

And that's, you know, OSD conformant means you still need to give us access to the, give

us the possibility to share, modify, give out free, without asking for permissions,

et cetera.

So it's a word that it will be more explicit in draft 09.

There will be a description in that lawyers can interpret more clearly.

So let's get into the concept of data information.

And maybe I need to take a little bit of a step back.

The intention of the definition is to provide in the upper part, so above the checklist,

what we call the checklist, in the upper part of the document, the stated intentions and

sort of a general, unmutable, general purpose reference point that can resist the test of

time.

That's why we have principles in the preamble.

The definition of open source AI is synthetic in the four freedoms.

The definition of preferred form to make modifications to a machine learning system is because machine

learning is the place where we have the challenges today of recognizing the new artifacts in

these AI, modern AI systems.

And so when we get into the preferred form to make modifications, we were looking for,

we were pushing the community to find a way to describe in generic terms, the intention.

And the intention is to have the possibility to recreate from scratch.

If I receive an AI system that I like and I wanted to give it to others, I need to be

able to have all the instructions and all the tools and all the data to recreate a substantially

equivalent system.

Because that's important.

That's one of the fundamental principles of open source has always been to be able to

have the instructions and be able to share those with others.

Now during the review process and during the co-design process, we asked volunteers to

evaluate existing systems and to rank the importance of some of the components.

And during that phase, a recommendation came out when they voted that many people voted

much higher the availability of the details about how the datasets were built rather than

the actual datasets.

So that gave us our suggestion that maybe it was worth testing the waters and understand

a little bit better what the issue around data is.

From the high level perspective, when approaching the problem, we realized, I mean, all of us

have had the same impression, data, the pipeline to build an AI system starts with data that

gets filtered, mangled, assembled, tokenized into a dataset.

The dataset gets fed into the training machine.

Training is an iterative process.

Data comes in at different stages.

All of this is complicated but should be described and made available.

And after the training is done, you get the parameters.

And with the parameters, you load them into an inference engine.

And that is what responds to, well, and you put an UI on top that gives you input and

outputs like think of chat GPT or other systems like that.

When you look from the distance at this whole pipeline, the intuition is that the whole

pipeline needs to be made available.

That whole pipeline is what you need to modify the preferred form to make modifications to

the system.

Now, when you start to zoom in, that's where the problem arises.

So when I started looking into one of these systems that in my mind were the two systems

that are the most open, the most freely licensed, freely made available, and that one is called

Pythia from the nonprofit called Eleuther AI.

The other one is from the research institute, ALEN AI Institute.

And Pythia has been trained on a dataset called the pile.

The pile is fully described.

There is that community working on it.

All the tools that have been used to assemble the pile, filter the pile, train Pythia using

the pile and all that, they're all released with open source licenses.

Now the pile has been an object of a takedown request for alleged copyright infringement

in the United States.

And since then, the original distributor of the pile has stopped distributing it.

Now you can still ask the Eleuther AI group to get the dataset, but the legal status of

the distribution of the pile is in jeopardy, or at least it's unclear in the United States.

But as discussions on the forum have revealed, the pile is perfectly legal in Japan.

And because it's distributed by a nonprofit and it's distributed for nonprofit uses,

maybe it's also legal in Europe, because Europe has reformed its copyright act a few years

ago and they have included an explicit exception for nonprofit text and data mining, which

is what the pile does.

So this raises a question, like what happens when you have...

Well, Dolma is in a similar situation.

Initially it was released with a license that doesn't obey, it's not compliant with the

open source definition.

It is imposing restrictions and permissions that needed to be asked to the island institute

before it could be used.

And then they changed the license.

So initially it would be not an open source dataset or an open dataset.

It has become an open dataset now with the change of license.

But upon looking at more closely, it contains probably the same issues that the pile has.

So someone could sue or request Dolma to be taken down for copyright infringement in the

United States.

So there are these legal issues around copyright, the fact that datasets can be open at a certain

point in time and not open at a later stage or vice versa.

And the legality of the distribution of this dataset may change over time and changes over

geographies.

So calling an open...

Anchoring the definition of open source AI to something that can change so quickly and

can change over time is challenging in many ways.

And there is another issue that is more technical.

There are ways to train systems without actually creating a dataset.

And one of these is called federated learning.

And in federated learning, each provider of datasets is more common.

It's common or, you know, yeah, it's common.

It's used with privacy preserving techniques.

If you have data that is owned by a different entity and they don't want to share it with

others, they don't want to create a pool for different reasons.

If they cannot create a pool because law, like privacy laws for medical records, for

example, doesn't allow hospitals to share data of their patients, then what they can

do is to set up training engines inside their own data centers.

And these training engines collaborate remotely in a privacy preserving way, training a model

without the data actually ever leaving their data centers.

So this technique creates models, parameters, but doesn't create datasets.

So when we were keeping this in mind, then we thought, OK, so this is a challenge and

we need to find another way to approach it.

And that's where we came up with the definition of data information.

Data information is, I didn't put this in the slides, but data information is described

in the draft, which I encourage everyone to look at.

The draft says that data information is, the intention here is to recreate an equivalent

system.

And the text says sufficiently detailed information about the data used to train the system.

So that, and this is the very important part, it's not just the information about this data

used to train the system, but the objective here needs to be taken into consideration

so that a skilled person can recreate a substantially equivalent system using the same or similar

data.

And this concept of the same or similar is important.

And I'll give you one example.

Let's say you have received a model that the original developer trained on Reddit.

This was an example brought up by Tom Callaway's bot from the AWS team, who doesn't agree with

the concept of data information.

And he said, what if someone trained on Reddit, but licensed the data from the Reddit corporations,

let's say for $100 million.

So you receive now, they have disclosed the data information, and they have given you

all the code, the source code used to train and run the system.

Now what about the, does that qualify, would that qualify as an open source AI?

Now, my answer to that, looking at the concept of data information, I want to be able, to

give an answer, I need to be able to know if I can build a substantially equivalent

system using the same or similar data.

So the same data would require me to enter into $100 million agreement with Reddit corporation.

But if you think about it, while thinking about it, I know that a data set called Common

Crawl contains the Reddit data already, despite the fact that Reddit tries to remove, to have

Common Crawl remove that data.

But that's a different story.

So Common Crawl has the Reddit data.

So before I can answer to the question, whether something trained on Reddit licensed data,

I need to extract, try to extract the Reddit data from Common Crawl, run the training.

If the model that I find, that I obtained at the end of the training, using the same

code from the people who have given it to me initially, if I get something that behaves

the same way, then I would say it's an open source AI.

If the original training data set from Reddit contains some really special source that makes

it impossible to replicate, then it would not be an open source AI.

And so I leave it at that.

I want to make clear that the intention at this stage of the definition, the preferred

form to make modifications to the system, is written in generic terms to accommodate

the fact that sometimes data sets don't exist and sometimes data sets cannot be distributed

or they can be distributed, but only in some geographies and only at different times.

So it's been written by lawyers and you can recognize in there some concepts like the

concept of the word skilled person, which is a term of art.

And it's meant to be a generic application of the principles of open source.

Now we have received also on the forums there have been proposals from Giulio Ferraglioli

and Tom to use something like synthetic data instead.

It's a fascinating example, definitely, and synthetic data is data created from scratch

by large language models and other techniques.

But it's really an unproven technology.

It would be really detrimental, I think, to anchor a definition to some technology that

is unproven, that is expensive and may not work in all cases.

Also this doesn't leave...

Yeah, it's unproven and it may not scale.

So what if?

And the other position that we have read in one of the comments, I think also this was

coming from Giulio, is that the whole pipeline must be open source before something can be

considered an open source system.

And I push back a little bit on this because if the GNU project, when it started and even

today, contemplates the option of running open source and free software, however you

want to call it, it's the same thing, on top of Windows, for example.

You can run...

You can...

The concept of free software that depends on proprietary libraries because they're part

of the system.

So the whole concept of complete, pure open source components in a system is not something

that exists in nature.

We have...

We, the communities around the world, have always accepted compromises when that led

to having more openness.

And I really want to have this clear and taken into consideration when we get into this debate.

And so these are the most important points.

There are other considerations that we have received.

I think, if we don't strictly require datasets, what are the incentives for other corporations

to reveal their...

To share, to create more open, more common datasets?

That is a very good question.

And in fact, I think that given the status of the legal status of policies around the

world that make the pile or dolma complicated to share is the reason why at the OSI, together

with Creative Commons, together with Open Future, we want to have a separate conversation

about the issue of data datasets and policies around that.

And we're working on a conference this year, sometime in October, to get this conversation

started because it's a very complex one.

We do recognize that there is an issue with creating datasets and sharing them.

And we wanted...

But we don't have right now clarity about how to fix this issue, how to create incentives,

how to create concepts like copyleft inside between data and training and models.

So that, for example, aggregators of large datasets who want to do the right thing, they

want to create more open models, they want to share their data in a way that preserves

the possibility for society to have access to models that can be controlled and shared

by larger groups, not just single vendors.

We don't know what the mechanisms are because copyright, which has helped us create copyleft,

does not help us cross the boundary between what is data and what is the trained model.

We need to think about contract laws, maybe, and maybe even policies like new law that

help us tie data to train models.

It's a complex topic, and that's why I think we're having such a tremendous amount of discussions

over two years of the investigations and then later the co-design process around the open

source AI definition.

All the hardest conversations have been around this concept of what about the data?

And I think we need to...

We really need to come to the conclusion that this is a very complex topic and that needs

to be...

The data issue needs to be taken in a separate trial.

And the other thing that I want to say is that the concept of data information, if you

read the definition and start from the end, start from the end, what is the intention?

The intention is to recreate a substantially equivalent system, whether you are using the

same data, exact data, because it's available, or whether you're using similar data because

one way or another you find it, but you end up with the same model, same behavior, then

that should be enough in the definition.

And by the way, so let's look at what...

Let's move on.

Let's look at what we have done to validate this hypothesis because that's how we've been

operating.

Let's look at examples.

Let's see what's happening out there in the wild.

We validated...

We went through a few systems.

We asked people to...

A few, more than...

Now we are at 12.

So we're trying to look at what happens with these systems.

Some we know, they are not passing the bar, like Lama and Mistral and Falcon and Grok.

Where does the definition fail?

We find that it's hard to find the components, right?

With people who don't know about it.

So for example, if you look at Grok, Grok is one perfect example.

It was developed by XAI, the Elon Musk thing, and they just share the model weights very

freely and nothing else.

Now if you don't find the other components, is it because they don't exist, which is probably

most likely, or is it because you couldn't find it?

The other thing is it's hard to understand that licenses sometimes if you don't have...

I mean, the volunteers, they may have limited knowledge about the terms of use and terms

of distribution.

So some of these reviews have been incomplete.

But despite this, we ended up, I think that we get a very easy sense.

We know that Falcon is missing information about 3M technology.

Their licenses have been modified.

They're not really compliant with the open source definition.

Grok, we know it's opaque.

Lama, we know it fails because of a variety of reasons, like lack of transparency, but

also it's missing other...

The license is not compliant.

But we know Alma, for example, they've been doing the right thing, and we expect it to

be a positive, passing the bar of open source AI.

By the way, they also released the data set.

And the similar is for PTA.

They're fully transparent, and they released the data set.

You can ask for it, and you can get it also.

But the issue remains with legal uncertainties around the world.

The other, Bloom, we know that we have everything.

It's transparent, but it fails because the license it uses for many of its components

are imposing restrictions and things like that.

So the concept of data information seems to be behaving exactly as expected.

And it's showing also that there is a very strong correlation.

Granted, it's a small sample, but there is a strong correlation between requiring data

information and having access to the data set to caveat those legal issues.

So I think it's working, and I'm not convinced that the alternative proposals are positive,

because the alternative proposals put PTA and even Olmo outside of the approved licenses.

And that is really not an acceptable outcome.

We cannot go credibly to either commercial partners, academia, and policymakers and say,

"This is the open source AI definition," and not have an answer when they say, "Okay,

which one is open source AI?"

And we cannot point at any examples, or we can only point at small, trivial academic

experiments as examples.

It's not going to work.

And it's not going to work because the industry and policymakers are already being pushed

to look at Lama and Mistral, and they consider those open source.

So if we don't come up with a counterproposal quickly, we will have lost an opportunity

here.

So what's next?

I really hope that we resolve these comments and we resolve this conversation around the

concept of data information with a release in 0.9, which we get support from organizations

that understand the principles behind it and validate it.

We started to get some positive feedback this week at a conference in Paris from Lina Gora

and publicly announced support for this concept, and others are coming in.

And then between July and October, we're going to have a series of release candidates with

trying to get more endorsements.

So there are two ways for you to help.

One is to look, keep on searching for systems that seem to be complying with the definition

0.8 or not, like complete, go on with the validation phase.

And yeah, and this is the timeline, and these are the things that we are, the places where

we're going to be speaking next and presenting and discussing with the community.

And as usual, try to join the forums.

I know I may have said in the past, also give us feedback through social media channels.

If you do that, please tag us because the algorithms on LinkedIn, some people are still

using X, et cetera.

We miss comments.

We miss the discussions.

They're very hard to find, and instead, the forums are the perfect place.

And of course, join the town halls because it's a time when we can ask live Q&A.

And with that, I will stop the speaking and see if there are any questions.

Well, I see that there's been quite a jump on the written form.

Trying to summarize.

Is there, do you want to?

Yeah, I think you all have voice rights.

You should be able to speak.

Do I have a path on the open source AI definition where Facebook's llama goes green on the list?

Yeah.

They release all of their training information, training data, and we can rebuild something

similar like that.

Yeah.

Yeah, exactly.

I got to say, conversations with commercial operators, I think that they tell me that

the secret sauce is actually in the training techniques because they seem to, that's where

the secret goes.

It looks to me, they tell me that that's where their secrets are.

How they score high on the leaderboards for benchmarks is how they train, and they don't

want to share it.

But I spoke with, for example, Lina Gora, they have this project called OpenLLM360,

France OpenLLM360, something like that.

And they've been training a system from scratch and they are releasing all of their information

and data, et cetera, because they want to do the right thing and they want to [inaudible

00:10:50] a model that is optimized for the French language.

So that other, and then they want to generate that collaboration on top of that.

So Honey Sabak comments that if we think the definitions settles on the training data method

must be open as well, then we may end up with few or no open source AI models.

It's one of the risks.

But also I want to point out that there is a little bit more than that.

The reason why I want to move on with the conversation, because it's a highlight how

complicated this is and how different from software this is.

On software, when you modify, you get access to the source code, you modify it and you

have to rebuild before you can ship it again.

So the concept of modification and studying are like that.

You study, you see the source code and you modify, rebuild and ship it.

For AI, you don't do this.

You can study just for the purpose to see if there are bugs you don't need to rebuild

or if there are issues, biases, et cetera, to evaluate a model around AI.

But for modifications, you have multiple ways of achieving the same goal without having

to retrain, which really is a much more interesting question to me than the debate about data.

How do we treat models that are fully disclosed, share their datasets, share the techniques

for the training when that training is fine tuning on proprietary models?

And I'll say more, that fine tuning is so deep that every layer of the neural network

has been rewritten so deeply that none of the behaviors and the benchmarks from the

original model apply to the retrained, fine-tuned model.

That is a huge question that we need to find an answer for today.

And it's been raised on the forum with an example of an AI system developed by Mozilla

to write captions for descriptions of images in the PDF.js tool.

And they mixed two proprietary models.

One is an object detection vision, computer vision model, and one is GPT-2.

It's a large language model.

We don't know anything about the training.

They have biases, etc.

Mozilla has fine-tuned these models, assembled them together to achieve a new system, a new

behavior.

It's that open source.

And they have released everything that they have done in a very reproducible fashion.

So what are we going to call this?

Is this open source AI built on top of non-open models?

Yes.

Interesting question.

Okay.

So, let's go back to the slides.

So, I'm going to show you a few slides.

And I'm going to show you a few examples.

So, let's go back to the slides.

So, this is the first slide.

And this is the second slide.

And this is the third slide.

And this is the fourth slide.

And this is the fifth slide.

And this is the sixth slide.

And this is the seventh slide.

And this is the eighth slide.

And this is the ninth slide.

And this is the tenth slide.

And this is the twelfth slide.

And this is the eighth slide.

And this is the ninth slide.

And this is the twelfth slide.

And this is the tenth slide.

And this is the eleventh slide.

And this is the twelfth slide.

And this is the thirteenth slide.

And this is the fifteenth slide.

And this is the sixteenth slide.

And this is the seventeenth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the seventeenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the seventeenth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the eighteenth slide.

And this is the twelfth slide.

And this is the twelfth slide.

And this is the twelfth slide.

to start the recording. Thank you. Yes. So welcome everyone to our biweekly town hall

for the open source AI definition process. And you can hear I've got a little bit of

a sore throat, but I'll hopefully be able to make it through. I will start. So these

are our community agreements that we have at every meeting. Some of you may have already

seen these. One mic, one speaker is about non-interrupting. Also when we get to the

Q&A, if you have multiple questions, please ask your question and then pause and let at

least one other person ask their own question before you ask a second question. Take space,

make space is a similar spirit. You know, just to invite others to share space with

us. And that some feel more shy and some feel more extroverted and everyone's voice matters.

Kindness is just that the work is hard, but we don't have to be. And just to remind ourselves

to be gentle and curious with each other, even when we disagree. Forward motion means

focusing on what's possible and not letting obstacles prevent the process from moving

forward. Similarly, solution seeking, just this work is very complex and it's vulnerable

to suggest a solution, but that is how we move forward. And anything else that people

would like to add to our community agreements for this meeting? You can say it in the chat

if you want. Okay. I'll continue. So yes, we are creating an open source AI definition

this year. And the current version is still 0.0.8. That's been the case for about a month.

And these are the pieces of it. Maybe Nick could drop the link to the HackMD page into

the chat because this is very hard to read. It just shows you the parts kind of as a map.

So we have a preamble. We have the four freedoms, studies, modify, and share as applied to AI.

And then we have the it's not circled, but we have preferred form for data information,

code and model. There's some description there. And then the current version also has a legal

thank you, Nick, has a legal checklist of what the licenses would be on the specific

components that would be required in those three categories of data information, code

and model. And what we're working on is versions. Yes. And we're open to comments. That's right.

And you can actually comment on that document. HackMD is a commenting platform. So what we're

working on right now is 0.0.9. And there will be some changes, a few changes. So in the

preamble, we are clarifying that recipients of the freedoms are developers, players, and

end users. So those freedoms of study, use, modification, and sharing. We are crediting

the Free Software Foundation for initially developing these four freedoms because crediting

people is a good thing to do. And so we're adding that in. And you can see in this larger

box how those freedoms are enumerated or described. The language should not be surprising to anyone.

And we did develop these four freedoms in a series of co-design workshops at the end

of last year. Also in the four freedoms, we are going to, in 0.0.9, underline that the

components must be free from encumbrance. That prevents any of those three user types,

developer, deployer, or end user from exercising the freedoms. So just underlining that, yes,

the four freedoms must be respected. And also if you're a little confused, you're not seeing

0.0.9 in these images. You're seeing 0.0.8. But I'm just indicating where the changes

will be. Also in preferred form, we are going to add

definitions which will be just a phrase, not a sentence, for the terms OSD compliant, which

is a requirement of data information, and OSD conformant, which is a requirement of

model parameters so that the legal requirements are clear. And the code components just need

to be licensed under an OSI approved license. So that's very straightforward. The code or

software can exist under those licenses. And the licensing and legal requirements are slightly

different for those other types of components. And so we're going to define what these terms

mean, compliant and conformant, the next version. And then, oh, someone unmuted themselves.

Please just stand by until the Q&A. If you have a question that you'd like to ask before

the Q&A, you can drop it in the chat. Okay. So the checklist. The checklist, we are in

the next version going to actually move it into a separate document. We realized that

in trying to create the definition and also to operationalize the definition in the same

process was a bit like jogging and juggling at the same time. And so we thought, let's

just focus on the definition. Let's basically the definition will stop at preferred form.

And then obviously operationalization of the definition is quite important. And that is

the checklist. And we're just going to separate those documents and also those processes.

One change that you will see in the checklist in version 9, and I guess we'll figure out

how to label the versions of these documents as well. But if you're not, we will figure

that out. It will be updated so that all the components are from the model openness framework.

So right now, if you look on the left, the data information components are coming from

the EU AI Act. So training methodologies and techniques, training, data scope and characteristics,

training data providence, etc. Those are not coming from the model openness framework,

which is a list of components from the Linux Foundation. It's coming from the EU AI Act.

And we just because of all the great work that the Linux Foundation is doing to create

an online compendium of AI systems and the openness of their components, we really want

to be able to rely on that for our own definition. And so we are going to use their component

list exclusively in our in our checklist. And I'll just read Stefano's comment, the

data information piece is going to look the same in 0.0.9. Oh, not because it's decided,

but because the topic is still being discussed. Okay, got it. So okay, so we're not yet. So

eventually, we will be transitioning over to model openness framework components. That's

not happening in 0.0.9. Thank you for the clarification. Okay, system validation. It's

pretty much the same as last time. So thank you to Arctic and LLM 360 for helping to identify

documentation, we found that it's really crucial to have creators help out with identifying

the legal documents describing the rights and permissions associated with the components

of their systems. So this screenshot of the progress and validation based on the process

of the review, which is being done by volunteers. And also the the results of that review so

far have not have not changed since last time. And yeah, we just find that we do need creators

to help provide documentation in order to to know whether a system would meet the requirements

of the open source AI definition. And Stefano's typing. I'll just wait for that if it's on

validation. Okay, pause. I'll read I'll read the comments if it comes up. Okay, so what's

next June, which we're almost at the end of through October, we do we want to obviously

complete the validation phase resolve comments and release versions 0.7.9. And then cut the

release candidate with sufficient endorsement, organizational endorsement. Okay, just keep

going. And this is our timeline, we had to update our timeline, because it ended at June,

I believe. And now we have to think through to the end of the project in October. So we

will be at hospitals for good in New York, both the UN event and the side event. We will

this is in July, I'll be doing a virtual event for sustain Africa. And this is to share the

OSAID and also to get further feedback. Let me pause and read what Stefano is writing.

The 0.0.9 draft includes a lot of small changes accumulated over two months since the release

of the previous draft, but all the pieces of 0.0.9 can still change based on community

feedback. Okay, that makes sense. Okay, so August, we'll be in Hong Kong for AI dev. And

September. Gosh, let's see if I can pronounce this correctly with my cold. Merdeala. Okay,

that's pretty good. And Buenos Aires. And then October, we will be launching the stable

version of the definition at all things open in Raleigh in the US. And then we will also

be doing a data workshop in Europe, in a city TBD. And the focus of that workshop, it will

be to write a policy paper to try to resolve some of these challenges with the sharing

of data sets. Yeah. Yeah. And as Stefano is saying, nothing is set in stone yet. Okay.

So yes, and actually, you've actually already seen most of these. Yep. The different events

that we're going to and when they are. So how to participate in this process. We do

share updates on the process and opportunities for volunteering also discuss issues of you

know, disagreement and difference of opinion on the public forum, which is discussed on

open source.org, which you can join for free, you do have to sign up just to prevent spam.

And then we have these bi weekly town halls, both for the this is one for the Europe, North

America and our Americas time zone. And then we have a second one. That is Europe, Africa

and Asia. So we cycle back between those two times. And then yes, if you would like to

volunteer a validation, particularly I think about volunteering we need at this point is

if you are the creator of a an AI system and would like to, you know, show that it is open

according to the definition that we have now, that that would be the most valuable type

of volunteer just because those are those are the those individuals that have this documentation

information most at hand. Yes, there's also a blog that we update and I can share that

and their summaries are shared every Monday on the blog. And yes, we highly recommend

the weekly summaries. So yeah, we will now do a Q&A. And what you can do is, I think,

raise, raise your hand and you can come off mute or you can just ask in the chat and I'll

read it like I've been doing throughout the meeting up to you. Love to hear your thoughts.

And for all those who who are not as familiar with our organization, Stefano, whose shots

I was reading is the executive director of the OSI. So if anyone was wondering why, why

is she reading aloud all these comments from this one participant? That is why he can't

participate live today. But that's why I was reading his comments. So yeah, I will just

be shy for a bit. Yeah, don't be shy. Yeah, don't be shy. You can actually click on the

microphone and speak or you can just chat as well. It's OK. Yes. OK. Oh, you're welcome,

Stefano. Yeah, thank you so much for coming. OK, yeah, go ahead, Gerardo, you can unmute

yourself. Hi. Yes. What's your question? I've been participating in several standard committees

on IEEE about the ethical use of AI and several AI definitions, and I'm finding that most

of the people I met there have not yet, do not yet know about this initiative and I'm

changing that. But I've been wondering if we don't need to push this discussion a little

bit forward with the scientific community, especially with certain researchers that are

dealing with this on several bases. I think I've covered most of the AI ethics discussions

that are occurring, but it seems to me there's more going on that probably we should be a

part of. OK, yeah, I may not be the person to respond to that. My primary role is or

my role is running the co-design process of the definition itself within OSI. But Stefano's

typing, but that sounds very, does sound very useful. And thank you for bringing those experiences

you had in other organization and standards making processes here. That's very, very helpful

to us. Gerardo, so we're working with several researchers and several organizations as well

and we would love if you have contacts with other researchers with whom we could work

with, that would be splendid. I just would like to highlight something because you mentioned

ethics, right? So even though, yes, ethics is really important for us, we want to see

open source AI being used for good, right? For the benefit of humanity. But ethics, as

the open source AI definition is concerned, is out of scope. It doesn't mean it doesn't

matter. It does matter that open source AI is used for the good, but it's just something

out of scope. I'm not sure if that clarifies your question.

Well, it's more on the way that for most of the discussions we are having, some of them

are about the age of tools and so on. There is a need for those groups to know a little

bit of the strains that we want to impose on these AI models to be labeled open source.

Because it's something, when you're talking about the ethics of using AI, that also brings

in the fact that the open source approach is more ethical in the terms of the way things

are constructed, in terms of the transparency, the sharing of knowledge. And one of the concerns

most of all of these groups are in is the issue of explainability. And probably that's

something else, but probably something that we should be addressing. The explainability

becomes easier when something is really transparent and clear and open source, more or less forces

you into this. And so it's more the other way around. It's not that this issue depends

on them. It's more that they, that's my part, they have to be aware of all of this.

That's a very good point. In fact, we are in touch with a few researchers around explainable

AI. And it's really, really interesting. So happy to connect with you. Thank you.

Thank you. Thank you. Does anyone else have a different question? Thank you, Gerardo and

Rick.

Hello, Anastasia. So I see a comment about how the data information piece is going to

stay the same in 0.9. Is that talking about how you're not going to change how you address

the topic of data and the availability of information about the data? And I guess I'm

curious about the general thinking since open data may not always be realistic, but it is

this potentially important piece. So I'm curious about the focus or lack of focus on open data.

I guess just in general.

Yeah, I would actually, Stefano, if you want to chat or come off mute, I would love for

you to answer that since it seems like you I mean, Stefano is is the leader on that particular

element of this. If he is on the chat. He is. Oh, but he is not. I see his. So I'm I

in the absence of Stefano, who made a correction on something in my slide. So obviously he

has information I don't. I actually can't give anything other than what he just said.

So there's two pieces of information shared. One one is that data information will not

change from output. Oh, Stefano is coming back on. Stefano, we were wondering if you

could answer. OK, I would still just love for you to answer Anastasia's question.

Did you want her to ask again? Did you hear it? OK, I know all he knows. OK, so then I'll

just continue. So there's two pieces of information shared once that data information will not

change from 0.0.8, the link to which Nick shared and also that the checklist will conform

to the MOF. So the way that I take that to mean. Is that.

Stefano, do you want to do you want to speak? I don't know if you're maybe you're not

know that you can speak. OK, it won't change only because the discussion is not complete.

OK, OK, OK, can't speak. OK, yes. So there will be there will be a shift to the components

coming from the model openness framework or MOF. And there may be I guess there may be

other changes as well, because Stefano is saying the discussion is not complete.

So maybe I can, Ximing, mirror. So there has been a lot of discussions around the data

information and I'll share a blog post as well that Stef wrote, which is very interesting

and also point a discussion topic that we have here. This is something that we're receiving

a lot of feedback and hearing the working group members also participated in those discussions

and to try to understand the role of data and data information. And this is actually

a crucial point of the open source CI definition. So let me just drop some links here and we

look forward to hearing more feedback on the discussion forum.

OK, thank you. And Stefano has just written, we may even remove the text altogether and

put a placeholder instead. And thank you, Nick, for that explainer link to the explainer

post on data information. I I'm sorry if that wasn't satisfying, Anastasia. That is that

is the level of response that I think we can give to you right now. But thank you for asking

the question. Does anyone else have a question? Yes, Gerardo, go ahead.

Just one more probably comes from the model we are working with, but I have an issue with

defining codes that trains and codes that trains a model and code that uses a model

of the same thing. And I think we should be splitting those and make it so that it's more

explicit to say that both parts are to be open source, first of all, because they are

probably not the same thing and and that most of the "open" AI things usually have that

second part of the code open and open source, the thing that uses the model to generate

stuff. But they keep close the code that was used to generate the model. And I think it

may be important to split and make it explicit that both parts are considered codes and they

are and they have to be open license and open source for the whole thing to be open source.

And something I haven't yet seen and why it's defined here as just one thing, but usually

it can become those two codes can be developed separately by different people on different

teams. And there could be, let us say, the temptation to license to open license one

and not the other.

Okay, so regarding the three kind of categories of AI systems, we have data information, code

and model, we are basically trying to have as few categories as possible that were still

descriptive of the different types. And obviously, there were other types of categorization we

could have used. That one seems pretty solid. In terms of the types of code, we are using

this maybe, maybe you're aware of this, and maybe not. This list of types of code components

or artifacts used to create AI systems, or used in AI systems from this model openness

framework that was developed by a group of researchers and practitioners at and affiliated

with the Linux Foundation. And we so as not to invent the wheel, because there's so much

that we are doing ourselves, we said, How can we rely on the brilliance of others. And

so we are using those code components. So we are we are not going to, I believe, change

those components as listed in this document. And maybe Nick could even share a link to

that it's a white paper is where those components live. Now, I think the Linux Foundation is

also spinning up some websites and landing pages. But as of now, I know that they that

you can find those in the white paper. So we are we're, we will just rely on that work

that they've done. Let's maybe take one more question. And then Yeah, you're welcome to

order. And then we'll call it a day. And Stefan, I was just saying we all care about open data.

And we're very concerned about the issue of accessing data suitable to train an AI, which

is true. Yep, absolutely. So, um, okay. Any, any other question from someone? I would say

another question from someone who hasn't asked one yet. And I'll just keep reading what Stefan

was saying, because he would be presenting with me if he were available. So he's saying

we're also planning a conference specifically on this topic, which is that event in October,

in in Europe in the city TBD is that comments or workshop on data, the issue of data and

AI, which is such a substantial one. Um, okay, I'm not seeing any questions. Thank you. Thank

you to everyone who came and who did ask a question that was really useful. Yeah, thank

you, Gerardo. Thumbs up. Yeah, so I think we can turn off the recording. And thank you

everyone for coming and have a have a wonderful weekend and do find us

So, first of all, let me introduce myself.

My name is Nick Vidal.

I'm the community manager at the OSI, the Open Source Initiative.

And every two weeks, we organize a public town hall about the open source AI definition.

The goal of this town hall is to give updates and news about what has been happening with

the definition and also to hear your feedback and see how we can make it better.

So let's jump to the rules, right?

What are some agreements that we have here?

I think we can all be very open and very kind.

The idea here, even though if we have any differences, we can agree to disagree.

And so this is especially important when I open space for questions.

You're free to ask any questions and I'll be happy to answer them as best as possible.

So let's talk about the open source AI definition and where we are.

We have been at version 0.0.8 for quite some time right now.

And the reason for that is that we received a lot of feedback and we are working those

details because the next one, the next version will be something much more stable and really

with very few changes going forward.

So the current definition, what we have right now is we have the preamble, we have the four

freedoms and a checklist.

Now what are we working for version 0.0.9?

There are going to be some significant changes based on this feedback and we're about to

release version 0.0.9.

It's just a matter of a final approval.

And we still have the preamble and we try to clarify who are the recipients of the freedoms.

We also have the what's open source AI and we clarify those four freedoms.

As you know, we have the freedom to use, to study, to modify and to share the system.

And for those who know, who have some background on the history of free software and open source,

you know very well that those four freedoms are from the free software definition.

And this has been very stable.

We have been using those four freedoms as the basis throughout most of the moment.

Now one observation that we're also making is that we are underlining that components

and systems must be free from encumbrances that prevent any developer, deployer or user

from exercising those freedoms.

So this is something that we highlighted for this version as well.

And now we made some substantial changes to the preferred form to make modifications to

machine learning systems.

And the reason why we did that, we received a lot of feedback and we wanted to really

make this as precise as possible.

So we added the definitions, right?

Also there's the question of OSD compliance and OSD conformance for each one of those

requirements, right?

And also the legal requirements for each components.

So we made this text here, the preferred form, clearer for us to understand.

And now this is a big one.

Since the definition is going to be something very stable, we cannot make, we shouldn't

make many changes with every version.

We want to have something very solid.

So this, the definition itself should not change much.

However, we know that the technologies are evolving very rapidly and there might be some

changes to the legal framework or to each one of those components.

And so what we're doing for 0.0.9 is actually we're going to make the checklist as a separate

document because the definition is going to be stable.

And the checklist, we might have some smaller changes, of course, but it's going to evolve,

right?

And I wanted to highlight that we use as the list of components, the model openness

framework.

This is something that was created by the Linux Foundation and they have 17 components

and we're using that as a basis, right?

For the checklist.

Now we are currently validating the open source CI definition, looking at several models.

Right now we're looking at Arctic, Bloom, Falcon, Grok, Yamachu, LLM360, Mistral, Oumu,

OpenCV, Fitu, Pythia, T5, and also I believe Vykan, we added that as well.

So the idea behind this is we are looking at the open source CI definition and looking

at the different models and different AI systems that exist.

And we are matching that, looking at the checklist and seeing if those systems are in fact, if

they achieve this, right?

If the open source CI definition applies well to them and we're validating this.

And so as part of this validation updates, here are the current results so far.

So looking at Arctic, for example, this is a large language model by Snowflake and it's

actually pretty good.

It's pretty open.

And we are looking at those different systems and for Arctic, we believe that it's expected

that it does, yes, fulfill the open source CI definition, all the checklists.

So it's very likely that Arctic is an open source AI, right?

Now we have other systems which can be a bit more challenging, right?

So Bloom, Bloom is regarded as an open model by some, but at the same time, they use Rail,

which is very restrictive.

It does not match the open source CI definition on that regard.

And if we look at all other models as well, we see that a few of them, the ones that we

expect to actually be considered open, in fact, they are, they are validating.

So for example, Omo, it's a very open and it's likely that it meets the open source

CI definition requirements.

And AlphaBifia, it's a confirmed yes right now.

So this validation process is important, right?

Now this, what's next?

What's the timeline?

What's happening?

We have this validation phase.

We are looking at the comments.

We're about to release version 0.0.9 after this validation.

We want to have a release candidate.

Also there's a guidance from the board and this is really important.

So the board has three requirements, right, for this definition.

It has to be supported by diverse stakeholders, right?

Also it must provide real life examples.

We don't want a definition that there's no AI system that actually matches that.

So it's important for us to have this, at least a few cases where those AI systems match

the open source CI definition.

They fulfill the open source CI definition.

And we really want to have this stable version by October, at all things open, where we're

going to be announcing this.

So we have this, this restriction on time.

We cannot just go on for this forever.

In fact, a lot of, there's a lot going on around policies and legislation around the

world.

And a definition, a clear definition really is really important.

So we're trying to run against the clock, right?

Basically this is a timeline throughout this past month, we've been attending several events

worldwide.

So July, right now we were in New York City for an event called Auspice for Good that

happened in the United Nations headquarters in New York.

And we also participated in Sustain Africa.

August is coming up.

We're still going to organize those online events, especially because not everyone can

travel, right?

And this makes it more accessible.

But we're going to attend AI Dev in Hong Kong.

This is an event by the Linux Foundation.

We're going to give a talk there.

We're also going to be in Northern Ireland, Buenos Aires.

So we want to make sure that we keep AI Dev will happen in Hong Kong, in Asia.

Northern Ireland, in Buenos Aires, in Latin America.

We just came from an event in New York.

So we really try to make this as representative as possible.

We're trying to organize an in-person event in Africa as well.

And I think we're finalizing that as well.

So we're trying to make the events as accessible as possible by making it online, but also

in-person events and representative of the whole world, right?

For October, then we have the All Things Open events, an important event around open source.

And by then, we hope to announce the stable version of the definition.

Also there's an event, a very small meeting around data.

But this is, we've been gathering mostly nonprofit organizations to be part of this meeting.

It's really small and it's fully booked.

So apologies if we cannot open it up more.

We will try to organize other events as well and invite people to be part of that.

This is the list of some events that have been happening these past months.

We were also in France for OW2.

And so you can see the dates here.

And this in-person events, they have been important.

We have been able to hear a lot of good feedback from everyone and really try to come up with

a definition that it has a lot of backing from people, right?

And so I would like to invite you to participate at these events, the events in person as well.

Also the public forum, you can go to discuss.opensource.org and comments on the drafts or any other topic

that you like to understand.

It's totally free.

You can join.

You don't have to join as an OSI paying member.

You can join as a free member as well.

And you have an access to the forum.

We're going to continue organizing this biweekly virtual townhouse.

And here is an opportunity for you to ask questions and try to understand what's really

happening, right?

Invite you if you want to volunteer for the validation process.

I believe right now it's the working groups are closed, but you can still email us to

know if there's still an opportunity.

And that's it.

So right now I'm going to open up spaces for questions and answers.

You can either ask questions on chats, if you have your microphone option open as well,

you can ask that question live.

And I'm available to answer your questions as best as I can.

>> I have a quick question.

Do you think there are only a few people on this call because there's not a release of

the .9 to discuss or sort of is that why this call is so quiet?

>> Yes.

So this is our 13th townhouse.

And so it has been we do this every two weeks.

And I think right now there's a high expectation for version 0.0.9.

We've been discussing 0.0.8 for quite some time right now.

And I think most of the questions around this version have been answered.

So people are really expecting a new version.

And highly so.

So are we.

We're just waiting for a final decision from the board to release the version.

I expect that we're going to have more questions around that.

>> Okay.

I have another question.

What about the events in Hong Kong and Buenos Aires?

Are there going to be more discussions, like presentations or more discussions or are they

panels?

Can you tell me any more about what's planned specifically for Hong Kong?

>> Of course.

Yeah.

For AI Dev Hong Kong, we're going to have a talk from Mare Joyce, who is the facilitator

of the open source AI definition.

And also from Annie Lai, who is the chair of the Linux Foundation AI and Data.

So they're going to give this talk.

And I believe they're also going to be available for any discussions.

I don't think we have a panel there.

Now for Buenos Aires, for Nerdiarla, there's going to be I see that there's a yes.

So we're going to have a presentation by Mare Joyce and staff.

And are we going to have a panel there or a I believe we're going to have a workshop

as well.

This is being confirmed right now by Holo, who is organizing this.

Yeah.

We're going to have a workshop as well.

It's very likely we're going to have a workshop there.

And it's this event in Buenos Aires is pretty huge.

It's 10,000 participants.

And very well organized events.

So I highly recommend it as well.

Anyone has any other questions?

Of course.

Yeah.

So let me share the link here.

Oh, thanks, Holo.

Holo has already added that.

In fact, Holo is one of the organizers of the events.

The leading organizer.

If you'd like to reach out to him directly, Holo, maybe if you could base your email

or all right.

Yeah.

Feel free to reach out to Holo regarding the events.

All right.

So if there are no other questions, this is going to be made available, the slides and

the recording.

I'm going to be basing this on the forum.

And thank you so much.

We really appreciate it.

And we look forward to your feedback on the forum as well.

All right?

Have a great weekend.

Bye bye.

Bye bye.

Bye bye.

I don't... oh now it's being recorded. Okay. Yeah. Okay. So now we're being recorded.

This is the Q&A session for those who are watching the recording. The

presentation has already occurred. Yeah. Sounds good. Nick. Nick is commenting. He's

going to record the Q&A. I believe Stefano will be in Vienna. I do not know

if there will be a workshop or session on the OSAID, but I think Stefano will

be in Vienna personally. Yeah. It's not on my official list, but Nick maybe you have

some information about that. Oh he will be presenting, but not giving a workshop.

Okay. Thanks Nick. All right. Oh okay. Yeah. She and I presented today as I

mentioned earlier. I don't know if people in the recording can see the chat, but

we're just saying that Stefano is going to present with Annie Lai of the Linux

Foundation in Vienna. Yeah. I'll hang out here at least till the half hour to chat

with him, but the formal program has ended.

And Nick will also hang out.

You're welcome.

Ah could I share a bit about my presentation in Hong Kong? Yeah. So it was

those slides that you all saw. I guess it's not I can go back so it's in the

recording, but these are the slides. This is what it what it was called unveiling

the future nurturing openness in AI development, which was Annie's creation.

And Annie talked about the Linux Foundation generative AI Commons

projects, the model openness framework, and the model openness tool. And then I

spoke about the OSAID and specifically talked about not only version 0.0.9

which you saw, but I also spoke about the co-design process both creating the

for freedoms for open source AI and also identifying the required

components using our virtual work groups. And that's been covered in past

workshops. But that was the that was what I presented in Hong Kong. And then

Stefano was also there and so he participated in the Q&A and that was

great. What was the questions? I think there was there was a question about AU

policy and the feasibility of implementation. And then there was a

question in Chinese and Annie fortunately speaks Chinese. And I believe it was

about there were two. One was about the legal implications of the definition. And

the second question was about just asking for why why use open source AI?

Why make a system open source? And so Annie reiterated the benefits of openness

for AI. So yeah.

Oh, loss of connection.

I think I'm still I can still see you chatting. Okay. It said I had lost

internet. Okay. Early impressions on the new, so I'm just going to read Martin's

comment. My early impressions on the new data requirements in 0.0.9 have been good.

Okay. It seems to do the best with a complex situation. We'll keep thinking

about any loopholes. Thank you, Martin. That is basically what we have also

found is this is a compromise. There are people that wish that the definition

were more stringent and there are people that wish it were looser. So there's pull

on both ends. But that's probably some symptom of a compromise. So yeah. I'm

glad that you're seeing that too.

Okay. If training data had been required, how many models would have met that? Yes.

So I think there would have been a few. I think Olmo I think might have met it. I

think the concern was about the legality of the data that there is a risk of

lawsuits or of the data being legally shareable in certain jurisdictions but

not others. And that we wanted to have a definition that would have a global

could be implemented globally and that systems wouldn't be hung up on or be on

possible legal actions. So that is my understanding. And Nick, feel free to

yeah there you go. Olmo and Pythia. Yes. Right. Yes. Yes. So there's a nice forum

post about yeah I could try to find it that talks about the legal

uncertainties of training data and how that could make it helpful to people who

want access to AI open source AI systems to simply pull that X factor out of the

requirements.

See if I can find those.

Maybe. I don't think no it's not something that I wrote. I think it was I

was something in June. Anyway I was reading it this morning. Oh yes

explaining the concept of data information I think it might have been

that one.

Yeah so yeah this is some someone called Sen Ficon. People can be pseudonymous

in the forum but it's just I'll just copy and paste it. It just felt very

clear and well written. This is just a part of that person's post. And that's

the link.

It might be Felix. I don't know. Could be.

Oh great. Thank you. Thank you to Felix. I've actually heard about Felix and

didn't know that this was what he'd written. But yeah it's very good. Very

well put. What else? What are people thinking about? Anyone to chat about?

So there are a couple folks. Maybe not both. There's at least one person on the

call who is from META but I won't ask them to represent that affiliation

unless they want to. But so the answer is yes they're on the call today. And if

that person wants to say anything they're welcome to but they don't have

to say anything if they don't want to.

Mm-hmm yeah for future LLAMA models. Yep. Yep. Do you want to ask? Yeah you can put

the question out there and the person can answer or not. I imagine it's

something they're discussing internally.

Yeah anyone who hasn't asked a question or participated in the chat.

Ralph or DB, Gerardo,

Toka.

Yes Nick that's yeah that's correct. Yeah the current

version of LLAMA does not meet those but they could in the future.

That would be great.

I see Martin is typing. Nick.

I guess is everyone else who's still on the call

is there anything else that you'd like

to me to cover? Anything else you'd like me to talk about?

Nick is just writing a clear definition will help organizations

to make a choice as to whether they want to release an AI system

as an open source AI or not. Okay yeah.

Okay Martin is saying hoping if any indications made about

if in desiring to conform but it sees not yet and it's obviously

fine. Yeah I imagine it's their conversations happening internally.

Releasing smaller models that do miss the OSAID.

That's one option. Yep.

Yep.

Yes that's well put. Nick is saying a clear definition will help guide

policymakers around the world and that was

the reason that we started this in the first place. I actually wasn't even

there in the beginning. Nick was there and Stefano was there.

The board was there but yeah that was the goal for doing this is to have

something clear that policymakers can rely on globally like the

open source definition currently. Yes and the EU AI Act is

is one clear application of this work.

Okay I see people dropping off which is fine. I think I will do a last

call for questions or comments.

And then

okay

Oh you posted on the forum. Kitty I'll post on the forum.

Okay discussing a forum post.

I'm not sure if folks have read it. I would say ideally

this is your opportunity to click on that link that Kitty has

just shared and take a read and comment

on his post. I think that's probably the thing to do.

Yes and thank you for participating in the forum.

Thank you.

All right I think let's call it Nick. Yes beautiful perfect.

Yes Nick has just dropped the link to the

forum and I guess we can turn off the recording and

Nick if you could hang out for a minute I just wanted to ask you something.

Let's start recording our session and get started.

Welcome, everyone.

This is our new format--

well, slightly new format in the sense

that we're going to be doing these town halls now weekly,

going into the session, going into the final stretch

before we have the open source AI definition reviewed

and approved by the board at the end of October.

At the board meeting that we have scheduled then.

So a quick reminder of our rules of engagement,

our community agreements that we call them.

This is our rules.

We want to have--

making sure that there are no overlaps

and people keep space for speaking and listening.

So take space if you are shy and tend not to speak.

But also, if you tend to speak a lot, take a break.

Consider others and ask questions.

Give space for others to come in and give their own things.

Be kind.

And the ones that I look always with in mind

is the think about the fact that we want to continue moving.

We can't stop discussing for too long.

We need to notice the places where

we have disagreement or difficult, complicated issues.

Maybe put a note in there and get back to this later.

And always look for solutions.

Listing the problems is OK to start the conversation,

but moving on.

And so let's review for-- this is the first time

we do this at this time of the week.

So you may have not seen the new version that

was released a couple of weeks ago, version 0.9.

We have presented it in--

I mean, we were in China with Mayor Joyce when this came out.

And basically, the principles haven't changed between 0.8

and 0.9.

The principles are that we want to have-- for an open source

AI, we want to have three kind of components

that can be grouped into three buckets.

The weights, the parameters, the architecture,

anything that is related to what we

call the model in machine learning

needs to be made available under--

needs to be made available.

We'll talk about the conditions for openness or availability.

The open-- the code used to train the system

needs to be made available also.

And also, you need to have a way to run the model,

run the AI system.

And then you need the data.

Everyone understands and agrees on the fact

that the data is where the parameters, the weights come

from.

And you need the data.

And the coalition, the group that

has discussed for many months how to solve the--

how to pass the big boulder of data

being many things in different legislations of the world

came with the description of the data, the requirement

the data has sufficiently detailed information

about the data used to train the system.

And that includes either the data set itself,

when it's possible and legally plausible to distribute safely,

or in alternative--

and also-- not in alternative, but also--

also the code with the full instructions

on how to replicate that data set.

And that includes the scripts to download the original data

and content, the code to run all the interesting--

all the interesting manipulation to go from the raw data

to the training data set.

And so the definition itself has the text

of what is required in a paragraph titled,

what is the preferred form to make modifications

for a machine learning system?

And describes the weights and gives some high level examples.

These are not-- this is not text that is strictly correct,

always--

always the-- always valid for every possible--

very strictly prescriptive about every possible system,

every possible kind of technology

that we can see today or available in the future.

These are examples that are useful to interpret

the actual meaning of the words above.

So for the model weights parameters,

that might include the checkpoints, for example,

if the training in the system is a large language model,

for example.

From the code perspective, it's the source code

used to train the system.

And this includes all the pre-processing code,

the training, the validation, the testing,

how it's been done, the supporting libraries,

and all of that code software.

And this, obviously, need to be made available

with open source AI approved licenses.

And for the data--

for the database, again, there is a-- this

is a little bit more worthy.

The intention here is that the open source AI,

the developers of open source AI,

must be sharing with others all the instructions

and all the knowledge that they have on how they built.

That's the intention.

The intention is to make sure that open source

AI carries the same meaning and the same practical values

that the open source software definition carries.

You need to be able to understand--

you need to be able to understand

how the system's been built, its intention, et cetera.

And you need to be able to learn from them,

from the original developers, and build on top of them

without having to reinvent the wheel or try to guess.

Maybe this thing has been done this way,

so I can improve it by doing this other thing.

No, it's building on top.

And this is where the--

building on top of what others have built,

one of the basic tenets of open source.

But we do have spent--

I mean, the community, and together with the--

also with the board.

And we have reviewed a lot of the comments

that we have received in the past.

And we have clarified also that we do have--

there is a-- we do have-- we do care about data.

We do care about the availability of the training

data.

We do know that the training data

is valuable to understand and study the AI systems.

And we also want to acknowledge that there

is different kind of data.

There is data that computers share,

and that would be--

make sense to always have open in terms of openly accessible

and as open data, following the definition of-- maintained

by the Open Knowledge Foundation.

But there is also training data that is simply public,

cannot be redistributed.

And that is basically the whole of the whole internet.

And where you have the right to crawl and build indexes on it.

This is one of the basic rights that Google

has had as a search engine for forever, since its existence.

And we need to continue to acknowledge the fact

that while search engines can crawl the internet,

they don't have the right to redistribute

what they have crawled.

But they have the right to offer the public

some new and transformative activity, actions,

and services.

So this is the same thing.

This is the concept of public training data

that is publicly available.

And then there is private data, which is another category

of data for which you may have the right to train on,

but you don't have the right to redistribute.

And so a reminder that we are working

within the constraints of the policies

that the board has set as criteria to have a definition.

The board wanted to have--

would ask us to work with the community

to understand, to have a definition that

is supported by a large coalition of individuals,

organizations, and groups with globally representative--

so a sample that is representative

of global communities, but also represent

various different interests.

We're not just representing the interest of research

and academia of individual developers,

or large corporations, small corporations,

European corporations, or governments

from other parts of the country.

But it's the whole--

we try to be as global and diverse as possible.

The other constraints that the board set for us

is that we need to provide real-life examples.

You can't really have a definition

that defines theoretical models, theoretical systems that

don't have any application in practice.

It would be not acceptable by the board.

And we also wanted to set a deadline,

because it's a hard deadline, because otherwise--

because the world needs this definition soon.

And it's better to have something

that is done rather than perfect.

So what's next?

In the next few months, we are working

to really solve the comments as they come,

and maybe release in the next weeks, couple of weeks,

release candidate version.

And then get a quick feedback with the top organizations,

groups that have worked in the process

to gain their endorsements, gather the last comments,

and march towards a stable version for all things

open on October 27.

So we are seeking now--

we're at the stage where we are seeking the comments

from individuals and organizational endorsements

for--

comments and endorsements for the draft.

So if you have--

if you're ready to say, yeah, we're

ready to endorse these principles,

just send us an email.

And you can email me or you can email Claire.

I've been assisting our project.

You can get in touch with Nick.

You can even go public on the forum already as you prefer.

We want to have--

we need to start moving.

We are already at the first week of September,

and we have only six weeks of time

basically left before we finish the process.

And yeah, we've covered a lot of space, a lot of time

over the months.

We've been traveling quite a bit.

We're trying to be presenting in many parts of the world,

presenting and discussing with the community

to make sure that there are the least amount of surprises

by the time we issue the version, version 1,

stable version in all things open.

I can also give you a preview.

You see here in October, there is--

we have two events scheduled.

One is the all things open launch,

but also there is a workshop that we're

organizing for around specifically about the issue

to discuss and understand better the space of data governance

distribution, et cetera.

We'll have more details this coming week made available.

And this is all thanks-- all the travel and all the--

and the workshop that we're organizing in Paris

is thanks to a grant, a large grant given to us

by the Alfred P. Sloan Foundation.

So how to participate?

You can definitely still email me or Mer,

the preferred for the endorsements.

You can also send public comments

on discuss.opensource.org.

Can definitely signal that you appreciate

the stewardship and the role of the Open Source

Initiative in driving this process

by becoming an OSI member.

You can also donate as you become a member.

And you can join these downloads that--

realize this slide needs to be updated.

Coming-- there's-- there being--

there being-- they're opening now weekly at alternating time.

One week is going to be at this time.

One other week is going to be at 9 AM Central European time

so that the Asian community can join.

And now-- yeah, now we've got time for Q&A.

So a comment from YouTube, an open AI

should prove that its training data is all legally licensed

open source data.

Right, so this is a very interesting question

because it's a frequently asked question, actually.

And so it's been debated for many months.

The short answer is that legally licensed open source data is--

is a-- is a big--

is a big-- is a different--

is a different set of what you think it might be.

And we may want to qualify.

So think about the fact that Google Books, for example,

has built a product built on legally--

legally acquired books, scanned, and done object character

recognition on it, and created a transformative work,

and was sued.

And then they won the lawsuit.

Makes me-- makes us think that the concept of training data

legally licensed open source data

is something that needs to be--

needs to be clarified.

So it's a gut reaction that we all go towards.

But we need to think about the consequences.

It's a big-- it's a big topic.

And that's why we're hosting that conference in Paris also.

So Joshua.

Hello.

This is Joshua.

So in the latest draft, I've been

spending most of my time really trying

to think through reading the definition

from different viewpoints of users, especially

a developer viewpoint.

And so I've been really digging in and thinking about

if I'm using Protobuf or TensorFlow

or these other common frameworks and formats for AI models, what

my world view looks like.

And one thing that really stands out to me

is that generally speaking, we're

gravitating towards these binary formats as what

we understand as the model.

And this is different than the abstract kind of approach

to thinking about what an AI model is in general.

It's, in a sense, broader than the AI model,

which is more narrow, which is counterintuitive.

You would think it would be just the opposite.

And the reason why it's somewhat broader

is because these binary formats allow

you to do a lot of things that go perhaps

beyond what you would normally think of as part of the AI

model.

But when you need to identify in your code base what

is the model, you point to that file.

That's the model.

And so I think that there's going

to be some gap between a lot of people's

intuitive understanding of what the model is

and what the intent of the model is by OS in this definition.

I think it would be helpful to put a little bit more

in the definition.

In the online feedback forum for the latest definition,

I added some comments specifically around this idea

that you should be encouraging you

to be explicit about saying that you should not

use the AI model as a way to pass through, say,

binary blobs or object code.

And the reason why I sort of came to that conclusion

is because I was looking at real examples

where people were using things like Protobuf and other--

in TensorFlow and using variables that just

store data effectively as part of their training.

So they're just storing verbatim blobs of information

that are then used as part of the program.

But it's that interaction, but it's stored in the model

from their perspective, from the user's perspective,

and in the documentation.

So I think it would be helpful to have a little bit more

nuance in the definition to clarify that a trained model is

not the same as merely storing files that can then be reused,

that it should be about a little bit more detail around that,

just to help abuse of the open source AI definition.

I think-- yeah.

So I'm not sure I understand exactly--

in fact, I was emailing you to have a conversation

to clarify what you actually meant.

And I'm glad you came for this and explained it via voice.

So I'm still a little bit puzzled

by the technical details here.

But the general principle of the definition

is that it must resist as much as possible the test of time.

And it needs to set high-level principles at this stage.

If you want to have a mental map to frame the intention here,

the open source AI definition file,

the way you see it linked in the chat,

is the page that the FSF, the Free Software Foundation,

hosts and calls what is free software.

It's the basic principles that we

want to have represented in a view of the world, what

needs to be achieved.

That page has gone through multiple iterations.

Like, if you go below and you read it,

the initial freedoms were three, and then a fourth was added.

And wording has been changed on that page to clarify.

But the principles, what is free software, those three,

and then letter four freedoms have pretty much

remained the same.

What has changed and has evolved and derived from that

is the open source definition, which

is a sort of a checklist to evaluate,

in practical forms, software packages used by--

in order to be included in the FTP servers at the Debian

project first, and then became the open source definition

that are currently used, those 10 principles,

to evaluate the licenses and legal documents.

We want-- we're trying to do the same thing here.

The open source AI definition is what is free software page.

And then the new split document, the checklist,

is more of those 10 points practical interpretation

of, in practice, of what will have

to happen for an AI system to be judged, evaluated,

to be respecting the original intention written

in the definition.

So what I would recommend is that we

spend a little bit more time, collectively,

to think about the interpretation.

Instead of making the first document longer,

we could be spending a little bit more time

to refine and review the-- and we

have more time with another set deadline

to finish the checklist.

Make that document a little bit more rich.

Bentley?

Yeah, I noticed this definition doesn't

mention content generated by models

under an open source license.

This might be much a bigger question,

but is there a plan to address the content generated

by an open source model, how that will be licensed,

or is that part of a much bigger discussion?

That's a good question.

So the jury's still out of what are the legal ramifications

for that part.

But definitely, the definition does not

touch that the same way that, more or less,

the open source software definition

doesn't say whether you can use a C compiler to build

malware or other things like that.

It's a separate-- it would be a separate conversation.

There might be legal documents that

say you cannot use this model, this AI system,

to create--

to infringe on someone else's copyright

or to invent things that have already been invented

or do other things.

But that's something that will have to be evaluated

by the legal community.

[AUDIO OUT]

- I have a question.

Can you hear me, Stefano?

- Yes.

- By way of introduction, I'm a tech attorney.

I've been practicing for 15 years.

And for better or for worse, I've

done a lot of work in the open source space.

The one question I had is, at the top of the call,

you went through the definition.

And you explained that there are three parts to the definition.

Is it fair to state that the first two

parts of that definition have not generated

any controversy versus the third?

- Yeah.

Well, not completely true.

So the first two parts, meaning the model weights

and parameters, and the second part--

- And the source code.

- --the source code of--

so there has been debate.

And there will continue to be a little bit.

In the legal community, I believe

that the legal nature of the weights parameters

is still being debated.

Some legislations may not consider those subject

to any exclusive right.

And whether they should be considered

under any IP law or other exclusive rights

is to be debated.

It's not ferocious debate, but it's an intellectually

stimulating one.

And on the code front, on the source code front,

there is debate over whether the training code should

be strictly required or not.

And there is a little bit of a push and pull.

I've heard rumors about that requirement,

strict requirement, as being a little bit too limiting.

Too limiting.

- Got it.

But just to clarify, the third component of the definition,

with respect to the training data,

is the most controversial.

Is that correct?

- Yeah.

Correct, yes.

Because, yes, instinctively, all of us,

at the beginning of the process, everyone had the same thought.

Data is where the weights come from.

Some people use the term source, which is confusing.

It's not source code in the same way.

But it's where it comes from.

If without the data, you don't have the models.

You don't have the parameters.

And therefore, given that requirement,

all of the pipe, the whole pipeline

needs to be open and open source.

But data is not source code.

It doesn't fall under the same easy, air quotes,

legal framework.

It's a whole different beast.

And realizing that became the big boulder

that we had to navigate around, find a way to navigate around.

- Got it.

Thank you.

That's very helpful, Stefano.

And I apologize.

I have read a bunch of the comments on the various versions.

But obviously, I don't have the full history here.

And nobody knows this stuff better than yourself.

Did OSI, at any point, consider using different words

to describe models that would fit within this definition

rather than open source as a way to resolve

the complaints from various members of the community?

Was that considered as an option?

- That is a very awesome question.

That is a very awesome question.

It was one of the very first questions,

is what we're going to call this thing.

And yeah, I'm on the left.

But yes, unfortunately, though, our hand

was forced by the fact that open source AI, as a term,

was already being used.

And even abused by some players.

And I can be public about it, because I've

been public about it.

Meta is one of the abusers of the term.

They keep on using, referring to open source AI.

So in order to safeguard open source, the term itself,

we don't have another choice but to call it open source AI

and work around it.

- Thank you.

That's very helpful context.

That's all I have.

- Yeah.

I see Joshua typing.

Are there any other questions from the Mozilla group or YouTube?

Josh, I see you typing.

Feel free to grab the mic.

- Thanks.

Yeah, it was just sort of a follow up.

My point is that, in principle, we

know that when training a model, that we

know that when training a model, that it gets trained on code

at times.

Some of the data is code.

Some of the data is object code.

We know this because GitHub and other things

are often used as the training data.

And we know that models sometimes make use of just

verbatim storage.

Instead of taking the data and trying to learn something

from it, sometimes you just save blobs of data in your model.

All major models, model formats, TensorFlow, and so forth,

have facilities for doing exactly that function.

TensorFlow Save Models has a bunch of things.

Protobuf has options.

And I don't think, in principle, that is not what you're saying.

You're not saying that training can be taking data,

like an object code blob, storing it in the model.

And then when you build your AI system and you use the model,

copy that data, load it into an executable area of memory,

and run it.

Now, if I'm building consumer electronics, though,

and I'm sending updates using my model, which

is going to be an increasingly common paradigm, given

the fact that we have just huge amounts of AI hardware being

put out there, then it would be an attractive thing for me

to update my platform via that AI model.

And some of the things I'll put in there are, yes,

they're technically trained.

They're trained to say, here's a lookup table of what

should be executed when the system initializes,

the AI system.

And I think it would be good to just draw a bright line

and say, no, you can't just say that--

you can't just move something technically

into what is the model and get around these principles

that we're making clear.

And that's the same thing as if you

were to move that code elsewhere in your AI model.

I see your point.

I see your point.

Now, it's more clear.

But I would recommend that we go back

to the reason why we put, at the beginning of the document,

the definition of what is an AI system.

Maybe that helps.

Because if we go back to the definition, what is the AI

system that we are defining in this work, in this document?

The AI system is anything that, for implicit objectives,

given an input spits out an output.

So whatever you call that, whether you package it

in a binary that loads a blob and executes

a virtual machine that executes something else,

if what we're calling here is what we're defining

and what we need the corresponding--

the preferred form to make modification of

is whatever that system is, however it's packaged,

however it's shipped, whatever it ships.

So when we go into the implementation,

some reviewer who wants to--

someone like, I don't know, the Linux Foundation

wants to--

may want to have a requirement some day,

maybe will have a requirement that says,

we only accept AI systems in our projects that are open source

AI following the definition of DOSI.

Then they will have a standard set for specifically

that technology, the same way that they have the model

openness framework now for the generative AI models.

And in that place, they can put all of the requirements

specifically for that technology to say,

nope, that loading of that binary

here is not a good thing.

It's basically a workaround.

It's not acceptable.

Or we'll have to wait and see.

I mean, another way, another approach that we could have

is to wait and see what--

if this threat that you have in mind

is actually going to show up.

It's not just a theoretical threat.

If it will be showing up, we're thinking one of the tasks

that we have to do by the launch is to really come up

with suggest recommendations on how we're going to be

monitoring the efficacy, the adoption of the open source AI

definition, the availability of other--

availability and reviewing of the existence of open source

AI systems besides the initial ones that we have identified,

which, by the way, are the ones released by the Eleuther AI,

Alen AI Institute, LLM 360, and most likely,

DII, we're working to understand those better.

So those are the ones that pass the open source AI definition

right now.

Thank you.

I see.

Yeah.

Ben?

So when a company modifies an open source AI model

for commercial use, at what point

does the modification become a derivative work subject

to the original license?

And would existing legal tests around open source licensing

be sufficient to determine the AI model modifications

and the derivative work aspect of it?

Or do you foresee a whole new level of legal guidance

needed with regards to these type of things?

Yeah, that's a very good question.

Frankly, lots of it depends on what the models themselves

are considered under laws.

Because right now, yeah, it all depends

on what contracts get built around them

and how those propagate between--

all the rights propagate between this new artifact,

the trained weights, trained parameters, to derivatives.

Yeah.

Not easy.

So there is a conversation now happening on the license

review mailing list, which is the community of volunteers

who've been reviewing licenses, software licenses.

And they've been asked to consider

how to handle licenses and other legal documents that

are not covering software, so the traditional space.

So if you're interested in joining that conversation,

I would highly recommend to join the license-review mailing

list.

I see a question from Peter.

Other non-profits in OSI ecosystems,

like GNOME, Alliance Foundation, Physotek Foundation, et cetera,

have any of them attempted to independently define

open-source AI or provided input to OSI about OSI's definition?

Oh, Peter, yeah, this is a great question

because it allows us to explain a little bit more

what the process has been.

So this is not OSI's definition, the same way

that the open-source definition is not OSI's definition.

We merely maintain it for the community.

So we have worked from the very beginning with Linux Foundation

and FSF and others, reached out to them

and asked them to contribute to the definition.

This definition is not written by us.

It's written by a process held by a co-design process.

It's a process designed to work with the people affected

by the decision, not for them.

So yes, all of these organizations

mentioned, plus many others-- Creative Commons, Eleuthera

AI, Mozilla Foundation, many other groups

that have participated to the list.

And we have somewhere on the website,

opensource.org/deepdive, we have a list of the groups

that have been-- and the volunteers that

have been included.

, All right.

Are there any more questions?

[AUDIO OUT]

OK, then.

I'm going to call it a day, call it a week.

Thanks, everyone.

This has been very useful, very interesting for me.

I hope it's been informative for you, too.

And I would like Nick is saying on the chat,

our discussions continue on our forum,

discuss.opensource.org.

And the license review working group is available.

Peter, stay on the chat here.

I will send you the link where to join it.

It's old school, meaningless.

Thank you, everyone.

The open source AI definition came out at the end of August with a new version

009. This is made of three main elements. It defines machine learning, open source

AI. The preferred form for making modifications is tied to the concepts of

machine learning. Because this is the technology that

requires a little bit more thinking because it has

this concept of trained models, trained weights and parameters. So the

weights are defined as the model weights and parameters made available under

open source initiative approved terms. And then there are

examples. Here what's important is the fact that we're trying to be vague

enough but signal precisely the intention. So the vagueness is because

we want to make sure that the text can resist time. It doesn't have to be updated

every time a new technology, a new model architecture, a new AI technology or

technique gets pushed out and made available. But also we want to use

the text so that the intention of the drafters is clear. The examples

provided are just part of the definition and they need to be

read together to understand it, to evaluate whether that signal, that

signaling of intention is clear enough. That should be clear. So from the source

code requirements also, this is a space that we know a lot more about.

Like what is the source code and how to deal with all the licenses etc.

But what's important here is that the requirement to release the source code

used to train the system. So one needs to be able, one who releases software

needs to be able to understand, one who releases an AI system needs to share all

the instructions, details including all the software used for training,

for validation, for testing. It's very important because that's the part where

collaboration can happen and improvements can happen iteratively.

And data information from the data front, the text here hasn't changed yet.

Although it's still quite convoluted and complicated, it could be refined. We'll

talk about that later. It needs to deal with the fact that laws are

complicated. And so this, again, the intention here is to give whoever

receives the software enough of the code itself and the datasets or the

provenance of the data so that the science can continue. And then also

innovation can keep on happening, building on the shoulder of the giants

exactly like it happens with the open source software where you don't have to

reinvent the wheel. You can build on top of someone else's work. So when

we released the version 009 of the open source AI definition, we

also released text to explain why the data set is considered, the release of

the training dataset is considered a benefit and not a requirement. It's

because training data are covered by laws that limit the resharing of the

datasets because of privacy rules, but also copyright law and even other

legislations like indigenous knowledge is not protected with copyright, it's

protected by other rules. And we need to take that diversity of legislation into

account and we need to make a difference between open training data, public

training data, and private data. So all of these have to be covered in a

different way, have to be treated differently because they are

different. And so the other thing worth reminding everyone all the time is

that the OSI board has set some basic criteria to approve the open

source, the results of the co-design process. We presented these slides a

couple of weeks ago in China, but the board requires that the

definition is supported by a diverse type of stakeholder and by

diversity it's listed not only into interest groups like users, developers,

deployers, subject of AI, but also geographic distribution. So we don't

want to have only Europeans or North Americans or South Americans, etc. We're

making an effort to go around the world to disseminate this work

and gather approval around the world and this is thanks to a grant from the

Alfred P Sloan Foundation. The other requirement is that the definition needs

to provide real-life examples. So once approved we need to make sure that

we have systems that we can point at and say these are open

source AI. And right now comfortably we can say that the

complying systems are PTI, the set of models released by

Yale AI Institute and LLM 360 and TII also. So non-profit research

institutions who have released the large language models and similarly

powerful AI systems. And we need to be ready by the October board

meeting that will happen on October 27th in North Carolina. So let's go through

the relevant comments that we have received this past few days on the

forums. We had Alison Randall basically requesting to be more

explicit about the requirements. This is a fair request. The text

tends to, the text of the definition tends to be more vague, to leave some vague

words in there. Like I said before, the intention is to be vague enough but

signal clearly the intentions. So it's worth rereading the text to

make sure that those intentions are clear. And especially one of the

intentions that Alison points out is the requirement to be explicit about

allowing, adding requirements the same way that the open source definition, the

classic open source definition allows for some requirements that are considered

to be good. Like a requirement for copyleft, you know, the persistence of

propagating the rights to downstream users is something that needs to be

evaluated. Whether the text that exists today allows that or if the text is

too vague and doesn't allow for that propagation downstream.

Technically, also legally, we need to understand how that can happen but

that's a different story most likely. Also be explicit about the fact that if the

training is done on public data, so data that actually can be distributed, there

are no exclusive IP rights, no natural exclusive IP rights. Like content created

by humans are, they always will have, I mean most parts of the world will have

copyright or civil rights, due to in European continental and moral rights.

But that doesn't mean that, for example, temperatures of the ocean, that

kind of data, that information doesn't have any right naturally. So

we want to consider that. She also suggests renaming data as source data.

This is something that I'm personally skeptical about. I would love to see more

people leaving comments on the forum because there is no, I mean, so data

is not source. Source is the word that has been traditionally used to

signal the source code or the preferred form for making modification to the

software. It's also mentioned in the original open source definition as such

and data is not the source of the training, training the outputs like

the weights and parameters. So I'm less reluctant. I mean it's called

training data in literature. So anyway I'd love to hear more comments

about this on the forum. And speaking of that concept of source as data, an

interesting comment received by a person, Professor Leon, he's a professor at

Stanford University. He made a good comment on the document on the

text. He's saying that the data is basically the data set is the output of

the processing of the original data and he's arguing that it's a lot more

important to get access to all the scripts used to build the data set

rather than the data set itself because the data set is not very comprehensible

without the code. And it's an interesting comment because it

really gives you, changes the perception. The data set is more like a

binary of the original data. And the source code is actually the code used

to create those tokens. So a very interesting comment in there and one

that might require also some refining, fine-tuning of the text of the

definition. Then we have comments on, we have received comments on hardware

considerations from Mariana Taglio and Alison Randall. This is an area, hardware

is an area where the open source initiative and open source in general

has not considered because it's a completely different layer and

can be isolated. Even in AI I think it can be isolated. Adding

hardware considerations would make the whole specification, the whole definition

a lot more complicated and I'm not sure it's viable. But you know if you think it

is, this is your time to leave your comments on the forums on this topic.

To me getting detailed aspects like hardware specifications, the

carbon footprint and things like that is interesting from the social benefit

perspective. But I don't think it really helps with the concept of improving,

collaborating, innovate on the AI systems. It's a little

bit the considerations about ethical use. They're valuable but they need to be put

at a different level, like a legislation level for example. But your comments, I

mean please leave your comments in this part if you think they are part of

the, if they're important for studying, share, modify and distribute AI

systems. And finally just a couple of days ago Carsten Wade made this proposal

to map visually the rights to distribute data set. I think it's an interesting

representation in a quadrant type of way where if you're

building on data, I mean he has this quadrant with two axes. One is on the

vertical axe, you have the IP intellectual property rights, present or

absent. And then if you want to have an integrity of the

pipeline stack, just another axis. So if you're

training something on public data, then basically anyone have high integrity

then you must release everything including the

original data set because basically why shouldn't you? Since there are no, I mean

since you should have all the IP rights. But if you're training on

private data then it's open source AI minus the data, D minus.

I think it's an interesting visual on this. Or if you don't have

the, if you choose not to release the data then it's

definitely going to be a closed, not open source AI. So let's talk about what's

next and that is we're going to be reviewing the text,

close some of the comments, most of the comments and release a release

candidate, have a release candidate version by probably in the next, within a

couple of weeks. So if you have more comments, please do it as soon as

possible. Although there will still be time to change after the release

candidate. And then if you're ready to endorse the open source AI definition, we

are looking for individuals and organizations who can endorse it and

that means that your name or your organization affiliation will be

appended to the press release and the announcement page of the open source AI

definition. So if you want to be part of this release, please email me or Mer,

the email address is on the deck. And just to give a timeline, we are

in September now, we gave a few talks around the world. We are going to

Buenos Aires next week, we Ashland in Oregon this weekend, we've been in

Daba and Bangalore to present this definition and we're going to

be holding more town halls every week until basically until the end of

October for the official launch in North Carolina at All Things Open.

We're going to be holding a special data workshop on data

in Paris also in October thanks to the Alfred P. Sloan Foundation grant.

Alright, so the way to participate is to endorse, so you can email me or

Stefano or Mer and you can keep on commenting on the forum. And with that,

time for Q&A. So take the floor as you want, open your mic or type

questions if you prefer.

I can see Ted comment saying not sure why hardware is needed.

Yeah, go ahead Ted. Yes, Stefano, thank you for sharing, this is really helpful.

Two questions, one is can you share the slides that we can distribute to many

people who cannot attend this town hall? Yes, so the session is recorded, I'm

going to cut the part without the audio and we're going to be sharing the deck, yes.

Okay, so you will share through email? Yeah, all of them are

shared on the forum, so I will put the link on where we're going to be

putting it so you can subscribe and get that one. But yeah, I can send it to you via email.

Okay, and secondly that endorsement, so it's just an email, is there any

template or just a simple email that endorses the RC1 unstable version?

Just an email saying, hey, I'm interested, my organization is

interested in endorsing this and we're going to be putting you in the

loop, so every release candidate will make sure that you have it and

once we get closer to the press release time, we will ask you formally, this

is probably going to be at the beginning of October, for a quote. Okay, can I

suggest that we put a link on the relevant website, so that I

can propagate or send to whoever is interested in endorsing it.

Just one click, one click link, so whatever individual or

organizations, we can hit on the quick list of names or organizations and

that would be it, instead of just a separate email.

Oh no, absolutely, yes, we're thinking about also creating a landing page with

the text and the button below that says, yes, I endorse it, name and

affiliation. Yeah, okay, all right, that'd be great, thank you, I have no more

questions. Thank you. Anyone else, any doubts, ideas?

Overall, it looks good to you?

All right then, oh, Jay, is someone typing?

All right, if there are no more questions, I mean, if you have more questions, you

can always email me or ask directly on the forum, really feel free to use all

the resources we have. I want to thank everyone and

Welcome everyone to our town hall. We're actually going to start having these town halls every week

until the OSAID is launched on October 28th. So we'll be seeing more of you. These are the

community agreements which you're familiar with if you've been here before. One mic, one speaker,

so allow one person to speak at a time, to take space, make space, if you tend to talk more,

pause to let others share, if you tend not to share we invite you to speak up and share your

opinions, to be kind to each other, just not acknowledging that the work is hard, but we can

still be gentle with each other. Obviously hate speech is not permitted in the meeting, that

hopefully is not a surprise, that we're trying to move forward, obviously, that obstacles are marked

to be discussed, but that we try to continue to make progress even when we find those, oh

Nick, I am seeing my whole slide, it's okay, that we seek solutions,

just because there are so many ways that this could not work and finding those ways that this

can work is needed. Does anyone have any other community agreements that they'd like us to

use as we conduct this meeting? You can share it in the chat.

Drinking a bubbly water, okay. Thank you Nick. So we're on version 0.0.9 which was released at

the end of last month, if you use that QR code you can view it online, I believe this is the

HackMD instance with the commenting function, and I'll go through that now. Next. Yeah, so the

OpenSource AI definition has two parts in addition to the preamble, it affirms the four freedoms

as initially enunciated by the Free Software Foundation, but now applied to AI systems, so

grants the freedom to use the system for any purpose without asking permission, to study the

system and inspect its components, to modify the system for any purpose, including to change its

output, and to share the system again with or without modification and for any purpose.

Next. And then the second part of the definition is the preferred form

to make modifications, and again this is for machine learning, OpenSource AI system, right,

so the technology is part of what defines the preferred form, the particular methodology.

So first it requires open weights, so that's model weights and parameters, requires open code,

which means source code used to train and run the system, and it requires data information,

which is the data set or detailed information about the data used to train the system,

and that actually we should change that particular way we're phrasing that,

because the detailed information about the data used to train and run the system is required,

whether or not a data set is also required. Okay, thank you. So what is next, September and

October? We're resolving the comments. We intended to release our RC1 this week. It is still being

edited for reasons some of you may have heard the conversation is having with Gerardo, but there's

still some edits being made to RC1, the release candidate one. Our goal is that we will launch

that next week though, at the Nerdeala conference in Argentina, and then we will have a staple

version launched at All Things Open on October 8th, 28th at the end of next month. Next.

And also just so you know the requirements that we have internally for this launch,

that the board requires that the open source AI definition or OSAID be supported by diverse

stakeholders and specifically for stakeholder types, end users, deployers, developers, and

subjects. So I think in this slide there are not definitions of that, but we can define that if

there's interest, and that that be global representation. Secondly, that there are real

life examples of these AI systems, so it is not, the definition does not result in an empty set.

And finally, that we are able to complete this process by that

deadline that I gave previously of the end of October. Next.

So this is just to let you know where we are. We're in September.

We have done a lot of, we and actually our partners, have done a lot of sharing

the OSAID internationally this month. We had Rahmat, who is a organizational endorser,

which I'll talk about later, and co-designer presented the OSAID in Dakar at the Deep Learning

in Dhaba. We had Taranima Prabhakar, who's a, I'd say a friend, a friend of the OSAID,

and the founder of Taddle, an open source AI system, presented at FOSS India in Bangalore.

I presented in the US at Regen AI, Ashland's in the state of Oregon.

Stefano presented the OSAID in Vienna at Lung's Foundation Europe, and then I will,

inshallah, present in Buenos Aires next week at NERD-ER-LA. And then next week, next month, we

will present at All Things Open, which is in Raleigh, and then we have a data workshop, which

will, which is a data policy paper that deals with, I would say, data questions emerging from the

open source AI definition, but is not specifically working on the definition,

and that will generate a white paper. Okay, yes, get involved. So the big ask,

do you want to do the ask, Nick, the endorse the OSAID ask, because you did, you did this web form.

So do you want to do it, or shall I? Yes, so right now, if you join the website,

and if you look under the drafts, there's a form now for endorsements. So if you'd like to join

that, and I'll paste the link here as well to the form, you can endorse that either as an individual

or as an organization. So let me just drop the link to the form, and it's very simple. You just

add your name, your role, your institution, and if you're endorsing this as an individual or

as an institution, or both, that's an option as well. You can add your comments, and once we

are going to be releasing this, the new release candidates, we'll also showcase some quotes,

and if you add a message there, that should appear as well. Thanks so much. Next slide.

So this is also just sharing with you the definition, and well, you can go back to that

colorful one. Okay, well, they, oh, oh, oh, oh, oh, yeah. So basically, just to say this is a call,

another call for public participation, that anyone who is on the web and would like to endorse the

OSAID is welcome to do so. We do, as Nick said, have the option for organizations to endorse the

OSAID, which is in a more formal process, but also any individual can choose to endorse the OSAID,

and what that means is that when we do have our official launch in October, that your name and

affiliation will be listed on the landing page as an endorser, kind of like the signature at

the end of a document. So, yes, thank you. Next. Hi. So I think that gave, yeah, I think that

gave that information that I was just describing. We can put it up in text still, go back. Some

people like to read as well as to hear information. Could you go back to that previous slide, Nick?

Thank you. Yeah, so this is just affirming that there's individual and organizational,

and it's clarifying what endorsement means, which is that your name is going on, it says

your press release, but it's a public statement that will be on our website, announcing the OSAID,

the web form, and then you can email or DM Nick or I if you have any questions about this,

in addition to the Q&A we're about to have. Now we can go on to the final slide.

Yep, so that's our request. We would love your endorsement of the OSAID,

and to participate in our public forum, which has always been available, and attend weekly town

halls are the ways to currently participate in the process, and that QR code is to the forum,

I believe. So if you go to the next slide.

I will open it up to Q&A, and please, please raise your hand, and I or Nick will call on you,

and allowing everyone to have a comment before we have double up on comments from any one person,

and you can also text in the chat if you would like to do that instead of speaking aloud.

But yeah, I would love to have your comments and questions.

All right.

All right. Hello, or Nick, are there any comments or questions that you feel might be interesting

for us to talk through? Is there anything, anything that I can clarify?

I know that you're going to be talking about the OSAID, and I'm going to be talking about

the OSAID, and I'm going to be talking about the OSAID, and I'm going to be talking about

the OSAID, and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID.

And I'm going to be talking about the OSAID.

Welcome everyone to our town hall. We're actually going to start having these town halls every week

until the OSAID is launched on October 28th. So we'll be seeing more of you. These are the

community agreements which you're familiar with if you've been here before. One mic, one speaker,

so allow one person to speak at a time, to take space, make space, if you tend to talk more,

pause to let others share, if you tend not to share we invite you to speak up and share your

opinions, to be kind to each other, just not acknowledging that the work is hard, but we can

still be gentle with each other. Obviously hate speech is not permitted in the meeting, that

hopefully is not a surprise, that we're trying to move forward, obviously, that obstacles are marked

to be discussed, but that we try to continue to make progress even when we find those, oh

Nick, I am seeing my whole slide, it's okay, that we seek solutions,

just because there are so many ways that this could not work and finding those ways that this

can work is needed. Does anyone have any other community agreements that they'd like us to

use as we conduct this meeting? You can share it in the chat.

Drinking a bubbly water, okay. Thank you Nick. So we're on version 0.0.9 which was released at

the end of last month, if you use that QR code you can view it online, I believe this is the

HackMD instance with the commenting function, and I'll go through that now. Next. Yeah, so the

OpenSource AI definition has two parts in addition to the preamble, it affirms the four freedoms

as initially enunciated by the Free Software Foundation, but now applied to AI systems, so

grants the freedom to use the system for any purpose without asking permission, to study the

system and inspect its components, to modify the system for any purpose, including to change its

output, and to share the system again with or without modification and for any purpose.

Next. And then the second part of the definition is the preferred form

to make modifications, and again this is for machine learning, OpenSource AI system, right,

so the technology is part of what defines the preferred form, the particular methodology.

So first it requires open weights, so that's model weights and parameters, requires open code,

which means source code used to train and run the system, and it requires data information,

which is the data set or detailed information about the data used to train the system,

and that actually we should change that particular way we're phrasing that,

because the detailed information about the data used to train and run the system is required,

whether or not a data set is also required. Okay, thank you. So what is next, September and

October? We're resolving the comments. We intended to release our RC1 this week. It is still being

edited for reasons some of you may have heard the conversation is having with Gerardo, but there's

still some edits being made to RC1, the release candidate one. Our goal is that we will launch

that next week though, at the Nerdeala conference in Argentina, and then we will have a staple

version launched at All Things Open on October 8th, 28th at the end of next month. Next.

And also just so you know the requirements that we have internally for this launch,

that the board requires that the open source AI definition or OSAID be supported by diverse

stakeholders and specifically for stakeholder types, end users, deployers, developers, and

subjects. So I think in this slide there are not definitions of that, but we can define that if

there's interest, and that that be global representation. Secondly, that there are real

life examples of these AI systems, so it is not, the definition does not result in an empty set.

And finally, that we are able to complete this process by that

deadline that I gave previously of the end of October. Next.

So this is just to let you know where we are. We're in September.

We have done a lot of, we and actually our partners, have done a lot of sharing

the OSAID internationally this month. We had Rahmat, who is a organizational endorser,

which I'll talk about later, and co-designer presented the OSAID in Dakar at the Deep Learning

in Dhaba. We had Taranima Prabhakar, who's a, I'd say a friend, a friend of the OSAID,

and the founder of Taddle, an open source AI system, presented at FOSS India in Bangalore.

I presented in the US at Regen AI, Ashland's in the state of Oregon.

Stefano presented the OSAID in Vienna at Lung's Foundation Europe, and then I will,

inshallah, present in Buenos Aires next week at NERD-ER-LA. And then next week, next month, we

will present at All Things Open, which is in Raleigh, and then we have a data workshop, which

will, which is a data policy paper that deals with, I would say, data questions emerging from the

open source AI definition, but is not specifically working on the definition,

and that will generate a white paper. Okay, yes, get involved. So the big ask,

do you want to do the ask, Nick, the endorse the OSAID ask, because you did, you did this web form.

So do you want to do it, or shall I? Yes, so right now, if you join the website,

and if you look under the drafts, there's a form now for endorsements. So if you'd like to join

that, and I'll paste the link here as well to the form, you can endorse that either as an individual

or as an organization. So let me just drop the link to the form, and it's very simple. You just

add your name, your role, your institution, and if you're endorsing this as an individual or

as an institution, or both, that's an option as well. You can add your comments, and once we

are going to be releasing this, the new release candidates, we'll also showcase some quotes,

and if you add a message there, that should appear as well. Thanks so much. Next slide.

So this is also just sharing with you the definition, and well, you can go back to that

colorful one. Okay, well, they, oh, oh, oh, oh, oh, yeah. So basically, just to say this is a call,

another call for public participation, that anyone who is on the web and would like to endorse the

OSAID is welcome to do so. We do, as Nick said, have the option for organizations to endorse the

OSAID, which is in a more formal process, but also any individual can choose to endorse the OSAID,

and what that means is that when we do have our official launch in October, that your name and

affiliation will be listed on the landing page as an endorser, kind of like the signature at

the end of a document. So, yes, thank you. Next. Hi. So I think that gave, yeah, I think that

gave that information that I was just describing. We can put it up in text still, go back. Some

people like to read as well as to hear information. Could you go back to that previous slide, Nick?

Thank you. Yeah, so this is just affirming that there's individual and organizational,

and it's clarifying what endorsement means, which is that your name is going on, it says

your press release, but it's a public statement that will be on our website, announcing the OSAID,

the web form, and then you can email or DM Nick or I if you have any questions about this,

in addition to the Q&A we're about to have. Now we can go on to the final slide.

Yep, so that's our request. We would love your endorsement of the OSAID,

and to participate in our public forum, which has always been available, and attend weekly town

halls are the ways to currently participate in the process, and that QR code is to the forum,

I believe. So if you go to the next slide.

I will open it up to Q&A, and please, please raise your hand, and I or Nick will call on you,

and allowing everyone to have a comment before we have double up on comments from any one person,

and you can also text in the chat if you would like to do that instead of speaking aloud.

But yeah, I would love to have your comments and questions.

All right.

All right. Hello, or Nick, are there any comments or questions that you feel might be interesting

for us to talk through? Is there anything, anything that I can clarify?

I know that you're going to be talking about the OSAID, and I'm going to be talking about

the OSAID, and I'm going to be talking about the OSAID, and I'm going to be talking about

the OSAID, and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

and I'm going to be talking about the OSAID, and I'm going to be talking about the OSAID,

Actually, I shouldn't say anything about its size related to others in Latin America. I'll let Holo do it. Go ahead. Hello. Can you hear me?

Yeah, sorry. I didn't show him with my microphone. Hi, everybody. I'm Holo. I'm a Program Coordinator at the OSI.

I'm also the organizer of Merdiarla, which is an open-source conference based in Latin America, Buenos Aires, Santiago de Chile and Mexico.

And Mer will be joining us next week. She will be giving a presentation at Mercado Libre, which is the biggest

company in Latin America, and is also an endorser and a sponsor of the Roadshow and the Open Source AI Definition Program.

She will be addressing local group of experts and the press as well. And then on Thursday evening,

she will be at Merdiarla in the open-source track

giving a presentation

about the co-design process and everything that led up to this moment and maybe a little teaser about what's happening next month in

October at All Things Open.

That session is going to be live-streamed and it's also going to be recorded.

We will be sharing more details next week on how you can see, watch Mer's talk.

So we are thrilled to have you here in Buenos Aires, Mer.

Thank you so much. And everybody that wants to join, I'm going to leave the link right here

if you want to check in, if you want to register. In order to watch the live streaming,

it's free, but you need to register for the conference.

And then it's going to be uploaded to YouTube probably the same day or Friday or Saturday.

Well, thank you so much, Paulo.

So I think we haven't gotten any other questions, so I think we can close

for update.

And yeah.

