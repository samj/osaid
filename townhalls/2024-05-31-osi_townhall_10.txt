So, thank you.

So hi everyone.

My name is Mare and I'm leading the code of design process for the open source AI definition

and Stefano is with me and this is the public town hall for May 31st.

And those of you who have been here before will recognize our community agreements.

I'll go through them very quickly.

Basically one person speaks at a time.

And we ask that you obviously mute yourself unless we're in the Q&A session.

Take space, make space just means that if you tend to speak up, take a moment to pause

to let others speak and if you do tend to be quiet, we also invite you to share your

thoughts.

And then also once we do get into Q&A, we can have whoever asks a question, there will

be a response and then we'll say wait for another person to ask a question so we don't

just have a back and forth with one speaker.

Kindness this work is hard, but let's be gentle with each other.

Forward motion, focus on what is possible in doing it because this is hard work.

So we note obstacles and we come back to them, but we do what is possible in the moment.

Likewise solution seeking.

So saying something is not possible, yes, and it's very vulnerable to say, hey, how

about this, but that is what we need to have as a mindset to get this work done.

And are there any other community agreements that people would like to propose that are

not here and you can just put them in the chat.

Oh, hi, Anna.

Hi, Anna.

Okay.

I'll just continue.

So yes, so we are creating the open source AI definition.

That's our project for this year.

And where are we now?

We're on version 0.0.8, which was released in April and the parts should be familiar.

We have a preamble.

We have the four freedoms, which we're not going to go into today, but they're used,

we modify and share.

And then we have the legal checklist, which is basically operationalizing the four freedoms

by identifying which components are required, which was voted on by our community co-design

process.

And then what is the license or legal framework for each component.

And Stefano, step in if you have any additions.

What we're working on now is to review, is the review process for determining if an AI

system meets the definition requirements.

And yeah, we would like to review about 10 systems before we release, do release candidate

one in June, which is coming up soon.

A little bit of how did we get here?

This is the recent past, not the story of the whole project as some previous town halls

have shared.

So these are the people who've been working on this.

At this point, we have 11 systems that we're looking at, and this is listing the reviewers.

We started with the asterisked systems, Bloom, Lama2, Pythia and OpenCV.

And then we added on seven more.

So you can see.

And we had this spreadsheet-based validation process where component listed on the far

left, then the legal framework from the definition, then the individual reviewers asked to find

on the internet, which I'll get to later, the legal document as provided by the system

creators, and then to look at that document and determine, does this document give the

ability to study, use, modify, share that particular required component?

And it was hard.

It was in most cases not possible for volunteer reviewers to find the required documents necessary

to do the review.

And as a result, the analysis was also not possible.

So let me just see what my next slide is.

So what this means is that -- oh, there's a new slide here.

I see.

So what that means is that we are still needing to work on the validation, and we're needing

to work with system creators.

We need from system creators their identification of this is the document that you need, this

is the license on this component of our system.

We've just realized that that's -- it's a required component of even being able to test

our own definition.

And okay, we're going to complete this validation phase by the 10th and resolve comments and

release a version 0.0.9 after the validation and cut a release candidate with sufficient

endorsement.

Stefano, did you want to say anything else on the slide?

>> Well, maybe just add a little bit about the validation phase and how it's going.

We realize that basically that checklist is complicated to -- for people, even for experts,

computer experts, to find these components without the expertise of the actual -- the

people who have created the systems is really complicated.

So we really -- at this point, we really have to engage with system creators, the original

creators of PHY, and LLAMA, LLAMA 2 and 3, and GROK, and Mestral, and PTI, et cetera,

Falco, and ask them to provide the list of components.

Or we need to find another way of validating.

Because we had conversations with the Linux Foundation also, and they have a similar concern

for the model openness framework, which we have -- we are reusing for the list of components.

So it is complicated.

But the intention here needs to be -- you know, I'd like to clarify.

The intention here is to provide a definition that is general purpose, that we can apply

to different technology, that can to some extent resist the test of time.

This components piece is really targeted at the latest generation of transformers and

large language models.

The architectures that -- of the systems that we have here, neural networks, et cetera.

So we're really trying to strike a balance between setting principles that are high level

and valid for a longer term.

And provide a checklist for the evaluation of the openness of these systems.

So yeah.

That's it.

We're a little bit -- and I just posted a few minutes ago, probably an hour ago, on

the forum, like a comment along the same lines.

Of what I just said.

There is one curiosity here that probably some people have been -- that I've heard people

asking.

Go back one slide, Nat, please.

Where it says -- the column that says legal document.

And why not call it license?

And that's because the licenses are -- is a term that is really tied to the concept

of copyright.

So it works really for documentation and code.

But for model parameters, the copyright is most likely not applicable.

And the same also for data.

Copyright is not necessarily applicable.

So those are usually referred to as agreements in legal terms.

So that's why we're not calling them -- legal document is more of a generic term that covers

both licenses and agreements in terms of service and other names.

>> So I'll just comment a little on Nick.

And then Dan, I'm going to leave your question to the Q&A.

So just to clarify, because this is a concern that people have of the idea that would system

creators be evaluating their own systems as part of a formal process?

No.

I think it would be that system creators are providing documentation and then there are

independent reviewers looking at that documentation and confirming, yes, this describes the component

as required.

I don't know, Stefano, if you have anything to add on that.

But just this idea of independent review is still part of the process.

Okay.

All right.

So yeah, this is just basically saying what Stefano was talking about.

Reaching out to system creators, I would add that, yeah, we are also looking into collaborating

with the Linux Foundation on this because we are using their component list.

And they do have -- I guess I can't -- I'm not sure what I can announce.

I know they have a launch.

But they're also working on a solution to this documentation challenge.

And so we're looking at how can we collaborate with them.

So that we're not both going to system creators and both asking them for documents, but where

we can be asking the system creators to funnel their documentation into the same location.

This volunteers, I'm not sure that's going to work.

But if volunteers do have this knowledge and can help us fill in the blanks, that's great.

Yes, and we're learning from reviewers, which is basically what Stefano has talked about.

This idea of needing the collaboration of creators, system creators is what we found

from talking to reviewers.

Yeah.

So this is -- yes, there is a report that Stefano referenced, which is just basically

in text talking through what I'm sharing with you now.

And that's a QR code to the forum.

And yeah, we've been thinking through what are ways to simplify the validation process.

At this point, it seems like making the documentation for each component easy to find and review

is probably the number one blocker.

There may also be blockers related to format.

And we're looking at the idea -- Stefano created this design, the idea of an evaluation card.

Maybe that format would be easier to work with than a spreadsheet.

But in any case, having the document to review is probably the number one need that we have

right now.

And Josh, I see your hand.

And I will answer during the Q&A.

And then just to have our timeline.

So we are still looking to release RC1 next month.

And then the stable version in October.

Yeah.

And also a virtual launch event, I guess, is still something we're planning for next

month.

RC1.

We'll see how that goes.

And then we have some in-person meetings.

We were at PyCon.

And Nick created a forum post about that, summaring what we're up to at PyCon.

And yeah, throughout the summer, we have a roadshow going.

And we'll have a data event in October.

That's an issue that's come up throughout the process, is what the definition should

be saying with regards to particularly training data.

So yes, speaking of which.

So yeah, so this is a huge issue.

It's a very important issue in the definition.

And the AWS, Amazon Web Services, open source team posted a range of different concerns

with our current version on the forum.

And the Linux team, primarily the issue of wanting data to be included as a requirement.

And then also the Linux Foundation has recommended adding a data card and removing data processing

code.

So there are various institutional actors and individuals that have made requests about

changing the definition.

And I also just want to affirm to everyone on the call that no changes will be made without

a very clear, structured public process.

So you're not going to wake up one morning and a new requirement is in there, or a requirement

has been removed.

We're sharing with you the requests for transparency.

But we will have a public decision-making process about any changes to the definition.

Let's see how much.

Yes.

So this was helpful and useful.

So the LLM 360 team voluntarily ran their system through version 8 review process.

So again, self-review wouldn't be something that would happen in a formal review process,

but this was very, very helpful just that they were able to look through the component

list and the description of the components and said, yes, we understand what each one

says.

Yes, we have documentation associated with each of these components.

Yes, we think it's fair and well-structured.

And they have their post.

Again, that QR code will take you to the forum, which includes all these different posts I'm

describing.

And then, yes, Stefano also posted about certification.

So what is the process for determining that an AI system meets or does not meet the open

source AI definition?

Is that a certification process that lives at OSI?

Does it live somewhere else?

That's something we're also considering.

And Stefano has a post on that.

If you have thoughts, please comment on that.

Yeah.

And this was also prompted by--

Go ahead.

Yeah.

That request was also prompted by the AWS team, which is something that we were already,

you know, back of our mind.

It's definitely for the future.

It's not an immediate urgency now to decide whether we want to have more certifications

and how that would look like.

But I think it's an interesting question to pose.

And if you have any thoughts, please join the forum and contribute to that conversation.

The question is if OSI should engage in the certification and how.

If yes, how?

It's not necessary.

I don't think it's mandatory for OSI to necessarily engage into this process of certification.

Yeah.

And that was also something that came out of the PyCon workshop that we did.

The number one question from participants was how do I know if an open source-- a system

is open source according to a definition?

You know, what's the process?

How do I know as a system creator even?

So that's also something that directed us in that-- toward that question.

Okay.

Yes.

So just ways to participate have been shared already.

But just the link to the forum is discussed at opensource.org.

You need to create an account, which is free if you want.

Or you can become a member and give us a little donation.

OSI is a nonprofit.

We have the biweekly town halls, which you obviously know about.

And then, yeah, if you would like to volunteer, you can DM myself or Stefano.

But primarily me, since it's my role to manage that.

And now we will get to the Q&A.

So I'll start with Dan, and then I'll call on Josh.

So Dan, I'll just read your question.

Are we looking all the way down to the library level for SBOMs?

And I don't know, Stefano, if you need additional information on that or--

I was wondering, I'm not sure what you mean, Dan.

I can give you voice if you want to speak out loud or if you want to elaborate a little

bit more, because I'm not sure which library level or which SBOMs you're referring to.

Okay.

Dan's typing.

Yeah, there you go.

Is that clarifying?

Yeah.

I'm thinking GitHub repositories.

So for AI systems, there are three type of components that are required.

Then they're grouped into data information, which is mainly made of documentation.

There is model parameters, which is basically a set of one and zero organized in tables.

And then there is code components that include the architecture of the system, the code used

for assembling and creating the data set, the code for running the training, and the

code for inference.

So are we looking at the library level?

I mean, for the code piece, SBOMs, I'm assuming you're talking about the code.

I don't understand the question.

Right.

Yeah.

Code, we're looking at is the code open source or not?

And it's usually pretty easy to understand if it's open source or not.

If it carries an open source license and source code is available, you should be able to figure

it out.

SBOMs are -- no.

So if you're asking how deep we are investigating it, you know, someone was asking yesterday

in a conversation, like, if you -- for inference, you need to run a proprietary system or you

need to run on a proprietary platform.

You can only do inference on G Cloud or something else.

We'll have to think specifically.

We'll have to look at specific examples.

Because we want to -- because there is a thing called the system library exception or there

is an experience that we have from the old days when we didn't have the Linux kernel.

And there was a lot of open source software running on proprietary hardware, on very proprietary

operating systems.

And that was okay.

That was fine.

Because we were working towards having more open source code.

So it didn't matter if you were running an open source photo editor on Windows or, you

know, a kernel, a known free kernel with a GNU user space.

It was still open source software.

So we will have to look at specific examples in these cases to see how deep we want to

go into -- it needs to be open all the way down to the last turtle.

>> Thank you.

Okay.

Josh.

>> I hope that explains.

If you have more questions -- okay.

Good.

Josh.

>> First off, thanks for bringing up the system library extension.

That's the first thing I thought of when I've been thinking about these things.

And the reason why that came about.

Just as you explained so succinctly.

And OSI came out of -- the open source definition came out of all of that.

Having criteria for determining, you know, what's going to be part of this operating

system and whatnot.

Where I feel this -- what I feel this is most analogous to, this process that I've experienced,

is actually the free software foundation's respect to your freedom hardware certification.

Because it had nothing to do with hardware in a sense.

Because they didn't -- they weren't looking at hardware design and things.

That was a nice thing.

If anybody wanted to share their hardware designs, that would be great.

But in designing that program, which is -- I led the launch of that.

And the initial certifications.

It really was about thinking about an ecosystem in a context.

Right?

And having to come up with the set of criteria.

How you go about -- okay.

Here's a person selling a product.

And we want to certify that it's, you know, respects your freedom in these ways.

Right?

But it wasn't just looking at that product.

And what code it shipped with.

That was what we would do to give them certification or not.

But what we did as a community and in working with them, is really encourage them to think

about how they're shipping that.

How they're treating the entire ecosystem.

Not just to support this product, but the idea of product lines and the ability for

a person to take this and make their own potential products or adapt the existing products.

And it feels very similar to that.

That you're going to have a lot of different kinds of hardware.

Or in this case, open AI systems or laboratories, as I kind of think of them.

Or open AI ecosystems.

And it feels like it's a little bit broader than, say, a definition.

But more like, you know, a tree of conditions.

Like, well, for these kinds of systems, there are levels of what a person can do.

You know?

If you ship all of this, it gives them this starting point.

And they can then adapt on top of it.

If you give them, you know, you can give them all of this, but it's not going to be any

of the data.

They're going to have to go out and find all of that to just get started.

To have day one.

It's going to be maybe a year out for them.

Or if they're going to need a certain amount of money.

But we had to do the same kinds of things in the open -- in the hardware certification.

And partly why I bring that up is because we didn't do actual certification.

You know?

Now that I'm in the world of standards development with IEEE, I understand what certification

is much better than I did when I was with the FSF.

But really, it was this criteria.

You could use a trademark.

The FSF's trademark.

You could self-certify was one of the ideas that we were pursuing.

And say, I'm delivering what I believe meets all of these criteria of some version of this

criteria.

And I just want to put that out there.

Because I think there are some amazing historical examples that would be -- that we could run

through this without feeling like we're having a moving target.

Things like Cafe.

And then Facebook's creation of Cafe 2 is, to me, one of the greatest case studies that

we can look at.

A lot of people aren't familiar with it.

And I don't do my civic duty of writing about it.

But to me, it's literally one of the best available sort of things that has gone through

a whole -- its whole life cycle from kind of beginning to end.

Because it's now moved on to other things.

But it's -- I'll leave it -- well, I'll leave everything there.

And then if another time I can come back and I can discuss why I think it's a great learning

example for what is happening here and how it could apply.

But my main kind of point -- and it's kind of a question, I guess -- is, do you feel

this is more like this multi -- like, OSI definition is kind of binary.

Your license is either -- when applied to code, is either meeting this definition or

not.

But I feel the open AI definition really is, it's more like a set of criteria for kinds

of systems or laboratories or like a lab of the box or something that is evaluated and

then potentially given kinds of -- not scores, but, you know, meet certain types of criteria.

And is that where you feel this might be going?

Or are you looking to try to get it to be simpler?

I can't really tell.

>> No, thanks, Josh.

What's your comment?

>> No, I get it.

So it's a frequently asked question, I guess.

Only recently there was another one request on the forum about this.

So I believe that strictly the open source AI definition must be binary.

And it must be binary because if it's not binary, then people will -- people, the public,

politicians, regulators, business managers, and business owners, venture capitals, et

cetera, will expect that also the open source definition will imply a range of openness.

Which is already there.

If you want, like if you look very carefully, you will see that some software is open source.

And then on top of that open source layer, there is a proprietary piece that renders

the whole stack less useful.

But still it's better than nothing.

So there is in practice, there are -- I can see that some people might interpret them

as ranges of open.

But for the definition itself is binary.

And that's where we're -- what we're aiming at.

We have an open source AI definition that is binary.

Meaning you provide these data information, code, and required data information, required

code components, and required model components, and you're done.

You pass the bar.

Then if you provide more, you are more open.

If you provide less, you're not open source AI.

That's it.

It's crystal clear.

Now there is something, though, that keeps coming into my mind.

The concept of what you can do, and there was someone posting recently on the forum

again.

What you can do with a full open source AI, in other words, or with some of the artifacts

of the machine learning, without having access to some of the components, is immensely more

useful and more powerful and more -- you can do more than you can do with a binary piece

of software without having the source code.

In other words, if I don't give you -- so the open source AI definition requires very

detailed information about the data set, so that -- and the code that you use to build

it so that you can retrain the -- or you can train a new model that has similar capabilities,

similar scoring, for example, in benchmarks, et cetera.

That's the intention of the Draft008.

That capability of retraining a model, especially if it's a large one, is not something that

will happen very often.

It's not like rebuilding a binary, even if it's a large one.

It's still within reach, and it makes a lot of sense for security, for research, for a

lot of other things.

The retraining of models is -- I don't think it's going to be very, very popular as an

activity.

But at the same time, fine tuning and splitting models, re-architecting and things like that

is the most, in my mind, in my -- you know, I'm not an expert, but from what I've already

-- we've already started to see those activities being a lot more exciting and popular.

So in the future, there might be some other -- I mean, in practice, as we go into practice,

we may see some -- something else pop up.

Yeah.

>> Thank you.

>> Yeah.

Custom models are time-consuming, expensive, et cetera.

Yeah.

So more questions.

>> Yeah.

Does anyone who hasn't asked a question have a question?

And you can raise your hand or write in the chat.

And any follow-up questions?

Someone who's already asked a question and wanted to ask a follow-up.

Okay.

Josh.

>> Yeah.

So part of where I'm still struggling here, right, is that -- for good reasons, I should

say, I'll start there.

So that I don't -- I don't want to offend anybody.

I think people have made a lot of good choices and has tried to do good things.

But in general, our community has tried to, except for some, avoided talking about the

fact that when we say an operating system is open source, we don't really mean that.

Right?

We don't really mean that you go and if I pick a piece of code at random, it is going

to be open source.

When we're talking about the operating system.

We mean for the most part, practically speaking, with some exceptions here and there.

And that's important to note.

Those are the exceptions that make -- those are the only parts that are the non-open source

parts at times.

And they're there to enable -- to practically allow people to run on different hardware

systems to allow for things that in life are important.

Right?

Whether they were browser add-ons or they were kernel modules or what have you.

Right?

And so I think it's kind of maybe important to note that if the level of things we're

judging are these multifaceted systems, our definition might not need to be when applied

in normally might not need to be perfect.

Because we've never really done that.

People don't want to take the free software foundation stance of, you know, Debian is

not a free software operating system.

Right?

Like, that's just been brutal.

I lived that for ten years when I worked there.

It was terrible.

I hated it.

But I understood why they took that line.

Because they felt somebody needed to.

Even if it -- but everybody else, and I'm very happy everybody else made the good choice

of being practical and saying Debian is a free and open source operating system and

Red Hat is and whatnot.

Right?

But I wonder if we could do something similar with this.

Where we say, look, here's the pristine version of it.

If there are just things that are kind of added on to enable this to happen in various

contexts, then we don't throw -- we don't just label the whole thing as not open source

AI.

Right?

I think that we -- I think that maybe we should say, when we apply this definition, we can

do it in a way that says, is the bulk sort of kernel of this?

Is there a single way in which you could take all of the -- take a subset, a majority subset

of this and apply it in a circumstance where it is 100% AI and these other things are just

for practical compromises to allow it to run in more systems, use certain data sources,

or what have you.

They're not necessarily necessary for what we're evaluating when we say open source AI,

but they're practically needed to allow people to actually use these.

And that's how we apply it.

It still gets us to binary, it's still criteria, but I mean -- sorry, I'm just trying to really

think about real world.

>> Great question.

Yeah.

>> Josh, I hear you.

And in fact, you know, probably as veterans of the open source and free software, I think

you recognize that there is a piece above the checklist.

The checklist is very specific.

And let's say it's a sort of experiment.

That's why it's going through the validation phase.

But what really, in my mind, what really counts is what's above that.

And above that, there is the definition that looks pretty much like the free software foundation,

the free software definition, not just the four freedoms, but also what's written below

as the preferred form to make modifications to a machine learning system.

Those pieces are the ones that in my mind count a lot more.

Because in those pieces, we can have that flexibility to judge and evaluate.

From a distance, we're going to be able to see, hey, do I know enough about the prominence

of this data so that I can say how you've trained your system and therefore I can say

I can replicate it and that will tell me that it's really an open source AI.

And if not, like, dude, I don't even need to go through the checklist.

Like, you know, it's very quick and clear.

But if I have plenty of information, then if it's skipping one of the elements of those

checklists, I can probably say confidently, like, yeah, this is open source enough.

I can live with it.

Because I know that I can do this, this, and that.

I can modify, I can study, share with confidence.

So a lot of it, remember that this is it took 20 plus years to go from the free software

definition to the open source definition.

Like, that required that generate I mean, those 20 years generated a huge amount of

code licenses, there was plenty to draw from to write those 10 points for the Debian free

software guidelines.

We don't have that luxury.

We're really flying and building the plane at the same time.

But yeah, the experience is really valuable.

And if you share with me that cafe that you mentioned that via email, I'm really curious

to see what that is.

Yeah, I'll do that.

I've written it up for sharing to a co worker somewhat recently.

And I'll adapt that.

Just a quick little follow up.

Oh, sorry.

I didn't capitalize.

Yep, yep.

Look, Peter, I need to just absolutely.

Sorry.

So what I'm going to do is I'm going to go to Dan's question.

And then I'll do a last call for questions.

And I think it might make sense, Josh to take the any continuing, continuing conversation

into email.

Just so that we can can wrap up the meeting.

But yeah, so I'll take Dan's question, then we'll do the last call.

So Dan is asking, how will OSI partnerships work, particularly a OS, OSI AI partnerships.

So I think we might need more clarification, but Stefano, do you have enough to respond

to that?

Yeah, I it's not clear to me the concept of partnership, because we don't have partners

now we have the OSI has affiliate organizations, which are other nonprofits that support the

mission of the OSI.

We have individual members who donate to us and decide donate or not, but decide to support

the mission of OSI with money or just by following our activities.

And we have individual sponsors, sorry, corporate sponsors and and but we don't have partners.

So I'm not sure.

We don't envision to have AI partnerships.

So if you want to type in there, Dan, what you're clarifying follow up, then we are happy

to respond to your questions.

And then I think I will just do one last call for comments, actually for questions.

Yes, and then and then yeah, we can take the conversation Josh, the quick conversation

offline to continue if you'd like.

So as I scroll to the last, thank you, slide.

I'm not seeing any.

Okay, cool.

All right.

So then thank you so much.

Anna.

I see I see a raised hand from Anna.

I think it might be a clapping hand from Anna.

Oh, I see.

Okay.

Thank you, Anna.

We appreciate it.

Yeah, we met on at PyCon.

Oh, just clapping.

Okay.

All right.

We appreciate it.

Okay, bye.

Thank you, everyone.

And hang out in the forum.

That's where we share all our updates and opportunities for interaction and feedback.

Thank you.

Thanks.

Bye.

Bye.

Bye.

Thanks.

